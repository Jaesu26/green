{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d464074f-c2b4-4b60-ac9e-3684190addbf",
   "metadata": {},
   "source": [
    "# 이진 분류에서 $F_1$ score와 $Macro-F_1$ score의 차이\n",
    "\n",
    "> \"작성 완료\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: 한재수\n",
    "- categories: [Machine Learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee500ed-9966-415b-aa9e-6146b645201d",
   "metadata": {},
   "source": [
    "## 배경 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5720c6-4ca1-4b23-843c-5d96812b2b9c",
   "metadata": {},
   "source": [
    "`-` 보통, 관심 있는 클래스를 양성(positive), 관심 없는 클래스를 음성(negative)으로 지정한다\n",
    "\n",
    "`-` 클래스: $y$가 가지는 카테고리 (ex: 개, 고양이)\n",
    "\n",
    "`-` 정밀도와 재현율 개념을 짤막하게 요약하면 아래와 같다 (양성 클래스를 P, 음성 클래스를 N이라 하자)\n",
    "\n",
    "`-` 정밀도 ($\\frac{TP}{TP + FP}$): 모델이 샘플을 보고 `P`라고 예측한 것 중 진짜로 `P`인 비율\n",
    "\n",
    "`-` 재현율 ($\\frac{TP}{TP + FN}$): 모든 `P` 샘플 중 모델이 `P`라고 예측해 정답을 맞춘 비율\n",
    "\n",
    "`-` `TP`, `TN`, `FP`, `FN`에서 뒤에 P 또는 N은 모델이 정답으로 추측한 클래스를 뜻하고\n",
    "\n",
    "`-` 앞에 T 또는 F는 모델이 추측한 결과가 True(정답)인지 False(오답)인지 나타낸 것이다\n",
    "\n",
    "`-` 예컨대, `FP`는 false positve라 읽으며 어떤 샘플 $X$를 보고 모델이 `P`라고 예측했는데 틀린(`F`)것을 의미한다 (이때 $X$의 클래스는 `N`임, 그러니까 모델이 틀렸겠지)\n",
    "\n",
    "`-` $F_1$ score는 정밀도(precision)과 재현율(recall)의 조화 평균이다\n",
    "\n",
    "`-` 즉, $F_1$ score $= \\dfrac{2}{\\text{precision}^{-1} + \\text{recall}^{-1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd4fad-6554-48d6-84d4-bb94884b6580",
   "metadata": {},
   "source": [
    "## 양성 샘플이 적은 상황"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c72406-9ede-4329-94ec-a5c1890493f1",
   "metadata": {},
   "source": [
    "`-` 일반적으로 $F_1$ score는 클래스 불균형에서 정확도의 단점을 보완하고자 사용한다\n",
    "\n",
    "`-` 예컨대 $10000$개의 샘플중 $99\\%$가 음성(0)이고 나머지 $1\\%$가 양성(1)이라면 0으로 찍어도 정확도가 $0.99$이다\n",
    "\n",
    "`-` 즉, 입력으로 무엇이 들어오든 0으로 예측한다 (입력을 보기도 전에 답부터 말하는 꼴)\n",
    "\n",
    "`-` 일반적으로 정확도가 $1$에 매우 가까운 $0.99$라면 샘플을 분류한 모델의 성능이 우수하다 생각하지만 위의 예시에선 전혀 아니다 \n",
    "\n",
    "`-` 이러한 문제점을 보완하기 위해 [$F_1$ score](https://en.wikipedia.org/wiki/F-score)를 사용한다\n",
    "\n",
    "`-` 위와 같은 경우 정확도는 $0.99$일지라도 $F_1$ score는 $0$이다 (정확하게는 모든 예측 라벨이 음성이므로 $F_1$ score가 정의되지 않음)\n",
    "\n",
    "`-` 따라서 양성 샘플이 매우 적은 클래스 불균형 상황이라면 $F_1$ score는 분류 성능을 제대로 표현할 수 있는 척도이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4eaaf-78e3-4d68-92b4-a2ef51813b7f",
   "metadata": {},
   "source": [
    "## 양성 샘플이 많은 상황"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b85358-ae5d-4a00-9526-e39314d58650",
   "metadata": {},
   "source": [
    "`-` 하지만 클래스 내에 양성 샘플이 음성 샘플보다 월등히 많은 불균형 상태라면 얘기는 달라진다\n",
    "\n",
    "`-` $10000$개의 샘플중 $1\\%$가 음성(0)이고 나머지 $99\\%$가 양성(1)이라면 1로 찍어도 정확도는 $0.99$이며 $F_1$ score는 대략 $0.995$이다\n",
    "\n",
    "`-` 위 상황에서 모든 샘플을 양성으로 찍으면 재현율은 $1$이며 정밀도에 따라 성능이 결정된다\n",
    "\n",
    "`-` 그런데 샘플의 대부분이 양성이므로 정밀도도 $1$에 근접한다\n",
    "\n",
    "`-` 따라서 클래스 불균형 상황에서 정확도의 단점을 보완하고자 사용한 $F_1$ score도 분류 성능을 제대로 나타내지 못하게 된다\n",
    "\n",
    "`-` 이러한 상황에서 $Macro-F_1$ score가 빛을 발하는데 $Macro-F_1$ score는 각 클래스를 양성, 나머지는 음성으로 놓은 뒤 $F_1$ score를 구하고 이를 평균내므로 하나의 라벨로만 찍게 되면 정확도와 $F_1$ score와 달리 점수가 매우 낮아지게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203e1e1-d011-476d-afa9-1446e0e2d40a",
   "metadata": {},
   "source": [
    "## 의문점?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e570e5-7a65-4cfd-8d56-fccb1eaf6677",
   "metadata": {},
   "source": [
    "`-` `양성 샘플이 많은 상황` ---> 그냥 적은 클래스를 양성으로 하고 $F_1$ score로 평가하면 되는거 아닌가?\n",
    "\n",
    "`-` 애초에 관심 있는 대상을 양성 클래스로 지정함 (ex: 금융 이상치 탐지, 게임 매크로 구분) \n",
    "\n",
    "`-` 흔치 않는 케이스에 관심을 가질것이니 일반적으로 양성 샘플이 훨씬 적을 것이다\n",
    "\n",
    "`-` 그게 아니라 해도 그냥 적은 클래스를 양성으로 지정하고 $F_1$ score로 평가하면 될 것 같은데?\n",
    "\n",
    "`-` 보통은 그렇지만 두 개의 클래스를 양성, 음성으로 구분하기 애매할 때가 존재한다\n",
    "\n",
    "`-` 예컨대 어떤 희귀한 종의 강아지, 희귀한 종의 고양이 이미지가 있을 때 클래스를 맞히고 싶을 수 있다 (강아지 이미지는 강아지라 하고 고양이 이미지는 고양이라 대답하기)\n",
    "\n",
    "`-` 그런데 고양이 이미지는 데이터가 부족하여 강아지 이미지의 $\\frac{1}{2}$만 존재한다고 해보자\n",
    "\n",
    "`-` 예컨대 강아지 이미지가 200장이면 고양이 이미지는 100장밖에 없다\n",
    "\n",
    "`-` 이런 상황에서 고양이를 양성(1), 강아지를 음성(0) 클래스로 지정하자\n",
    "\n",
    "`-` 어떤 무지성 모델이 있는데 이 모델은 어떤 이미지든 무조건 1로 예측한다\n",
    "\n",
    "`-` $\\text{precision} = \\dfrac{100}{300} = \\dfrac{1}{3},\\; \\text{recall} = \\dfrac{100}{100} = 1$\n",
    "\n",
    "`-` 따라서 $F_1$ score는 $\\dfrac{2}{3+1}=\\dfrac{2}{4}=0.5$이다\n",
    "\n",
    "`-` $0.5$면 찍은거치고 생각보다 높은 것 같다?\n",
    "\n",
    "`-` 하지만 강아지 이미지는 단 1개도 맞히지 못했다 (강아지가 양성 클래스인 기준이라면 $F_1$ score는 $0$이다)\n",
    "\n",
    "`-` 반면 $Macro-F_1$ score는 $\\dfrac{0.5+0}{2}=0.25$이다\n",
    "\n",
    "`-` $F_1$ score는 양성 클래스만 포커스를 두므로 $0.5$라는 점수와 강아지 이미지는 구분 못하는 것 사이의 괴리감이 있다\n",
    "\n",
    "`-` 하지만 $Macro-F_1$ score는 강아지 이미지를 구분하지 못하는 것을 반영하여 $F_1$ score보다 낮은 $0.25$라는 점수를 가진다\n",
    "\n",
    "`-` 따라서 두 클래스가 동등하게 중요하다면 점수를 평균내는 $Macro-F_1$ score가 평가 지표로 더 적절하다\n",
    "\n",
    "`-` 근데 어차피 이진 분류이므로 모델의 성능이 좋아지면 $F_1$ score나 $Macro-F_1$ score나 비슷해지긴 하다\n",
    "\n",
    "`-` 그래도 두 클래스 모두 중요한 경우라면 $Macro-F_1$ score가 $F_1$ score보다 적절하다 생각한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228df59-f023-45f8-a88d-745566328ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
