{
  
    
        "post0": {
            "title": "아나콘다 가상환경 만들기",
            "content": "- 가상환경 목록 확인 : conda env list . - 가상환경 간단한 명령어 : conda env . &#50500;&#45208;&#53080;&#45796; &#44032;&#49345;&#54872;&#44221;&#50640;&#49436; &#51452;&#54588;&#53552;&#47017; &#49324;&#50857; . - 간단히 정리하자 . 1. conda create -n 가상환경이름 python=3.8 $ longrightarrow$ 가상환경 생성 . 2. conda activate 가상환경이름 $ longrightarrow$ 가상환경 활성화 . 3. conda install -c conda-forge r-essentials=4.0 $ longrightarrow$ R 4.0 버전 설치 . 4. conda install -c conda-forge jupyterlab $ longrightarrow$ 주피터랩 설치 . 5. R $ longrightarrow$ R 환경진입 . 6. install.packages(&quot;IRkernel&quot;) . 7. library(IRkernel) . 8. installspec() . 9. q() . 10. jupyter lab $ longrightarrow$ 주피터랩 실행 .",
            "url": "https://jaesu26.github.io/green/anaconda/2022/02/18/%EC%95%84%EB%82%98%EC%BD%98%EB%8B%A4-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD.html",
            "relUrl": "/anaconda/2022/02/18/%EC%95%84%EB%82%98%EC%BD%98%EB%8B%A4-%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD.html",
            "date": " • Feb 18, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "데이터시각화 기말고사",
            "content": "- 문제: https://guebin.github.io/2021DV/2021/12/03/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94-%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC.html . - 1, 2번 푸는데 1시간 걸림... 어렵다... . - 아니 왜 plot HTML로 바꿔 올리면 에러남... . import pandas as pd import folium import json import requests . 1 . df = pd.read_html(&#39;https://ncv.kdca.go.kr/mainStatus.es?mid=a11702000000&#39;, encoding = &#39;utf-8&#39;)[1] . df . 구분 1차접종 2차접종 3차접종 . 구분 당일 실적 당일 누계 당일 실적 당일 누계 당일 실적 당일 누계 . 0 합계 | 44915 | 42871274 | 54713 | 41568595 | 439915 | 5289734 | . 1 서울 | 6632 | 7978215 | 7730 | 7760751 | 82159 | 988855 | . 2 부산 | 3359 | 2740631 | 3523 | 2653933 | 28332 | 320683 | . 3 대구 | 2196 | 1907860 | 2353 | 1845856 | 16526 | 195340 | . 4 인천 | 2446 | 2446083 | 3075 | 2370883 | 26230 | 279748 | . 5 광주 | 1480 | 1197383 | 1990 | 1156165 | 10386 | 147318 | . 6 대전 | 1288 | 1180917 | 1639 | 1142424 | 11252 | 135211 | . 7 울산 | 1203 | 914405 | 1171 | 886896 | 7737 | 85420 | . 8 세종 | 304 | 274389 | 371 | 264195 | 2292 | 30502 | . 9 경기 | 11172 | 11225014 | 11469 | 10888835 | 103816 | 1301726 | . 10 강원 | 1411 | 1286431 | 1967 | 1248659 | 17893 | 181907 | . 11 충북 | 1297 | 1359054 | 1874 | 1318878 | 14207 | 180186 | . 12 충남 | 1750 | 1799651 | 2594 | 1741052 | 20880 | 246609 | . 13 전북 | 2044 | 1523092 | 3994 | 1478776 | 21387 | 235253 | . 14 전남 | 1728 | 1582830 | 3270 | 1534876 | 17895 | 276074 | . 15 경북 | 2230 | 2171884 | 2790 | 2102489 | 23735 | 282803 | . 16 경남 | 3536 | 2729534 | 4141 | 2639330 | 29592 | 339109 | . 17 제주 | 839 | 553901 | 762 | 534597 | 5596 | 62990 | . - 합계는 필요없는것 같다 . df_ = df.copy() . df_ = df_.iloc[1:,:].reset_index(drop = True) ## df와 df2의 인덱스번호를 맞춰주기 위함 . global_url = &#39;https://raw.githubusercontent.com/southkorea/southkorea-maps/master/kostat/2018/json/skorea-provinces-2018-geo.json&#39; . global_dict = json.loads(requests.get(global_url).text) . df_.loc[:, (&#39;구분&#39;,&#39;구분&#39;)] = [global_dict[&#39;features&#39;][i][&#39;properties&#39;][&#39;name&#39;] for i in range(17)] . df2 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv&#39;) df2 . 행정구역(시군구)별 총인구수 (명) . 0 서울특별시 | 9532428 | . 1 부산광역시 | 3356311 | . 2 대구광역시 | 2390721 | . 3 인천광역시 | 2945009 | . 4 광주광역시 | 1442454 | . 5 대전광역시 | 1454228 | . 6 울산광역시 | 1122566 | . 7 세종특별자치시 | 368276 | . 8 경기도 | 13549577 | . 9 강원도 | 1537717 | . 10 충청북도 | 1596948 | . 11 충청남도 | 2118977 | . 12 전라북도 | 1789770 | . 13 전라남도 | 1834653 | . 14 경상북도 | 2627925 | . 15 경상남도 | 3318161 | . 16 제주특별자치도 | 676569 | . df2[&#39;prob&#39;] = df_[(&#39;2차접종&#39;, &#39;당일 누계&#39;)] / df2[&#39;총인구수 (명)&#39;] . df2 = df2.rename(columns = {&#39;행정구역(시군구)별&#39;:&#39;prov&#39;}).drop(&#39;총인구수 (명)&#39;, axis = 1) . df2 . prov prob . 0 서울특별시 | 0.814142 | . 1 부산광역시 | 0.790729 | . 2 대구광역시 | 0.772092 | . 3 인천광역시 | 0.805051 | . 4 광주광역시 | 0.801526 | . 5 대전광역시 | 0.785588 | . 6 울산광역시 | 0.790061 | . 7 세종특별자치시 | 0.717383 | . 8 경기도 | 0.803629 | . 9 강원도 | 0.812021 | . 10 충청북도 | 0.825874 | . 11 충청남도 | 0.821647 | . 12 전라북도 | 0.826238 | . 13 전라남도 | 0.836603 | . 14 경상북도 | 0.800057 | . 15 경상남도 | 0.795420 | . 16 제주특별자치도 | 0.790159 | . m = folium.Map(scrollWheelZoom = False, location = [36,128], zoom_start = 8.2) folium.Choropleth( data = df2, geo_data = global_dict, columns = [&#39;prov&#39;, &#39;prob&#39;], key_on = &#39;feature.properties.name&#39; ).add_to(m) # m . &lt;folium.features.Choropleth at 0x215edd70f70&gt; . 2 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/covid19_20211202.csv&#39;) df . 일자 계(명) 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 검역 . 0 누적(명) | 457,612 | 158,774 | 16,555 | 19,114 | 25,299 | 6,353 | 8,809 | 5,675 | 1,588 | 136,546 | 8,889 | 8,942 | 13,174 | 6,453 | 4,498 | 11,471 | 15,236 | 3,762 | 6,474 | . 1 2020-01-20 | 1 | - | - | - | 1 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 2 2020-01-21 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 3 2020-01-22 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 4 2020-01-23 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 3,925 | 1,673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1,090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | 10 | . 680 2021-11-29 | 3,308 | 1,393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | 3 | . 681 2021-11-30 | 3,032 | 1,186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | 8 | . 682 2021-12-01 | 5,123 | 2,222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1,582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | 20 | . 683 2021-12-02 | 5,266 | 2,268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1,495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | 5 | . 684 rows × 20 columns . df3 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-11-22-prov.csv&#39;) df3 . 행정구역(시군구)별 총인구수 (명) . 0 서울특별시 | 9532428 | . 1 부산광역시 | 3356311 | . 2 대구광역시 | 2390721 | . 3 인천광역시 | 2945009 | . 4 광주광역시 | 1442454 | . 5 대전광역시 | 1454228 | . 6 울산광역시 | 1122566 | . 7 세종특별자치시 | 368276 | . 8 경기도 | 13549577 | . 9 강원도 | 1537717 | . 10 충청북도 | 1596948 | . 11 충청남도 | 2118977 | . 12 전라북도 | 1789770 | . 13 전라남도 | 1834653 | . 14 경상북도 | 2627925 | . 15 경상남도 | 3318161 | . 16 제주특별자치도 | 676569 | . df3 = df3.rename(columns = {&#39;행정구역(시군구)별&#39;:&#39;prov&#39;, &#39;총인구수 (명)&#39;:&#39;pop&#39;}) . - 검역은 지도에 표시 안할거니 제외 . df_ = df.copy() . df_.iloc[1:, 1:] = df_.iloc[1:, 1:].applymap(lambda x: int(x.replace(&#39;,&#39;, &#39;&#39;)) if x != &#39;-&#39; else 0) . df_ = df_.iloc[1:, :-1].drop(&#39;계(명)&#39;, axis = 1) . df_[&#39;일자&#39;] = df_[&#39;일자&#39;].apply(lambda x: str(x)[:-3]) df_ . 일자 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 . 1 2020-01 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 2020-01 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11 | 1673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | . 680 2021-11 | 1393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | . 681 2021-11 | 1186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | . 682 2021-12 | 2222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | . 683 2021-12 | 2268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | . 683 rows × 18 columns . _df = df_.groupby(&#39;일자&#39;).agg(&#39;sum&#39;).reset_index(). rename(columns = dict(zip(df_.columns, [&#39;ym&#39;] + [global_dict[&#39;features&#39;][i][&#39;properties&#39;][&#39;name&#39;] for i in range(17)]))). query(&#39;&quot;2021-01&quot; &lt;= ym &lt;= &quot;2021-10&quot;&#39;). melt(id_vars = &#39;ym&#39;).rename(columns = {&#39;variable&#39;:&#39;prov&#39;, &#39;value&#39;:&#39;confirmed&#39;}) . _df = _df.assign(pop = [df3.query(&#39;prov == @_df[&quot;prov&quot;][@i]&#39;)[&#39;pop&#39;].pipe(int) for i in range(len(_df))]). eval(&#39;prop = confirmed / pop&#39;) . _df . ym prov confirmed pop prop . 0 2021-01 | 서울특별시 | 5160 | 9532428 | 0.000541 | . 1 2021-02 | 서울특별시 | 4080 | 9532428 | 0.000428 | . 2 2021-03 | 서울특별시 | 3794 | 9532428 | 0.000398 | . 3 2021-04 | 서울특별시 | 5807 | 9532428 | 0.000609 | . 4 2021-05 | 서울특별시 | 6078 | 9532428 | 0.000638 | . ... ... | ... | ... | ... | ... | . 165 2021-06 | 제주특별자치도 | 234 | 676569 | 0.000346 | . 166 2021-07 | 제주특별자치도 | 468 | 676569 | 0.000692 | . 167 2021-08 | 제주특별자치도 | 870 | 676569 | 0.001286 | . 168 2021-09 | 제주특별자치도 | 273 | 676569 | 0.000404 | . 169 2021-10 | 제주특별자치도 | 225 | 676569 | 0.000333 | . 170 rows × 5 columns . - 지금까지 고생해서 만든 데이터프레임은 시도별 월별 코로나수 확진자 수이다 . # from IPython.display import HTML # fig = px.choropleth_mapbox(_df, # geojson = global_dict, # color = &#39;prop&#39;, # locations = &#39;prov&#39;, # animation_frame = &#39;ym&#39;, # featureidkey = &#39;properties.name&#39;, # center = {&quot;lat&quot;: 36, &quot;lon&quot;: 128}, # mapbox_style = &#39;carto-positron&#39;, # range_color = (0, _df.prop.max()), # height = 1200, # zoom = 6.5) # fig.update_layout(margin = {&quot;r&quot;:0, &quot;t&quot;:0, &quot;l&quot;:0, &quot;b&quot;:0}) # _html = fig.to_html(include_mathjax = False, config = dict({&#39;scrollZoom&#39;:False})) # HTML(_html) . - 위 코드를 실행하면 컴퓨터가 맛이가서 전부 주석처리했다 . 3 . df4 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/covid19_20211202.csv&#39;) df4 . 일자 계(명) 서울 부산 대구 인천 광주 대전 울산 세종 경기 강원 충북 충남 전북 전남 경북 경남 제주 검역 . 0 누적(명) | 457,612 | 158,774 | 16,555 | 19,114 | 25,299 | 6,353 | 8,809 | 5,675 | 1,588 | 136,546 | 8,889 | 8,942 | 13,174 | 6,453 | 4,498 | 11,471 | 15,236 | 3,762 | 6,474 | . 1 2020-01-20 | 1 | - | - | - | 1 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 2 2020-01-21 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 3 2020-01-22 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . 4 2020-01-23 | 0 | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | - | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 3,925 | 1,673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1,090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | 10 | . 680 2021-11-29 | 3,308 | 1,393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | 3 | . 681 2021-11-30 | 3,032 | 1,186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | 8 | . 682 2021-12-01 | 5,123 | 2,222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1,582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | 20 | . 683 2021-12-02 | 5,266 | 2,268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1,495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | 5 | . 684 rows × 20 columns . - 위의 데이터프레임을 전처리한것이 아래다 . - 누적과 합계를 제외하고 검역도 제외했다 . - 관찰치를 int형으로 바꾸고 -은 0으로 처리했다 . df4.iloc[1:, 1:] = df4.iloc[1:, 1:].applymap(lambda x: int(x.replace(&#39;,&#39;, &#39;&#39;)) if x != &#39;-&#39; else 0) . df4 = df4.iloc[1:, :-1].drop(&#39;계(명)&#39;, axis = 1) . df4.columns = [&#39;date&#39;] + [global_dict[&#39;features&#39;][i][&#39;properties&#39;][&#39;name_eng&#39;] for i in range(17)] . df4 . date Seoul Busan Daegu Incheon Gwangju Daejeon Ulsan Sejongsi Gyeonggi-do Gangwon-do Chungcheongbuk-do Chungcheongnam-do Jeollabuk-do Jeollanam-do Gyeongsangbuk-do Gyeongsangnam-do Jeju-do . 1 2020-01-20 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01-21 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01-22 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01-23 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 2020-01-24 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 1673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | . 680 2021-11-29 | 1393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | . 681 2021-11-30 | 1186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | . 682 2021-12-01 | 2222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | . 683 2021-12-02 | 2268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | . 683 rows × 18 columns . (1) matplotlib . import matplotlib.pyplot as plt . df4.plot.line(x = &#39;date&#39;, subplots = True, layout = (9, 2), figsize = (15, 15)) plt.tight_layout() . (2) plotly . - 데이터프레임을 tidy하게 만들면된다 . df4 ## 현재 데이터프레임 상태 . date Seoul Busan Daegu Incheon Gwangju Daejeon Ulsan Sejongsi Gyeonggi-do Gangwon-do Chungcheongbuk-do Chungcheongnam-do Jeollabuk-do Jeollanam-do Gyeongsangbuk-do Gyeongsangnam-do Jeju-do . 1 2020-01-20 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 2020-01-21 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 2020-01-22 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 2020-01-23 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 2020-01-24 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 679 2021-11-28 | 1673 | 148 | 106 | 278 | 52 | 53 | 4 | 5 | 1090 | 63 | 25 | 121 | 45 | 25 | 103 | 89 | 35 | . 680 2021-11-29 | 1393 | 144 | 88 | 233 | 61 | 43 | 2 | 15 | 910 | 56 | 33 | 52 | 49 | 28 | 68 | 86 | 44 | . 681 2021-11-30 | 1186 | 79 | 78 | 192 | 52 | 43 | 3 | 22 | 909 | 84 | 59 | 81 | 50 | 36 | 68 | 60 | 22 | . 682 2021-12-01 | 2222 | 143 | 86 | 326 | 29 | 88 | 17 | 20 | 1582 | 105 | 48 | 96 | 50 | 40 | 97 | 127 | 27 | . 683 2021-12-02 | 2268 | 158 | 70 | 355 | 39 | 166 | 18 | 8 | 1495 | 145 | 49 | 149 | 71 | 39 | 106 | 94 | 31 | . 683 rows × 18 columns . df4_ = df4.melt(id_vars = &#39;date&#39;).rename(columns = {&#39;variable&#39;:&#39;prov&#39;}) . df4_ . date prov value . 0 2020-01-20 | Seoul | 0 | . 1 2020-01-21 | Seoul | 0 | . 2 2020-01-22 | Seoul | 0 | . 3 2020-01-23 | Seoul | 0 | . 4 2020-01-24 | Seoul | 1 | . ... ... | ... | ... | . 11606 2021-11-28 | Jeju-do | 35 | . 11607 2021-11-29 | Jeju-do | 44 | . 11608 2021-11-30 | Jeju-do | 22 | . 11609 2021-12-01 | Jeju-do | 27 | . 11610 2021-12-02 | Jeju-do | 31 | . 11611 rows × 3 columns . # fig = df4_.plot.line(backend = &#39;plotly&#39;, # x = &#39;date&#39;, # y = &#39;value&#39;, # color = &#39;prov&#39;, # facet_col = &#39;prov&#39;, # facet_col_wrap = 3, # height = 1000) # fig.update_yaxes(matches = None) # HTML(fig.to_html(include_mathjax = False, config = dict({&#39;scrollZoom&#39;:False}))) . 4 . (1) . df5 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) df5.head() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . 5 rows × 65 columns . abilities = [&#39;Crossing&#39;, &#39;Finishing&#39;, &#39;HeadingAccuracy&#39;, &#39;ShortPassing&#39;, &#39;Volleys&#39;, &#39;Dribbling&#39;, &#39;Curve&#39;, &#39;FKAccuracy&#39;, &#39;LongPassing&#39;, &#39;BallControl&#39;, &#39;Acceleration&#39;, &#39;SprintSpeed&#39;, &#39;Agility&#39;, &#39;Reactions&#39;, &#39;Balance&#39;, &#39;ShotPower&#39;, &#39;Jumping&#39;, &#39;Stamina&#39;, &#39;Strength&#39;, &#39;LongShots&#39;, &#39;Aggression&#39;, &#39;Interceptions&#39;, &#39;Positioning&#39;, &#39;Vision&#39;, &#39;Penalties&#39;, &#39;Composure&#39;, &#39;StandingTackle&#39;, &#39;SlidingTackle&#39;] . - 일단 Korea Republic을 Korea로 바꾼다 . df5[&#39;Nationality&#39;] = df5[&#39;Nationality&#39;].replace(&#39;Korea Republic&#39;, &#39;Korea&#39;) . mean_ = [&#39;mean&#39;] * len(abilities) . df5_ = df5.query(&#39;Nationality == &quot;Korea&quot; or Nationality == &quot;Japan&quot;&#39;). groupby(&#39;Nationality&#39;).agg(dict(zip(abilities, mean_))). stack().reset_index().rename(columns = {&#39;level_1&#39;:&#39;aility&#39;, 0:&#39;value&#39;}) . df5_[&#39;value&#39;] = round(df5_[&#39;value&#39;], 2) . df5_ . Nationality aility value . 0 Japan | Crossing | 54.42 | . 1 Japan | Finishing | 50.67 | . 2 Japan | HeadingAccuracy | 51.07 | . 3 Japan | ShortPassing | 62.35 | . 4 Japan | Volleys | 46.54 | . 5 Japan | Dribbling | 59.53 | . 6 Japan | Curve | 51.18 | . 7 Japan | FKAccuracy | 46.57 | . 8 Japan | LongPassing | 57.50 | . 9 Japan | BallControl | 62.29 | . 10 Japan | Acceleration | 67.31 | . 11 Japan | SprintSpeed | 66.84 | . 12 Japan | Agility | 68.63 | . 13 Japan | Reactions | 62.05 | . 14 Japan | Balance | 68.37 | . 15 Japan | ShotPower | 59.14 | . 16 Japan | Jumping | 67.12 | . 17 Japan | Stamina | 66.35 | . 18 Japan | Strength | 62.54 | . 19 Japan | LongShots | 51.57 | . 20 Japan | Aggression | 54.74 | . 21 Japan | Interceptions | 46.55 | . 22 Japan | Positioning | 55.34 | . 23 Japan | Vision | 58.00 | . 24 Japan | Penalties | 48.74 | . 25 Japan | Composure | 58.93 | . 26 Japan | StandingTackle | 48.48 | . 27 Japan | SlidingTackle | 45.37 | . 28 Korea | Crossing | 49.76 | . 29 Korea | Finishing | 47.74 | . 30 Korea | HeadingAccuracy | 51.69 | . 31 Korea | ShortPassing | 58.76 | . 32 Korea | Volleys | 43.68 | . 33 Korea | Dribbling | 55.82 | . 34 Korea | Curve | 48.52 | . 35 Korea | FKAccuracy | 45.63 | . 36 Korea | LongPassing | 53.37 | . 37 Korea | BallControl | 57.70 | . 38 Korea | Acceleration | 65.85 | . 39 Korea | SprintSpeed | 66.11 | . 40 Korea | Agility | 67.11 | . 41 Korea | Reactions | 61.94 | . 42 Korea | Balance | 66.66 | . 43 Korea | ShotPower | 56.83 | . 44 Korea | Jumping | 64.88 | . 45 Korea | Stamina | 64.63 | . 46 Korea | Strength | 65.23 | . 47 Korea | LongShots | 48.94 | . 48 Korea | Aggression | 56.08 | . 49 Korea | Interceptions | 47.47 | . 50 Korea | Positioning | 54.62 | . 51 Korea | Vision | 57.27 | . 52 Korea | Penalties | 47.97 | . 53 Korea | Composure | 58.48 | . 54 Korea | StandingTackle | 46.63 | . 55 Korea | SlidingTackle | 44.28 | . # y = &#39;aility&#39;, # x = &#39;value&#39;, # barmode = &#39;group&#39;, # color = &#39;Nationality&#39;, # text = &#39;value&#39;, # height = 1500, # width = 800) # HTML(fig.to_html(include_mathjax = False, config = dict({&#39;scrollZoom&#39;:False}))) . - plotly는 따로 barh가 없으니 x와 y를 바꾸자 . (2) . _df5 = df5.copy() . players = _df5.groupby(&#39;Nationality&#39;).agg(&#39;size&#39;).reset_index(). sort_values(0, ascending = False).iloc[:20, 0].pipe(set) . players . {&#39;Argentina&#39;, &#39;Belgium&#39;, &#39;Brazil&#39;, &#39;Colombia&#39;, &#39;Denmark&#39;, &#39;England&#39;, &#39;France&#39;, &#39;Germany&#39;, &#39;Italy&#39;, &#39;Japan&#39;, &#39;Mexico&#39;, &#39;Netherlands&#39;, &#39;Norway&#39;, &#39;Poland&#39;, &#39;Portugal&#39;, &#39;Republic of Ireland&#39;, &#39;Scotland&#39;, &#39;Spain&#39;, &#39;Sweden&#39;, &#39;United States&#39;} . - 위는 선수 수가 많은 상위 20개 나라 . overall = set(_df5.groupby(&#39;Nationality&#39;).agg({&#39;Overall&#39;:&#39;mean&#39;}). sort_values(&#39;Overall&#39;, ascending = False).iloc[:20,:].T.columns.tolist()) . overall . {&#39;Algeria&#39;, &#39;Argentina&#39;, &#39;Brazil&#39;, &#39;Cape Verde Islands&#39;, &#39;Central African Republic&#39;, &#39;Croatia&#39;, &#39;Czech Republic&#39;, &#39;Egypt&#39;, &#39;Fiji&#39;, &#39;Gabon&#39;, &#39;Libya&#39;, &#39;Mozambique&#39;, &#39;Namibia&#39;, &#39;Portugal&#39;, &#39;Russia&#39;, &#39;Serbia&#39;, &#39;Syria&#39;, &#39;Tanzania&#39;, &#39;Ukraine&#39;, &#39;Uruguay&#39;} . - 위는 Overall이 높은 상위 20개 나라 . best = list(overall.intersection(players)) best . [&#39;Argentina&#39;, &#39;Brazil&#39;, &#39;Portugal&#39;] . - 위는 overall과 players의 교집합 . df5.query(&#39;Nationality in @best&#39;). groupby(&#39;Nationality&#39;).agg({&#39;Age&#39;:&#39;mean&#39;}). sort_values(&#39;Age&#39;, ascending = False). plot.bar() . &lt;AxesSubplot:xlabel=&#39;Nationality&#39;&gt; . - Argentina 선수들의 평균 연령이 제일 높고 그 다음은 Brazil 마지막은 Portugal 이다 . 5 . - 내가 임의로 만든 데이터 . from plotnine import * . gdp = [500, 600, 620, 700, 900, 800, 770, 765, 1102, 1155, 1320, 1500, 1900, 1950, 2200] year = list(range(1990, 2005)) unfair = [58, 60, 61, 57, 58.2, 59.7, 63.5, 62.7, 57.5, 56.8, 60.2, 59.2, 58.2, 57.8, 61.3] govern = [&#39;A&#39;] * 5 + [&#39;B&#39;] * 5 + [&#39;C&#39;] * 5 . Data = pd.DataFrame({&#39;gdp&#39;:gdp, &#39;year&#39;:year, &#39;unfair&#39;:unfair, &#39;govern&#39;:govern}) . Data . gdp year unfair govern . 0 500 | 1990 | 58.0 | A | . 1 600 | 1991 | 60.0 | A | . 2 620 | 1992 | 61.0 | A | . 3 700 | 1993 | 57.0 | A | . 4 900 | 1994 | 58.2 | A | . 5 800 | 1995 | 59.7 | B | . 6 770 | 1996 | 63.5 | B | . 7 765 | 1997 | 62.7 | B | . 8 1102 | 1998 | 57.5 | B | . 9 1155 | 1999 | 56.8 | B | . 10 1320 | 2000 | 60.2 | C | . 11 1500 | 2001 | 59.2 | C | . 12 1900 | 2002 | 58.2 | C | . 13 1950 | 2003 | 57.8 | C | . 14 2200 | 2004 | 61.3 | C | . a = Data.loc[[5]] b = Data.loc[[10]] . a[&#39;govern&#39;] = &#39;A&#39; b[&#39;govern&#39;] = &#39;B&#39; . Data = pd.concat([Data.loc[:4], a, Data.loc[5:9], b, Data.loc[10:]]) . Data . gdp year unfair govern . 0 500 | 1990 | 58.0 | A | . 1 600 | 1991 | 60.0 | A | . 2 620 | 1992 | 61.0 | A | . 3 700 | 1993 | 57.0 | A | . 4 900 | 1994 | 58.2 | A | . 5 800 | 1995 | 59.7 | A | . 5 800 | 1995 | 59.7 | B | . 6 770 | 1996 | 63.5 | B | . 7 765 | 1997 | 62.7 | B | . 8 1102 | 1998 | 57.5 | B | . 9 1155 | 1999 | 56.8 | B | . 10 1320 | 2000 | 60.2 | B | . 10 1320 | 2000 | 60.2 | C | . 11 1500 | 2001 | 59.2 | C | . 12 1900 | 2002 | 58.2 | C | . 13 1950 | 2003 | 57.8 | C | . 14 2200 | 2004 | 61.3 | C | . - C만 5개여서 불편... . ggplot(Data, aes(x = &#39;gdp&#39;, y = &#39;unfair&#39;)) + geom_point() + geom_text(aes(label = &#39;year&#39;), size = 8, va = &#39;bottom&#39;, ha = &#39;left&#39;) + geom_path(aes(color = &#39;govern&#39;), size = 2, alpha = 0.7) . &lt;ggplot: (194634680408)&gt; . ggplot(Data, aes(x = &#39;gdp&#39;, y = &#39;unfair&#39;)) + geom_point() + geom_text(aes(label = &#39;year&#39;), size = 8, va = &#39;bottom&#39;, ha = &#39;left&#39;) + geom_line(aes(color = &#39;govern&#39;), size = 2, alpha = 0.7) . &lt;ggplot: (194634631623)&gt; . - geom_line과 geom_path의 차이 . - geom_path는 선이 year를 따라간다 . - geom_line는 선이 왼쪽에서 오른쪽으로 간다(예컨대 1993다음은 1994이지만 1993 바로 오른쪽(같은 색깔중)에 1995가 있어서 1995로 간다) . (1) . - 실제 문제 . from plotnine import * . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df1.csv&#39;) df . GDP Inequality Government . 0 500 | 56 | A | . 1 550 | 58 | A | . 2 530 | 59 | A | . 3 480 | 61 | A | . 4 550 | 64 | A | . 5 550 | 64 | B | . 6 750 | 66 | B | . 7 560 | 68 | B | . 8 800 | 70 | B | . 9 900 | 65 | B | . 10 900 | 65 | C | . 11 910 | 62 | C | . 12 1100 | 61 | C | . 13 1250 | 58 | C | . 14 1350 | 63 | C | . 15 1350 | 63 | D | . 16 1500 | 57 | D | . 17 1660 | 55 | D | . df2 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df2.csv&#39;, index_col = 0) df2 . A B C D . pop 54232.213 | 48823.432 | 46823.453 | 45232.119 | . df_ = df2.T.reset_index().rename(columns = {&#39;index&#39;:&#39;Government&#39;}).merge(df) df_ . Government pop GDP Inequality . 0 A | 54232.213 | 500 | 56 | . 1 A | 54232.213 | 550 | 58 | . 2 A | 54232.213 | 530 | 59 | . 3 A | 54232.213 | 480 | 61 | . 4 A | 54232.213 | 550 | 64 | . 5 B | 48823.432 | 550 | 64 | . 6 B | 48823.432 | 750 | 66 | . 7 B | 48823.432 | 560 | 68 | . 8 B | 48823.432 | 800 | 70 | . 9 B | 48823.432 | 900 | 65 | . 10 C | 46823.453 | 900 | 65 | . 11 C | 46823.453 | 910 | 62 | . 12 C | 46823.453 | 1100 | 61 | . 13 C | 46823.453 | 1250 | 58 | . 14 C | 46823.453 | 1350 | 63 | . 15 D | 45232.119 | 1350 | 63 | . 16 D | 45232.119 | 1500 | 57 | . 17 D | 45232.119 | 1660 | 55 | . ggplot(df_) + geom_path(aes(x = &#39;GDP&#39;, y = &#39;Inequality&#39;, size = &#39;pop&#39;, color = &#39;Government&#39;)) . &lt;ggplot: (194634670827)&gt; . (2) . df3 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/gdp_df3.csv&#39;, index_col = 0) df3 . type . A prog | . B cons | . C prog | . D cons | . df__ = df3.reset_index().rename(columns = {&#39;index&#39;:&#39;Government&#39;}).merge(df_) df__ . Government type pop GDP Inequality . 0 A | prog | 54232.213 | 500 | 56 | . 1 A | prog | 54232.213 | 550 | 58 | . 2 A | prog | 54232.213 | 530 | 59 | . 3 A | prog | 54232.213 | 480 | 61 | . 4 A | prog | 54232.213 | 550 | 64 | . 5 B | cons | 48823.432 | 550 | 64 | . 6 B | cons | 48823.432 | 750 | 66 | . 7 B | cons | 48823.432 | 560 | 68 | . 8 B | cons | 48823.432 | 800 | 70 | . 9 B | cons | 48823.432 | 900 | 65 | . 10 C | prog | 46823.453 | 900 | 65 | . 11 C | prog | 46823.453 | 910 | 62 | . 12 C | prog | 46823.453 | 1100 | 61 | . 13 C | prog | 46823.453 | 1250 | 58 | . 14 C | prog | 46823.453 | 1350 | 63 | . 15 D | cons | 45232.119 | 1350 | 63 | . 16 D | cons | 45232.119 | 1500 | 57 | . 17 D | cons | 45232.119 | 1660 | 55 | . ggplot(df__) + geom_path(aes(x = &#39;GDP&#39;, y = &#39;Inequality&#39;, size = &#39;pop&#39;, color = &#39;Government&#39;, linetype = &#39;type&#39;)) . &lt;ggplot: (194634935881)&gt; . 6 . df6 = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/phone.csv&#39;) df6 . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 461 | 324 | 136 | 109 | 76 | 81 | 43 | 37 | 135 | 28 | 39 | 14 | 22 | 17 | 20 | 17 | . 1 2019-11 | 461 | 358 | 167 | 141 | 86 | 61 | 29 | 36 | 141 | 27 | 29 | 20 | 23 | 10 | 19 | 27 | . 2 2019-12 | 426 | 383 | 143 | 105 | 53 | 45 | 51 | 48 | 129 | 30 | 20 | 26 | 28 | 18 | 18 | 19 | . 3 2020-01 | 677 | 494 | 212 | 187 | 110 | 79 | 65 | 49 | 158 | 23 | 13 | 19 | 19 | 22 | 27 | 22 | . 4 2020-02 | 593 | 520 | 217 | 195 | 112 | 67 | 62 | 71 | 157 | 25 | 18 | 16 | 24 | 18 | 23 | 20 | . 5 2020-03 | 637 | 537 | 246 | 187 | 92 | 66 | 59 | 67 | 145 | 21 | 16 | 24 | 18 | 31 | 22 | 14 | . 6 2020-04 | 647 | 583 | 222 | 154 | 98 | 59 | 48 | 64 | 113 | 20 | 23 | 25 | 19 | 19 | 23 | 21 | . 7 2020-05 | 629 | 518 | 192 | 176 | 91 | 87 | 50 | 66 | 150 | 43 | 27 | 15 | 18 | 19 | 19 | 13 | . 8 2020-06 | 663 | 552 | 209 | 185 | 93 | 69 | 54 | 60 | 140 | 39 | 16 | 16 | 17 | 29 | 25 | 16 | . 9 2020-07 | 599 | 471 | 214 | 193 | 89 | 78 | 65 | 59 | 130 | 40 | 27 | 25 | 21 | 18 | 18 | 12 | . 10 2020-08 | 615 | 567 | 204 | 182 | 105 | 82 | 62 | 42 | 129 | 47 | 16 | 23 | 21 | 27 | 23 | 20 | . 11 2020-09 | 621 | 481 | 230 | 220 | 102 | 88 | 56 | 49 | 143 | 54 | 14 | 15 | 17 | 15 | 19 | 15 | . 12 2020-10 | 637 | 555 | 232 | 203 | 90 | 52 | 63 | 49 | 140 | 33 | 17 | 20 | 22 | 9 | 22 | 21 | . (1) . df6.set_index(&#39;Date&#39;). plot.line(figsize = (10, 7)) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . (2) . df6.set_index(&#39;Date&#39;). plot.line(figsize = (10, 15), subplots = True, layout = (8, 2)) plt.tight_layout() . (3) . df6.set_index(&#39;Date&#39;).stack().reset_index().rename(columns = {&#39;level_1&#39;:&#39;variable&#39;, 0:&#39;value&#39;}). groupby(&#39;variable&#39;).agg(&#39;sum&#39;).sort_values(&#39;value&#39;, ascending = False). plot.bar() . &lt;AxesSubplot:xlabel=&#39;variable&#39;&gt; . (4) . df6_ = df6.copy() . df6_.Date = df6_.Date.apply(lambda x: str(x)[:4]) . _df6 = df6_.query(&#39;Date == &quot;2019&quot;&#39;).melt(id_vars = &#39;Date&#39;).groupby(&#39;variable&#39;).agg(&#39;sum&#39;) . _df6[&#39;value&#39;] = _df6[&#39;value&#39;] / _df6.value.sum() . _df6 . value . variable . Apple 0.224873 | . Asus 0.013302 | . Google 0.018581 | . Huawei 0.094172 | . LG 0.025549 | . Lenovo 0.015414 | . Mobicel 0.039485 | . Motorola 0.025971 | . Nokia 0.012669 | . OnePlus 0.009502 | . Oppo 0.045397 | . Others 0.085515 | . Realme 0.017948 | . Samsung 0.284628 | . Sony 0.012035 | . Xiaomi 0.074958 | . _df6.rename(columns = {&#39;value&#39;:&#39;2019&#39;}). plot.pie(y = &#39;2019&#39;, figsize = (7, 7)) . &lt;AxesSubplot:ylabel=&#39;2019&#39;&gt; . (5) . df7 = df6.set_index(&#39;Date&#39;).stack().reset_index().rename(columns = {&#39;level_1&#39;:&#39;variable&#39;, 0:&#39;value&#39;}). groupby(&#39;Date&#39;).agg(&#39;sum&#39;).reset_index() . df7 . Date value . 0 2019-10 | 1559 | . 1 2019-11 | 1635 | . 2 2019-12 | 1542 | . 3 2020-01 | 2176 | . 4 2020-02 | 2138 | . 5 2020-03 | 2182 | . 6 2020-04 | 2138 | . 7 2020-05 | 2113 | . 8 2020-06 | 2183 | . 9 2020-07 | 2059 | . 10 2020-08 | 2165 | . 11 2020-09 | 2139 | . 12 2020-10 | 2165 | . df7.Date = df7.Date.apply(lambda x: str(x)[:4]) . df7 . Date value . 0 2019 | 1559 | . 1 2019 | 1635 | . 2 2019 | 1542 | . 3 2020 | 2176 | . 4 2020 | 2138 | . 5 2020 | 2182 | . 6 2020 | 2138 | . 7 2020 | 2113 | . 8 2020 | 2183 | . 9 2020 | 2059 | . 10 2020 | 2165 | . 11 2020 | 2139 | . 12 2020 | 2165 | . df7.groupby(&#39;Date&#39;).agg(&#39;mean&#39;). plot.bar() . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . 7 . (1) . import matplotlib matplotlib.rcParams[&#39;font.family&#39;] = &#39;Malgun Gothic&#39; # 한글이 깨지지 않도록 설정 matplotlib.rcParams[&#39;axes.unicode_minus&#39;] = False # 한글이 깨지지 않도록 설정 . df7 = pd.read_html(&#39;https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%B8%EA%B5%AC&#39;)[17] df7 . 지역 출생아 수(천명) 조출생률 합계출산율 거주인구(2021년 주민등록 인구) . 0 서울 | 47.4 | 5.0 | 0.64 | 9588711 | . 1 부산 | 15.1 | 4.5 | 0.75 | 3369704 | . 2 대구 | 11.2 | 4.6 | 0.81 | 2406296 | . 3 대전 | 7.5 | 5.1 | 0.81 | 1457619 | . 4 광주 | 7.3 | 5.1 | 0.81 | 1444787 | . 5 인천 | 16.0 | 5.5 | 0.83 | 2936214 | . 6 경기도 | 77.8 | 5.9 | 0.88 | 13479798 | . 7 전라북도 | 8.2 | 4.5 | 0.91 | 1796331 | . 8 경상남도 | 16.8 | 5.1 | 0.95 | 3329623 | . 9 충청북도 | 8.6 | 5.4 | 0.98 | 1596303 | . 10 울산 | 6.6 | 5.8 | 0.99 | 1128163 | . 11 경상북도 | 12.9 | 4.9 | 1.00 | 2635896 | . 12 제주도 | 4.0 | 6.0 | 1.02 | 674484 | . 13 충청남도 | 11.9 | 5.7 | 1.03 | 2116452 | . 14 강원도 | 7.8 | 5.1 | 1.04 | 1536175 | . 15 전라남도 | 9.7 | 5.3 | 1.15 | 1844148 | . 16 세종 | 3.5 | 10.0 | 1.28 | 361396 | . 17 대한민국(전체) | 272.4 | 5.3 | 0.84 | 51702100 | . df7.iloc[:-1, :].set_index(&#39;지역&#39;) . 출생아 수(천명) 조출생률 합계출산율 거주인구(2021년 주민등록 인구) . 지역 . 서울 47.4 | 5.0 | 0.64 | 9588711 | . 부산 15.1 | 4.5 | 0.75 | 3369704 | . 대구 11.2 | 4.6 | 0.81 | 2406296 | . 대전 7.5 | 5.1 | 0.81 | 1457619 | . 광주 7.3 | 5.1 | 0.81 | 1444787 | . 인천 16.0 | 5.5 | 0.83 | 2936214 | . 경기도 77.8 | 5.9 | 0.88 | 13479798 | . 전라북도 8.2 | 4.5 | 0.91 | 1796331 | . 경상남도 16.8 | 5.1 | 0.95 | 3329623 | . 충청북도 8.6 | 5.4 | 0.98 | 1596303 | . 울산 6.6 | 5.8 | 0.99 | 1128163 | . 경상북도 12.9 | 4.9 | 1.00 | 2635896 | . 제주도 4.0 | 6.0 | 1.02 | 674484 | . 충청남도 11.9 | 5.7 | 1.03 | 2116452 | . 강원도 7.8 | 5.1 | 1.04 | 1536175 | . 전라남도 9.7 | 5.3 | 1.15 | 1844148 | . 세종 3.5 | 10.0 | 1.28 | 361396 | . df7.iloc[:-1, :].set_index(&#39;지역&#39;).plot.pie(y = &#39;출생아 수(천명)&#39;) . &lt;AxesSubplot:ylabel=&#39;출생아 수(천명)&#39;&gt; . (2) . df8 = pd.read_html(&#39;https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%B8%EA%B5%AC&#39;)[18] df8 . Unnamed: 0 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 . 0 전국 | 0.918 | 0.977 | 1.052 | 1.172 | 1.239 | 1.205 | 1.187 | 1.297 | 1.244 | 1.226 | 1.149 | 1.192 | 1.259 | 1.132 | 1.085 | 1.164 | 1.191 | 1.178 | 1.309 | . 1 서울특별시 | 0.717 | 0.761 | 0.836 | 0.940 | 1.001 | 0.983 | 0.968 | 1.059 | 1.014 | 1.015 | 0.962 | 1.010 | 1.068 | 0.980 | 0.932 | 1.015 | 1.014 | 1.006 | 1.111 | . 2 부산광역시 | 0.827 | 0.899 | 0.976 | 1.095 | 1.139 | 1.090 | 1.049 | 1.135 | 1.078 | 1.045 | 0.940 | 0.980 | 1.024 | 0.915 | 0.887 | 0.953 | 0.988 | 0.975 | 1.103 | . 3 대구광역시 | 0.932 | 0.987 | 1.067 | 1.186 | 1.216 | 1.169 | 1.127 | 1.217 | 1.146 | 1.109 | 1.029 | 1.072 | 1.137 | 1.011 | 1.001 | 1.087 | 1.116 | 1.076 | 1.216 | . 4 인천광역시 | 0.940 | 1.006 | 1.007 | 1.144 | 1.216 | 1.212 | 1.195 | 1.301 | 1.232 | 1.214 | 1.143 | 1.186 | 1.257 | 1.116 | 1.075 | 1.158 | 1.213 | 1.185 | 1.324 | . 5 광주광역시 | 0.913 | 0.972 | 1.053 | 1.168 | 1.207 | 1.199 | 1.170 | 1.295 | 1.234 | 1.223 | 1.137 | 1.198 | 1.262 | 1.152 | 1.105 | 1.203 | 1.278 | 1.264 | 1.421 | . 6 대전광역시 | 0.883 | 0.952 | 1.075 | 1.192 | 1.277 | 1.250 | 1.234 | 1.315 | 1.261 | 1.205 | 1.156 | 1.215 | 1.274 | 1.158 | 1.107 | 1.181 | 1.221 | 1.207 | 1.330 | . 7 울산광역시 | 1.084 | 1.131 | 1.261 | 1.418 | 1.486 | 1.437 | 1.391 | 1.481 | 1.393 | 1.369 | 1.308 | 1.338 | 1.403 | 1.242 | 1.186 | 1.241 | 1.280 | 1.242 | 1.423 | . 8 세종특별자치시 | 1.472 | 1.566 | 1.668 | 1.821 | 1.893 | 1.354 | 1.435 | 1.597 | - | - | - | - | - | - | - | - | - | - | - | . 9 경기도 | 0.943 | 1.002 | 1.069 | 1.194 | 1.272 | 1.241 | 1.226 | 1.355 | 1.314 | 1.309 | 1.226 | 1.285 | 1.361 | 1.239 | 1.183 | 1.280 | 1.321 | 1.305 | 1.437 | . 10 강원도 | 1.082 | 1.067 | 1.123 | 1.237 | 1.311 | 1.248 | 1.249 | 1.374 | 1.338 | 1.313 | 1.248 | 1.253 | 1.356 | 1.202 | 1.188 | 1.261 | 1.279 | 1.317 | 1.413 | . 11 충청북도 | 1.050 | 1.172 | 1.235 | 1.358 | 1.414 | 1.363 | 1.365 | 1.485 | 1.428 | 1.402 | 1.317 | 1.319 | 1.398 | 1.233 | 1.195 | 1.272 | 1.270 | 1.294 | 1.426 | . 12 충청남도 | 1.112 | 1.186 | 1.276 | 1.395 | 1.480 | 1.421 | 1.442 | 1.571 | 1.496 | 1.479 | 1.408 | 1.444 | 1.506 | 1.356 | 1.267 | 1.357 | 1.358 | 1.361 | 1.532 | . 13 전라북도 | 0.971 | 1.044 | 1.151 | 1.251 | 1.352 | 1.329 | 1.320 | 1.440 | 1.405 | 1.374 | 1.279 | 1.305 | 1.380 | 1.213 | 1.184 | 1.239 | 1.274 | 1.275 | 1.426 | . 14 전라남도 | 1.234 | 1.240 | 1.325 | 1.466 | 1.549 | 1.497 | 1.518 | 1.642 | 1.568 | 1.537 | 1.445 | 1.449 | 1.542 | 1.337 | 1.290 | 1.360 | 1.389 | 1.391 | 1.566 | . 15 경상북도 | 1.089 | 1.167 | 1.256 | 1.396 | 1.464 | 1.408 | 1.379 | 1.489 | 1.434 | 1.377 | 1.274 | 1.313 | 1.369 | 1.208 | 1.173 | 1.203 | 1.253 | 1.232 | 1.402 | . 16 경상남도 | 1.046 | 1.122 | 1.227 | 1.358 | 1.437 | 1.409 | 1.367 | 1.503 | 1.446 | 1.413 | 1.323 | 1.368 | 1.434 | 1.254 | 1.189 | 1.266 | 1.290 | 1.272 | 1.417 | . 17 제주특별자치도 | 1.145 | 1.220 | 1.305 | 1.432 | 1.477 | 1.481 | 1.427 | 1.598 | 1.487 | 1.463 | 1.378 | 1.386 | 1.489 | 1.372 | 1.310 | 1.365 | 1.438 | 1.394 | 1.564 | . df9 = df8.rename(columns = {&#39;Unnamed: 0&#39;:&#39;지역&#39;}).iloc[1:, :]. sort_values(&#39;지역&#39;).set_index(&#39;지역&#39;). applymap(lambda x: float(x) if x != &#39;-&#39; else 0) df9 . 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 . 지역 . 강원도 1.082 | 1.067 | 1.123 | 1.237 | 1.311 | 1.248 | 1.249 | 1.374 | 1.338 | 1.313 | 1.248 | 1.253 | 1.356 | 1.202 | 1.188 | 1.261 | 1.279 | 1.317 | 1.413 | . 경기도 0.943 | 1.002 | 1.069 | 1.194 | 1.272 | 1.241 | 1.226 | 1.355 | 1.314 | 1.309 | 1.226 | 1.285 | 1.361 | 1.239 | 1.183 | 1.280 | 1.321 | 1.305 | 1.437 | . 경상남도 1.046 | 1.122 | 1.227 | 1.358 | 1.437 | 1.409 | 1.367 | 1.503 | 1.446 | 1.413 | 1.323 | 1.368 | 1.434 | 1.254 | 1.189 | 1.266 | 1.290 | 1.272 | 1.417 | . 경상북도 1.089 | 1.167 | 1.256 | 1.396 | 1.464 | 1.408 | 1.379 | 1.489 | 1.434 | 1.377 | 1.274 | 1.313 | 1.369 | 1.208 | 1.173 | 1.203 | 1.253 | 1.232 | 1.402 | . 광주광역시 0.913 | 0.972 | 1.053 | 1.168 | 1.207 | 1.199 | 1.170 | 1.295 | 1.234 | 1.223 | 1.137 | 1.198 | 1.262 | 1.152 | 1.105 | 1.203 | 1.278 | 1.264 | 1.421 | . 대구광역시 0.932 | 0.987 | 1.067 | 1.186 | 1.216 | 1.169 | 1.127 | 1.217 | 1.146 | 1.109 | 1.029 | 1.072 | 1.137 | 1.011 | 1.001 | 1.087 | 1.116 | 1.076 | 1.216 | . 대전광역시 0.883 | 0.952 | 1.075 | 1.192 | 1.277 | 1.250 | 1.234 | 1.315 | 1.261 | 1.205 | 1.156 | 1.215 | 1.274 | 1.158 | 1.107 | 1.181 | 1.221 | 1.207 | 1.330 | . 부산광역시 0.827 | 0.899 | 0.976 | 1.095 | 1.139 | 1.090 | 1.049 | 1.135 | 1.078 | 1.045 | 0.940 | 0.980 | 1.024 | 0.915 | 0.887 | 0.953 | 0.988 | 0.975 | 1.103 | . 서울특별시 0.717 | 0.761 | 0.836 | 0.940 | 1.001 | 0.983 | 0.968 | 1.059 | 1.014 | 1.015 | 0.962 | 1.010 | 1.068 | 0.980 | 0.932 | 1.015 | 1.014 | 1.006 | 1.111 | . 세종특별자치시 1.472 | 1.566 | 1.668 | 1.821 | 1.893 | 1.354 | 1.435 | 1.597 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | . 울산광역시 1.084 | 1.131 | 1.261 | 1.418 | 1.486 | 1.437 | 1.391 | 1.481 | 1.393 | 1.369 | 1.308 | 1.338 | 1.403 | 1.242 | 1.186 | 1.241 | 1.280 | 1.242 | 1.423 | . 인천광역시 0.940 | 1.006 | 1.007 | 1.144 | 1.216 | 1.212 | 1.195 | 1.301 | 1.232 | 1.214 | 1.143 | 1.186 | 1.257 | 1.116 | 1.075 | 1.158 | 1.213 | 1.185 | 1.324 | . 전라남도 1.234 | 1.240 | 1.325 | 1.466 | 1.549 | 1.497 | 1.518 | 1.642 | 1.568 | 1.537 | 1.445 | 1.449 | 1.542 | 1.337 | 1.290 | 1.360 | 1.389 | 1.391 | 1.566 | . 전라북도 0.971 | 1.044 | 1.151 | 1.251 | 1.352 | 1.329 | 1.320 | 1.440 | 1.405 | 1.374 | 1.279 | 1.305 | 1.380 | 1.213 | 1.184 | 1.239 | 1.274 | 1.275 | 1.426 | . 제주특별자치도 1.145 | 1.220 | 1.305 | 1.432 | 1.477 | 1.481 | 1.427 | 1.598 | 1.487 | 1.463 | 1.378 | 1.386 | 1.489 | 1.372 | 1.310 | 1.365 | 1.438 | 1.394 | 1.564 | . 충청남도 1.112 | 1.186 | 1.276 | 1.395 | 1.480 | 1.421 | 1.442 | 1.571 | 1.496 | 1.479 | 1.408 | 1.444 | 1.506 | 1.356 | 1.267 | 1.357 | 1.358 | 1.361 | 1.532 | . 충청북도 1.050 | 1.172 | 1.235 | 1.358 | 1.414 | 1.363 | 1.365 | 1.485 | 1.428 | 1.402 | 1.317 | 1.319 | 1.398 | 1.233 | 1.195 | 1.272 | 1.270 | 1.294 | 1.426 | . lst = df7.iloc[:-1, :].sort_values(&#39;지역&#39;).loc[:, [&#39;지역&#39;, &#39;합계출산율&#39;]]. rename(columns = {&#39;합계출산율&#39;:&#39;2020&#39;}).set_index(&#39;지역&#39;).index.tolist() lst . [&#39;강원도&#39;, &#39;경기도&#39;, &#39;경상남도&#39;, &#39;경상북도&#39;, &#39;광주&#39;, &#39;대구&#39;, &#39;대전&#39;, &#39;부산&#39;, &#39;서울&#39;, &#39;세종&#39;, &#39;울산&#39;, &#39;인천&#39;, &#39;전라남도&#39;, &#39;전라북도&#39;, &#39;제주도&#39;, &#39;충청남도&#39;, &#39;충청북도&#39;] . - matplotlib 사용(untidy data) . df7.iloc[:-1, :].sort_values(&#39;지역&#39;).loc[:, [&#39;지역&#39;, &#39;합계출산율&#39;]]. rename(columns = {&#39;합계출산율&#39;:&#39;2020&#39;}).set_index(&#39;지역&#39;). rename(index = dict(zip(lst, df9.index))).reset_index(). merge(df9.reset_index()).set_index(&#39;지역&#39;).T. plot.line(figsize = (10, 6)) . &lt;AxesSubplot:&gt; . - plotly 사용(tidy data) . # rename(columns = {&#39;합계출산율&#39;:&#39;2020&#39;}).set_index(&#39;지역&#39;). # rename(index = dict(zip(lst, df9.index))).reset_index(). # merge(df9.reset_index()).melt(id_vars = &#39;지역&#39;). # rename(columns = {&#39;variable&#39;:&#39;year&#39;, &#39;value&#39;:&#39;birth_rate&#39;}). # plot.line(x = &#39;year&#39;, y =&#39;birth_rate&#39;, color = &#39;지역&#39;, backend = &#39;plotly&#39;) .",
            "url": "https://jaesu26.github.io/green/python/2021/12/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC.html",
            "relUrl": "/python/2021/12/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EA%B8%B0%EB%A7%90%EA%B3%A0%EC%82%AC.html",
            "date": " • Dec 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "데이터시각화 중간고사",
            "content": "- 시험문제 : https://guebin.github.io/2021STDV/2021/11/07/mid.html . - 문제에 대한 나의 풀이(틀릴 수 있음) . import pandas as pd import numpy as np from plotnine import * import matplotlib.pyplot as plt import seaborn as sns . 1 . - (a)-(c) . - (b)-(d) . 2 . x = [1, 2, 3, 4] y = [1, 2, 4, 3] . fig, axs = plt.subplots(2,2) . (ax1, ax2), (ax3, ax4) = axs . ax1.plot(x, y, &#39;o:r&#39;) ax2.plot(x, y, &#39;Xb&#39;) ax3.plot(x, y, &#39;xm&#39;) ax4.plot(x, y, &#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x25605a16100&gt;] . fig . 3 . - 하니, 홍두깨, 고은애, 이창수 . 4 . - 하니, 홍두깨, 고은애 . 5 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) . df.head() . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 212198 | Bruno Fernandes | 26 | https://cdn.sofifa.com/players/212/198/22_60.png | Portugal | https://cdn.sofifa.com/flags/pt.png | 88 | 89 | Manchester United | https://cdn.sofifa.com/teams/11/30.png | ... | 65.0 | 12.0 | 14.0 | 15.0 | 8.0 | 14.0 | CAM | 88.0 | €206.9M | 72.0 | . 1 209658 | L. Goretzka | 26 | https://cdn.sofifa.com/players/209/658/22_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 87 | 88 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 77.0 | 13.0 | 8.0 | 15.0 | 11.0 | 9.0 | CM | 87.0 | €160.4M | 74.0 | . 2 176580 | L. Suárez | 34 | https://cdn.sofifa.com/players/176/580/22_60.png | Uruguay | https://cdn.sofifa.com/flags/uy.png | 88 | 88 | Atlético de Madrid | https://cdn.sofifa.com/teams/240/30.png | ... | 38.0 | 27.0 | 25.0 | 31.0 | 33.0 | 37.0 | ST | 88.0 | €91.2M | 42.0 | . 3 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | https://cdn.sofifa.com/teams/10/30.png | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 224334 | M. Acuña | 29 | https://cdn.sofifa.com/players/224/334/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 84 | 84 | Sevilla FC | https://cdn.sofifa.com/teams/481/30.png | ... | 82.0 | 8.0 | 14.0 | 13.0 | 13.0 | 14.0 | LB | 84.0 | €77.7M | 80.0 | . 5 rows × 65 columns . (a) . df[&#39;Loaned From&#39;] . 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN ... 16705 NaN 16706 NaN 16707 NaN 16708 NaN 16709 NaN Name: Loaned From, Length: 16710, dtype: object . df[&#39;Loaned From&#39;].isnull().sum() . 15578 . df[&#39;Marking&#39;] . 0 NaN 1 NaN 2 NaN 3 NaN 4 NaN ... 16705 5.0 16706 NaN 16707 NaN 16708 NaN 16709 15.0 Name: Marking, Length: 16710, dtype: float64 . df[&#39;Marking&#39;].isnull().sum() . 15818 . - 결측치가 많다 . (b) . df = df.drop([&#39;Loaned From&#39;, &#39;Marking&#39;], axis = 1) . df.isnull().sum().sum() . 5404 . (c) . df = df.dropna() . df.isnull().sum().sum() . 0 . - 5404개의 결측치가 제거되었다 . (d) . def convert_currency(value): floatvalue = 0.0 strvalue=&quot;&quot; if &quot;M&quot; in value: strvalue=value.replace(&quot;M&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000000) elif &quot;K&quot; in value: strvalue=value.replace(&quot;K&quot;,&quot;&quot;).replace(&quot;€&quot;,&quot;&quot;) floatvalue=float(float(strvalue)*1000) else: floatvalue=value.replace(&quot;€&quot;,&quot;&quot;) return floatvalue . - 코드출처: https://www.kaggle.com/talhademirezen/cost-effective-youth-players-fifa22 . df[&#39;Wage&#39;] = list(map(convert_currency, df[&#39;Wage&#39;])) . df[&#39;Wage&#39;] . 0 250000.0 1 140000.0 2 135000.0 3 350000.0 4 45000.0 ... 16703 650 16704 950 16706 550 16707 700 16708 500 Name: Wage, Length: 14398, dtype: object . (e) . df[&#39;Value&#39;] = list(map(convert_currency, df[&#39;Value&#39;])) . df2 = df.groupby(by = &#39;Best Position&#39;).agg({&#39;Value&#39;:np.mean}) . - 신기한점 : 컴퓨터마다(?) &#39;Value&#39;가 object 타입인지 float 타입인지가 다른것같다 . - 나의 경우는 자료형을 변환하지 않아도 위와 같이 잘되는데 안되는 경우도 있나봄 . df2 . Value . Best Position . CAM 4.356162e+06 | . CB 3.038834e+06 | . CDM 3.539740e+06 | . CF 9.122222e+06 | . CM 5.630414e+06 | . GK 2.703686e+06 | . LB 3.051887e+06 | . LM 3.439977e+06 | . LW 6.443137e+06 | . LWB 3.451340e+06 | . RB 3.203283e+06 | . RM 2.550153e+06 | . RW 3.977832e+06 | . RWB 3.023522e+06 | . ST 3.295080e+06 | . df2 = df2.stack().reset_index() . df2 = df2.rename(columns={&#39;level_1&#39;:&#39;group1&#39;, 0:&#39;mean(Value)&#39;}) . df2 . Best Position group1 mean(Value) . 0 CAM | Value | 4.356162e+06 | . 1 CB | Value | 3.038834e+06 | . 2 CDM | Value | 3.539740e+06 | . 3 CF | Value | 9.122222e+06 | . 4 CM | Value | 5.630414e+06 | . 5 GK | Value | 2.703686e+06 | . 6 LB | Value | 3.051887e+06 | . 7 LM | Value | 3.439977e+06 | . 8 LW | Value | 6.443137e+06 | . 9 LWB | Value | 3.451340e+06 | . 10 RB | Value | 3.203283e+06 | . 11 RM | Value | 2.550153e+06 | . 12 RW | Value | 3.977832e+06 | . 13 RWB | Value | 3.023522e+06 | . 14 ST | Value | 3.295080e+06 | . df2 = df2.sort_values(by = [&#39;mean(Value)&#39;], axis = 0, ascending = False) . df2 = df2.reset_index(drop = True) . df2 . Best Position group1 mean(Value) . 0 CF | Value | 9.122222e+06 | . 1 LW | Value | 6.443137e+06 | . 2 CM | Value | 5.630414e+06 | . 3 CAM | Value | 4.356162e+06 | . 4 RW | Value | 3.977832e+06 | . 5 CDM | Value | 3.539740e+06 | . 6 LWB | Value | 3.451340e+06 | . 7 LM | Value | 3.439977e+06 | . 8 ST | Value | 3.295080e+06 | . 9 RB | Value | 3.203283e+06 | . 10 LB | Value | 3.051887e+06 | . 11 CB | Value | 3.038834e+06 | . 12 RWB | Value | 3.023522e+06 | . 13 GK | Value | 2.703686e+06 | . 14 RM | Value | 2.550153e+06 | . cnt = 0 . def z(x): global cnt cnt += 1 if cnt &lt;= 3: return &#39;True&#39; else: return &#39;False&#39; . df2[&#39;Highlight&#39;] = list(map(z, df2[&#39;mean(Value)&#39;])) . df2 . Best Position group1 mean(Value) Highlight . 0 CF | Value | 9.122222e+06 | True | . 1 LW | Value | 6.443137e+06 | True | . 2 CM | Value | 5.630414e+06 | True | . 3 CAM | Value | 4.356162e+06 | False | . 4 RW | Value | 3.977832e+06 | False | . 5 CDM | Value | 3.539740e+06 | False | . 6 LWB | Value | 3.451340e+06 | False | . 7 LM | Value | 3.439977e+06 | False | . 8 ST | Value | 3.295080e+06 | False | . 9 RB | Value | 3.203283e+06 | False | . 10 LB | Value | 3.051887e+06 | False | . 11 CB | Value | 3.038834e+06 | False | . 12 RWB | Value | 3.023522e+06 | False | . 13 GK | Value | 2.703686e+06 | False | . 14 RM | Value | 2.550153e+06 | False | . ggplot(df2) + geom_bar(aes(x = &#39;Best Position&#39;, y = &#39;mean(Value)&#39;, fill = &#39;Highlight&#39;), stat = &#39;identity&#39;) . &lt;ggplot: (160530408406)&gt; . (f) . - 문제는 alpha = 0.5로 하라고 했는데 시각화 예시는 alpha = 0.2임... . ggplot(df) + geom_point(aes(x = &#39;Dribbling&#39;, y = &#39;SlidingTackle&#39;, color = &#39;Age&#39;), alpha = 0.5, size = 0.5) + facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (160533279925)&gt; . (g) . - 하니, 홍두깨, 고은애 . (h) . df3 = df.loc[lambda df:(df[&#39;Best Position&#39;] ==&#39;CAM&#39;) | (df[&#39;Best Position&#39;] ==&#39;CB&#39;)] . - 이유는 모르겠는데 query로는 안되서 위와 같이 했음 . - 문제에는 CB가 아니라 CM인데 plot은 CB로 되어있어서 CB로 했음 + (i)문제에서도 CB라고 언급함 . ggplot(df3) + geom_point(aes(x = &#39;Dribbling&#39;, y = &#39;SlidingTackle&#39;, color = &#39;Age&#39;, size = &#39;Value&#39;), alpha = 0.2 ) + facet_wrap(&#39;Best Position&#39;) . &lt;ggplot: (160531860947)&gt; . (i) . - 홍두깨 . 6 . x = [0, 1, 4, 5] y = [0, 2, 3, 5] x2 = [5, 4.1, 1, 0] y2 = [5, 3, 0.5, 0] . df_ = pd.DataFrame({&#39;x&#39;:x ,&#39;y&#39;:y}) . df_[&#39;course&#39;] = &#39;A&#39; . df_ . x y course . 0 0 | 0 | A | . 1 1 | 2 | A | . 2 4 | 3 | A | . 3 5 | 5 | A | . df2_ = pd.DataFrame({&#39;x&#39;:x2 ,&#39;y&#39;:y2}) . df2_[&#39;course&#39;] = &#39;B&#39; . df2_ . x y course . 0 5.0 | 5.0 | B | . 1 4.1 | 3.0 | B | . 2 1.0 | 0.5 | B | . 3 0.0 | 0.0 | B | . stamina = 100 ## 집에서 출발시 체력 x_ = 0 y_ = 0 def f(x,y): global x_ global y_ global stamina stamina = stamina - (((x-x_)**2 + (y-y_)**2)**0.5) ## 두 점 사이의 거리 x_ = x y_ = y return stamina . df_[&#39;stamina&#39;] = list(map(f, df_[&#39;x&#39;], df_[&#39;y&#39;])) . df_ . x y course stamina . 0 0 | 0 | A | 100.000000 | . 1 1 | 2 | A | 97.763932 | . 2 4 | 3 | A | 94.601654 | . 3 5 | 5 | A | 92.365586 | . stamina -= 70 ## A지점 도착지점에서 B지점 출발지점까지 가는데 70이 소모됨 . df2_[&#39;stamina&#39;] = list(map(f, df2_[&#39;x&#39;], df2_[&#39;y&#39;])) . df2_ . x y course stamina . 0 5.0 | 5.0 | B | 22.365586 | . 1 4.1 | 3.0 | B | 20.172415 | . 2 1.0 | 0.5 | B | 16.189954 | . 3 0.0 | 0.0 | B | 15.071920 | . df3_ = pd.concat([df_, df2_]) ## 두 데이터프레임 합치기 . df3_ . x y course stamina . 0 0.0 | 0.0 | A | 100.000000 | . 1 1.0 | 2.0 | A | 97.763932 | . 2 4.0 | 3.0 | A | 94.601654 | . 3 5.0 | 5.0 | A | 92.365586 | . 0 5.0 | 5.0 | B | 22.365586 | . 1 4.1 | 3.0 | B | 20.172415 | . 2 1.0 | 0.5 | B | 16.189954 | . 3 0.0 | 0.0 | B | 15.071920 | . ggplot(df3_) + geom_point(aes(x = &#39;x&#39;, y = &#39;y&#39;)) + geom_line(aes(x = &#39;x&#39;, y = &#39;y&#39;, size = &#39;stamina&#39;, color = &#39;course&#39;), alpha = 0.5) . &lt;ggplot: (160530609351)&gt; . 7 . - 문제 풀고나니 느낀건데 국어를 너무 못함 &gt; 문제를 제대로 파악을 못함 . p = [&#39;A&#39;] * 2 + [&#39;B&#39;] * 2 s1 = [10, 20, 30, 4] s2 = [7, 19, 23, 4] s3 = [&#39;one&#39;, &#39;two&#39;] * 2 . data = pd.DataFrame({&#39;person&#39;:p, &#39;count&#39;:s1, &#39;goal&#39;:s2, &#39;season&#39;:s3}) . data . person count goal season . 0 A | 10 | 7 | one | . 1 A | 20 | 19 | two | . 2 B | 30 | 23 | one | . 3 B | 4 | 4 | two | . data[&#39;prob&#39;] = data[&#39;goal&#39;] / data[&#39;count&#39;] . data . person count goal season prob . 0 A | 10 | 7 | one | 0.700000 | . 1 A | 20 | 19 | two | 0.950000 | . 2 B | 30 | 23 | one | 0.766667 | . 3 B | 4 | 4 | two | 1.000000 | . data2 = data.groupby([&#39;person&#39;]).agg({&#39;count&#39;:np.sum, &#39;goal&#39;:np.sum}).reset_index().rename(columns = {&#39;count&#39;:&#39;sum&#39;, &#39;goal&#39;:&#39;goal_sum&#39;}) . data2 . person sum goal_sum . 0 A | 30 | 26 | . 1 B | 34 | 27 | . td = pd.merge(data, data2) . td . person count goal season prob sum goal_sum . 0 A | 10 | 7 | one | 0.700000 | 30 | 26 | . 1 A | 20 | 19 | two | 0.950000 | 30 | 26 | . 2 B | 30 | 23 | one | 0.766667 | 34 | 27 | . 3 B | 4 | 4 | two | 1.000000 | 34 | 27 | . td[&#39;prob2&#39;] = (td[&#39;goal_sum&#39;] / td[&#39;sum&#39;]) / 2 ## 시즌이 2개라 값이 2번 들어가서 2로 나눠줌 . td . person count goal season prob sum goal_sum prob2 . 0 A | 10 | 7 | one | 0.700000 | 30 | 26 | 0.433333 | . 1 A | 20 | 19 | two | 0.950000 | 30 | 26 | 0.433333 | . 2 B | 30 | 23 | one | 0.766667 | 34 | 27 | 0.397059 | . 3 B | 4 | 4 | two | 1.000000 | 34 | 27 | 0.397059 | . ggplot(data) + geom_bar(aes(x = &#39;person&#39;, y = &#39;prob&#39;, fill = &#39;person&#39;), stat = &#39;identity&#39;) + facet_wrap(&#39;season&#39;) . &lt;ggplot: (160530787118)&gt; . - 시즌별 성공확률은 B가 더 높다 . - 하지만 전체 성공확률을 보면? . ggplot(td) + geom_bar(aes(x = &#39;person&#39;, y = &#39;prob2&#39;, fill = &#39;person&#39;), stat = &#39;identity&#39;) . &lt;ggplot: (160532310432)&gt; . - A가 더 높은것을 확인할수있다 . - B가 100%확률을 기록했을 때 전체횟수가 모종의 이유(부상 치료 등)로 인해 4회밖에 되지않아 전체에 끼치는 영향력이 작아져 위와같은 결과가 발생했다 .",
            "url": "https://jaesu26.github.io/green/python/2021/11/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%A4%91%EA%B0%84%EC%8B%9C%ED%97%98.html",
            "relUrl": "/python/2021/11/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94%EC%A4%91%EA%B0%84%EC%8B%9C%ED%97%98.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "데이터시각화 중간고사 연습문제",
            "content": "- 시험문제 : https://guebin.github.io/2021DV/2021/11/05/(A2)-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC-%EB%8C%80%EB%B9%84%EB%AC%B8%EC%A0%9C.html . import pandas as pd import numpy as np from plotnine import * import matplotlib.pyplot as plt import seaborn as sns . - 흠 20분 걸렸는데... 조금 느리다 . Type I. &#54532;&#47196;&#44536;&#47016; &#44396;&#54788;&#45733;&#47141; &#54217;&#44032; . np.random.seed(202016248) . x1 = np.random.normal(0, 1, 10000) x2 = np.random.normal(1, 1, 10000) . sns.histplot([x1, x2]) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . x = [1, 2, 3, 4] y = [1, 2, 4, 3] . fig, axs = plt.subplots(2,2) . (ax1, ax2), (ax3, ax4) = axs . ax1.plot(x, y, &#39;o:r&#39;) ax2.plot(x, y, &#39;Xb&#39;) ax3.plot(x, y, &#39;xm&#39;) ax4.plot(x, y, &#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x1f9133fc730&gt;] . fig . Type II. &#44060;&#45392;&#51032; &#51060;&#54644; &#54217;&#44032; . (1) 하니, 홍두깨 . (2) 하니, 나애리 . Type III. &#51088;&#47308;&#48516;&#49437; &#48143; &#49884;&#44033;&#54868; &#45733;&#47141; &#51333;&#54633;&#54217;&#44032; . df = pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/employee.csv&#39;) df . UNIQUE_ID POSITION_TITLE DEPARTMENT BASE_SALARY RACE EMPLOYMENT_TYPE GENDER EMPLOYMENT_STATUS HIRE_DATE JOB_DATE . 0 0 | ASSISTANT DIRECTOR (EX LVL) | Municipal Courts Department | 121862.0 | Hispanic/Latino | Full Time | Female | Active | 2006-06-12 | 2012-10-13 | . 1 1 | LIBRARY ASSISTANT | Library | 26125.0 | Hispanic/Latino | Full Time | Female | Active | 2000-07-19 | 2010-09-18 | . 2 2 | POLICE OFFICER | Houston Police Department-HPD | 45279.0 | White | Full Time | Male | Active | 2015-02-03 | 2015-02-03 | . 3 3 | ENGINEER/OPERATOR | Houston Fire Department (HFD) | 63166.0 | White | Full Time | Male | Active | 1982-02-08 | 1991-05-25 | . 4 4 | ELECTRICIAN | General Services Department | 56347.0 | White | Full Time | Male | Active | 1989-06-19 | 1994-10-22 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1995 1995 | POLICE OFFICER | Houston Police Department-HPD | 43443.0 | White | Full Time | Male | Active | 2014-06-09 | 2015-06-09 | . 1996 1996 | COMMUNICATIONS CAPTAIN | Houston Fire Department (HFD) | 66523.0 | Black or African American | Full Time | Male | Active | 2003-09-02 | 2013-10-06 | . 1997 1997 | POLICE OFFICER | Houston Police Department-HPD | 43443.0 | White | Full Time | Male | Active | 2014-10-13 | 2015-10-13 | . 1998 1998 | POLICE OFFICER | Houston Police Department-HPD | 55461.0 | Asian/Pacific Islander | Full Time | Male | Active | 2009-01-20 | 2011-07-02 | . 1999 1999 | FIRE FIGHTER | Houston Fire Department (HFD) | 51194.0 | Hispanic/Latino | Full Time | Male | Active | 2009-01-12 | 2010-07-12 | . 2000 rows × 10 columns . (a) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 2000 entries, 0 to 1999 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 UNIQUE_ID 2000 non-null int64 1 POSITION_TITLE 2000 non-null object 2 DEPARTMENT 2000 non-null object 3 BASE_SALARY 1886 non-null float64 4 RACE 1965 non-null object 5 EMPLOYMENT_TYPE 2000 non-null object 6 GENDER 2000 non-null object 7 EMPLOYMENT_STATUS 2000 non-null object 8 HIRE_DATE 2000 non-null object 9 JOB_DATE 1997 non-null object dtypes: float64(1), int64(1), object(8) memory usage: 156.4+ KB . df.isnull().sum() . UNIQUE_ID 0 POSITION_TITLE 0 DEPARTMENT 0 BASE_SALARY 114 RACE 35 EMPLOYMENT_TYPE 0 GENDER 0 EMPLOYMENT_STATUS 0 HIRE_DATE 0 JOB_DATE 3 dtype: int64 . df.isnull().sum().sum() . 152 . df = df.dropna() . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1853 entries, 0 to 1999 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 UNIQUE_ID 1853 non-null int64 1 POSITION_TITLE 1853 non-null object 2 DEPARTMENT 1853 non-null object 3 BASE_SALARY 1853 non-null float64 4 RACE 1853 non-null object 5 EMPLOYMENT_TYPE 1853 non-null object 6 GENDER 1853 non-null object 7 EMPLOYMENT_STATUS 1853 non-null object 8 HIRE_DATE 1853 non-null object 9 JOB_DATE 1853 non-null object dtypes: float64(1), int64(1), object(8) memory usage: 159.2+ KB . df.isnull().sum() . UNIQUE_ID 0 POSITION_TITLE 0 DEPARTMENT 0 BASE_SALARY 0 RACE 0 EMPLOYMENT_TYPE 0 GENDER 0 EMPLOYMENT_STATUS 0 HIRE_DATE 0 JOB_DATE 0 dtype: int64 . df.isnull().sum().sum() . 0 . (b) . df_ = df.groupby(by = &#39;GENDER&#39;).agg({&#39;BASE_SALARY&#39;:np.mean}) df_ . BASE_SALARY . GENDER . Female 52474.665487 | . Male 57670.031832 | . df_ = df_.stack().reset_index() df_ . GENDER level_1 0 . 0 Female | BASE_SALARY | 52474.665487 | . 1 Male | BASE_SALARY | 57670.031832 | . (df_.query(&#39;GENDER == &quot;Female&quot;&#39;))[0].to_list() &gt; (df_.query(&#39;GENDER == &quot;Male&quot;&#39;))[0].to_list() . False . - 남자 급여평균이 더 크다 . (c) . df2 = df.groupby(by = [&#39;RACE&#39;,&#39;GENDER&#39;]).agg({&#39;BASE_SALARY&#39;:[np.mean, min, max]}) . df2 . BASE_SALARY . mean min max . RACE GENDER . American Indian or Alaskan Native Female 60238.800000 | 26125.0 | 98536.0 | . Male 60305.400000 | 26125.0 | 81239.0 | . Asian/Pacific Islander Female 63226.300000 | 26125.0 | 130416.0 | . Male 61033.906667 | 27914.0 | 163228.0 | . Black or African American Female 48965.790378 | 24960.0 | 150416.0 | . Male 51118.867374 | 26125.0 | 275000.0 | . Hispanic/Latino Female 46503.316176 | 26125.0 | 126115.0 | . Male 54767.541538 | 26104.0 | 165216.0 | . Others Female 63785.000000 | 63785.0 | 63785.0 | . Male 38771.000000 | 38771.0 | 38771.0 | . White Female 66793.352941 | 27955.0 | 178331.0 | . Male 63940.388119 | 26125.0 | 210588.0 | . - tidydata로 만들자! . df2.stack() . BASE_SALARY . RACE GENDER . American Indian or Alaskan Native Female mean 60238.800000 | . min 26125.000000 | . max 98536.000000 | . Male mean 60305.400000 | . min 26125.000000 | . max 81239.000000 | . Asian/Pacific Islander Female mean 63226.300000 | . min 26125.000000 | . max 130416.000000 | . Male mean 61033.906667 | . min 27914.000000 | . max 163228.000000 | . Black or African American Female mean 48965.790378 | . min 24960.000000 | . max 150416.000000 | . Male mean 51118.867374 | . min 26125.000000 | . max 275000.000000 | . Hispanic/Latino Female mean 46503.316176 | . min 26125.000000 | . max 126115.000000 | . Male mean 54767.541538 | . min 26104.000000 | . max 165216.000000 | . Others Female mean 63785.000000 | . min 63785.000000 | . max 63785.000000 | . Male mean 38771.000000 | . min 38771.000000 | . max 38771.000000 | . White Female mean 66793.352941 | . min 27955.000000 | . max 178331.000000 | . Male mean 63940.388119 | . min 26125.000000 | . max 210588.000000 | . df3 = df2.stack().reset_index().rename(columns={&#39;level_2&#39;:&#39;aggtype&#39;}) . df3 . RACE GENDER aggtype BASE_SALARY . 0 American Indian or Alaskan Native | Female | mean | 60238.800000 | . 1 American Indian or Alaskan Native | Female | min | 26125.000000 | . 2 American Indian or Alaskan Native | Female | max | 98536.000000 | . 3 American Indian or Alaskan Native | Male | mean | 60305.400000 | . 4 American Indian or Alaskan Native | Male | min | 26125.000000 | . 5 American Indian or Alaskan Native | Male | max | 81239.000000 | . 6 Asian/Pacific Islander | Female | mean | 63226.300000 | . 7 Asian/Pacific Islander | Female | min | 26125.000000 | . 8 Asian/Pacific Islander | Female | max | 130416.000000 | . 9 Asian/Pacific Islander | Male | mean | 61033.906667 | . 10 Asian/Pacific Islander | Male | min | 27914.000000 | . 11 Asian/Pacific Islander | Male | max | 163228.000000 | . 12 Black or African American | Female | mean | 48965.790378 | . 13 Black or African American | Female | min | 24960.000000 | . 14 Black or African American | Female | max | 150416.000000 | . 15 Black or African American | Male | mean | 51118.867374 | . 16 Black or African American | Male | min | 26125.000000 | . 17 Black or African American | Male | max | 275000.000000 | . 18 Hispanic/Latino | Female | mean | 46503.316176 | . 19 Hispanic/Latino | Female | min | 26125.000000 | . 20 Hispanic/Latino | Female | max | 126115.000000 | . 21 Hispanic/Latino | Male | mean | 54767.541538 | . 22 Hispanic/Latino | Male | min | 26104.000000 | . 23 Hispanic/Latino | Male | max | 165216.000000 | . 24 Others | Female | mean | 63785.000000 | . 25 Others | Female | min | 63785.000000 | . 26 Others | Female | max | 63785.000000 | . 27 Others | Male | mean | 38771.000000 | . 28 Others | Male | min | 38771.000000 | . 29 Others | Male | max | 38771.000000 | . 30 White | Female | mean | 66793.352941 | . 31 White | Female | min | 27955.000000 | . 32 White | Female | max | 178331.000000 | . 33 White | Male | mean | 63940.388119 | . 34 White | Male | min | 26125.000000 | . 35 White | Male | max | 210588.000000 | . ggplot(data = df3) + geom_bar(aes(x = &#39;aggtype&#39;, y = &#39;BASE_SALARY&#39;, fill = &#39;GENDER&#39;), stat = &#39;identity&#39;, position = &#39;dodge&#39;) + coord_flip() + facet_wrap(facets = &#39;RACE&#39;) . &lt;ggplot: (135580437071)&gt; .",
            "url": "https://jaesu26.github.io/green/python/2021/11/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.html",
            "relUrl": "/python/2021/11/05/%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%8B%9C%EA%B0%81%ED%99%94_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC%EC%97%B0%EC%8A%B5%EB%AC%B8%EC%A0%9C.html",
            "date": " • Nov 5, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "R입문 중간고사",
            "content": "- 시험문제 : https://guebin.github.io/2021IR/2024/01/01/R%EC%9E%85%EB%AC%B8%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html . - 파이썬 연습겸 R입문 중간고사 문제 파이썬으로 풀어봄 . 1&#48264; &#47928;&#51228; . (a) . 2**-5 + 2**3 . 8.03125 . (b) . 33**0.5 . 5.744562646538029 . (c) . sum_ = 0 for k in range(1, 101): sum_ += 1 / ((k+1) ** 2) print(sum_) . 0.6350819297898338 . - 리스트 컴프리핸션 . sum([1/((k+1)**2) for k in range(1, 101)]) . 0.6350819297898338 . 2&#48264; &#47928;&#51228; . (a) . import numpy as np x = np.arange(-10, 10.5, 0.5) print(x) . [-10. -9.5 -9. -8.5 -8. -7.5 -7. -6.5 -6. -5.5 -5. -4.5 -4. -3.5 -3. -2.5 -2. -1.5 -1. -0.5 0. 0.5 1. 1.5 2. 2.5 3. 3.5 4. 4.5 5. 5.5 6. 6.5 7. 7.5 8. 8.5 9. 9.5 10. ] . (b) . def f(x): if abs(x) &gt; 5: return x elif abs(x) &lt; 2: return 0 else: return 5 y = list(map(f, x)) print(y) . [-10.0, -9.5, -9.0, -8.5, -8.0, -7.5, -7.0, -6.5, -6.0, -5.5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0] . 3&#48264; &#47928;&#51228; . from math import exp def f(x): return 2*x + 3 def g(x): return exp(x) / (1 + exp(x)) def h(x): return max(x, 0) x1 = list(map(f, x)) x2 = list(map(g, x1)) x3 = list(map(h, x2)) print(x3) . [4.1399375473943306e-08, 1.12535162055095e-07, 3.059022269256247e-07, 8.315280276641321e-07, 2.2603242979035742e-06, 6.144174602214718e-06, 1.670142184809518e-05, 4.5397868702434395e-05, 0.00012339457598623172, 0.00033535013046647816, 0.0009110511944006454, 0.0024726231566347748, 0.006692850924284856, 0.017986209962091555, 0.04742587317756679, 0.11920292202211755, 0.2689414213699951, 0.5, 0.7310585786300049, 0.8807970779778824, 0.9525741268224333, 0.9820137900379085, 0.9933071490757152, 0.9975273768433652, 0.9990889488055994, 0.9996646498695335, 0.9998766054240138, 0.9999546021312976, 0.9999832985781519, 0.9999938558253978, 0.999997739675702, 0.9999991684719723, 0.9999996940977731, 0.9999998874648379, 0.9999999586006245, 0.9999999847700205, 0.9999999943972036, 0.9999999979388464, 0.999999999241744, 0.9999999997210532, 0.9999999998973812] . 4&#48264; &#47928;&#51228; . (a) . import matplotlib.pyplot as plt n = 10 l = [0]*n for i in range(1, n+1): l[i-1] = 1/(2**i) l_ = np.cumsum(l) plt.plot(list(range(n)), l_) . [&lt;matplotlib.lines.Line2D at 0x15879d61f70&gt;] . sum = 0 n = 10 x = 5 ## 예시 for i in range(n): sum += x**i print(exp(x),&quot; n&quot;, sum) . 148.4131591025766 2441406 . - 모든 x에 대해 성립해야 되는데 아니다 . 5&#48264; &#47928;&#51228; . x = a = 10 #예시 salary = a for i in range(1, 19): a *= 1.08 salary += a for j in range(20, 29): a *= 0.75 salary += a print(salary / x) . 52.53420212516463 . 6&#48264; &#47928;&#51228; . - (a) : 참 . - (b) : 거짓 . - (c) : 거짓 . - (d) : 거짓 . 7&#48264; &#47928;&#51228; . n = 100 doors = [False] * (n+1) for i in range(1, n+1): for j in range(i, n+1): if j % i == 0: if doors[j] == True: doors[j] = False else: doors[j] = True sum_ = 0 for k in range(1, n+1): if doors[k] == True: sum_ += 1 print(sum_) . 10 . 8&#48264; &#47928;&#51228; . dist = 35 dp = [0] * 456 dp2 = [0] * 456 x = np.array(range(1, 457)) / 100 for i in np.arange(10, 0, -0.5): for j in range(456): if dp2[j] == 0: dp[j] = round(dp[j] + round(x[j], 3), 3) if x[j] &gt; i and dp2[j] == 0: ## 0은 False이다 if dp[j] - round((x[j] - i), 3) &lt; dist: dp2[j] = -1 elif dp[j] - round((x[j] - i), 3) &gt;= dist: dp2[j] = 1 elif x[j] &lt;= i and dp[j] &gt;= dist and dp2[j] == 0: dp2[j] = 1 x += 1 . (a) . dp2[0] # 사망 . -1 . dp2[66] # 사망 . -1 . dp2[217] # 생존 . 1 . dp2[455] # 사망 . -1 . (b) . sum_ = 0 for k in range(456): if dp2[k] == 1: sum_ += 1 print(sum_) . 85 . - 전체 생존자는 85명 . - 고찰 . - 이것때문에 정신나감 . - 그리고 처음 dp 설정할 때 전부 0으로 해야됐는데 -1로 해서 또 정신나감 . a = np.array([0, 0]) b = [0] * 2 a[0] += 0.01 print(a[0]) . 0 . - 왜 0인지 이해가 안됨 . - 왜 0.01이 아니냐? . b[0] += 0.01 print(b[0]) . 0.01 . - ㅋㅋㅋㅋㅋㅋㅋㅋㅋ . - 넘파이 어레이는 0인데 그냥 리스트는 0.01이다 . - 이유는 모른다 . 9&#48264; &#47928;&#51228; . import pandas as pd df = pd.read_csv(&quot;https://raw.githubusercontent.com/miruetoto/yechan/master/_notebooks/round2.csv&quot;) mat = np.matrix(df) . mat.shape . (5513, 2) . (a) . plt.plot(mat[:,0], mat[:,1], &#39;.k&#39;) . [&lt;matplotlib.lines.Line2D at 0x200885d74c0&gt;] . (b) . mat[0,:] . matrix([[ 12, 313]], dtype=int64) . (c) . np.matrix([[0,-1], [-1,0]]) @ np.matrix([12,313]).T . matrix([[-313], [ -12]]) . (d) . mat2 = mat for i in range(5513): mat2[i,:] = (np.matrix([[0,-1], [-1,0]]) @ mat[i,:].T).T . (e) . plt.plot(mat2[:,0], mat2[:,1], &#39;.r&#39;) . [&lt;matplotlib.lines.Line2D at 0x200886dc190&gt;] . - 위에서 mat2 = mat이라고 했는데 그러면 안됨 . id(mat2), id(mat) . (2203309972272, 2203309972272) . - 메모리 주소가 동일해서 mat2를 바꾸면 mat도 바뀌어서 아래와 같이 된다 . plt.plot(mat[:,0], mat[:,1], &#39;.r&#39;) . [&lt;matplotlib.lines.Line2D at 0x20088745760&gt;] . - 그럼 어떻게? &gt; 깊은복사! . - mat 다시 초기화 . mat = np.matrix(df) . plt.plot(mat[:,0], mat[:,1], &#39;.k&#39;) . [&lt;matplotlib.lines.Line2D at 0x200887ad7c0&gt;] . mat3 = mat.copy() . for i in range(5513): mat3[i,:] = (np.matrix([[0,-1], [-1,0]]) @ mat[i,:].T).T . plt.plot(mat3[:,0], mat2[:,1], &#39;.r&#39;) . [&lt;matplotlib.lines.Line2D at 0x20088815970&gt;] . id(mat), id(mat3) . (2201311857904, 2201313255712) . - 메모리 주소가 다르다 . plt.plot(mat[:,0], mat[:,1], &#39;.k&#39;) . [&lt;matplotlib.lines.Line2D at 0x20088877850&gt;] . - mat3를 바꿨지만 깊은복사를 하였기에 mat에는 영향을 끼치지 않음 .",
            "url": "https://jaesu26.github.io/green/python/2021/11/04/R%EC%9E%85%EB%AC%B8_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "relUrl": "/python/2021/11/04/R%EC%9E%85%EB%AC%B8_%EC%A4%91%EA%B0%84%EA%B3%A0%EC%82%AC.html",
            "date": " • Nov 4, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "혈압-혈당 데이터 분석",
            "content": "&#54056;&#53412;&#51648; import &#48143; &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . - 데이터 출처 : https://nhiss.nhis.or.kr/bd/ab/bdabf003cv.do . - 한글 깨짐 참고 : https://mirae-kim.tistory.com/14 . import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib import seaborn as sns import scipy.stats as stats from scipy.stats import norm import statsmodels.formula.api as smf fig_dims = (10, 6) sns.set(rc = {&#39;figure.figsize&#39;:fig_dims}) # plot 사이즈 및 스타일 통일 sns.set_theme() # 테마 설정 matplotlib.rcParams[&#39;font.family&#39;] = &#39;Malgun Gothic&#39; # 한글이 깨지지 않도록 설정 matplotlib.rcParams[&#39;axes.unicode_minus&#39;] = False # 한글이 깨지지 않도록 설정 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/gkswotn9999/data/main/blood_data.csv&#39;, header = 0) ## 2013~2014년에 실시된 백만개의 국가건강검진_혈압혈당데이터 . df.shape ## matrix는 1000000 × 7 크기 . (1000000, 7) . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1000000 entries, 0 to 999999 Data columns (total 7 columns): # Column Non-Null Count Dtype -- -- 0 SEX 1000000 non-null int64 1 BTH_G 1000000 non-null int64 2 SBP 1000000 non-null int64 3 DBP 1000000 non-null int64 4 FBS 1000000 non-null int64 5 DIS 1000000 non-null int64 6 BMI 1000000 non-null float64 dtypes: float64(1), int64(6) memory usage: 53.4 MB . - 결측치는 없다 . - 우선 열 이름을 한글로 변경한다 . df.columns = [&#39;성별&#39;, &#39;연령대&#39;, &#39;수축기혈압&#39;, &#39;이완기혈압&#39;, &#39;공복혈당&#39;, &#39;고혈압_당뇨_진료내역&#39;, &#39;BMI&#39;] . df.head(6) . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI . 0 1 | 1 | 116 | 78 | 94 | 4 | 16.6 | . 1 1 | 1 | 100 | 60 | 79 | 4 | 22.3 | . 2 1 | 1 | 100 | 60 | 87 | 4 | 21.9 | . 3 1 | 1 | 111 | 70 | 72 | 4 | 20.2 | . 4 1 | 1 | 120 | 80 | 98 | 4 | 20.0 | . 5 1 | 1 | 115 | 79 | 95 | 4 | 23.1 | . - 변수별 요약통계량은 아래와 같다 . df.describe().round(2) . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI . count 1000000.00 | 1000000.00 | 1000000.00 | 1000000.00 | 1000000.00 | 1000000.00 | 1000000.0 | . mean 1.49 | 13.91 | 121.87 | 75.79 | 98.86 | 3.47 | 23.8 | . std 0.50 | 7.01 | 14.56 | 9.79 | 22.98 | 0.95 | 3.3 | . min 1.00 | 1.00 | 82.00 | 50.00 | 60.00 | 1.00 | 14.8 | . 25% 1.00 | 9.00 | 110.00 | 70.00 | 87.00 | 3.00 | 21.5 | . 50% 1.00 | 14.00 | 120.00 | 76.00 | 94.00 | 4.00 | 23.6 | . 75% 2.00 | 19.00 | 130.00 | 80.00 | 104.00 | 4.00 | 25.8 | . max 2.00 | 27.00 | 190.00 | 120.00 | 358.00 | 4.00 | 40.3 | . - 수축기혈압은 82~190의 범위를 가지고 중앙값은 120, 평균은 121.87이다 . - 이완기혈압은 50~120의 범위를 가지고 중앙값은 76, 평균은 75.79이다 . - 공복혈당은 60~358의 범위를 가지고 중앙값은 94, 평균은 98.86이다 . - BMI은 14.8~40.3의 범위를 가지고 중앙값은 23.6, 평균은 23.8이다 . - 양적변수들을 보면 중앙값과 평균이 거의 비슷한데 대칭인 분포인 것 같다 . - 각 변수에 대한 설명은 아래와 같다 . 변수명 범위 비고 . 수축기혈압 | 82-190 mmHg | 상·하위 극단값 0.05% 제거 | . 이완기혈압 | 50-120 mmHg | 〃(위와 동일함) | . 공복혈당 | 60-358 mg/dL | 〃 | . BMI | 14.8-40.3 kg/m2 | $ cfrac{w}{t^2}$키가 t미터, 몸무게가 w킬로그램〃(위와 동일함) | . 성별 숫자 . 남자 | 1 | . 여자 | 2 | . 고혈압/당뇨병 진료내역 숫자 . 고혈압/당뇨병 진료내역 있음 | 1 | . 고혈압 진료내역 있음 | 2 | . 당뇨병 진료내역 있음 | 3 | . 고혈압/당뇨병 진료내역 없음 | 4 | . - 고혈압, 당뇨 진료내역의 의미는 다음과 같다 . - 현재 고혈압을 앓고있을 수 도 있고 아니면 과거에 고혈압에 걸렸었던 것일 수 도 있다 . - 즉 현재 고혈압인 경우와 과거에 고혈압이었던 경우로 나뉘며 당뇨도 마찬가지이다 . &#50672;&#47161;&#45824; &#48276;&#51452; &#48320;&#44221; . - 현재 연령대 column 이 가지는 값은 1부터 27 까지인데 이들에는 1 =&gt; 20~24, 2 부터는 24살부터 2세 간격으로 끊어진 연령대가 할당되고 마지막은 27 =&gt; 75+ 이다 . ft = df[&#39;연령대&#39;].value_counts() rft = df[&#39;연령대&#39;].value_counts() / len(df[&#39;연령대&#39;]) age_group_table = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) age_group_table.sort_index() . Freq Relative freq . 1 26699 | 0.026699 | . 2 22398 | 0.022398 | . 3 26925 | 0.026925 | . 4 30595 | 0.030595 | . 5 34984 | 0.034984 | . 6 33797 | 0.033797 | . 7 29666 | 0.029666 | . 8 30074 | 0.030074 | . 9 53811 | 0.053811 | . 10 50787 | 0.050787 | . 11 50881 | 0.050881 | . 12 49544 | 0.049544 | . 13 46303 | 0.046303 | . 14 46373 | 0.046373 | . 15 52352 | 0.052352 | . 16 53382 | 0.053382 | . 17 47760 | 0.047760 | . 18 45048 | 0.045048 | . 19 37174 | 0.037174 | . 20 33846 | 0.033846 | . 21 30824 | 0.030824 | . 22 32253 | 0.032253 | . 23 22906 | 0.022906 | . 24 22720 | 0.022720 | . 25 24530 | 0.024530 | . 26 18463 | 0.018463 | . 27 45905 | 0.045905 | . - 변수가 가지는 범주가 너무 많고 범주가 가지는 나이의 범위가 현재 2세인데 조금 더 늘려도 크게 차이가 있을 것 같지는 않다 . - 표본수가 많으므로 10세 간격으로 끊지 않고 5세 간격으로 끊어 비슷한 연령끼리 그룹화 하겠다 . - 애매한 것은 연령대 데이터가 31-32, 33-34, 35-36, 37-38, 39-40 이런식으로 되어있어 5개씩 나눌 수 가 없는 점이다 . - 0~4 과 5~9으로 나누면 균등해지고 좋을 것 같다 . - 혈압혈당데이터는 건강검진을 받은 사람들 중 백만명을 무작위 층화추출했다 . - 그렇기에 주기성이 없을 것이니 하나의 난수를 가지고 20~70세의 초반, 후반을 나누겠다 . - 5세 간격으로 끊어 편의상 0~4는 &#39;초반&#39;, 5~9는 &#39;후반&#39;으로 표기했다 . - 위의 범주를 무작위로 50%씩 나눠서 반절은 &#39;초반&#39;에 나머지 반절은 &#39;후반&#39;에 할당하겠다 . np.random.seed(2021) rs = np.random.binomial(n = 1, p = 0.5, size = 60000) # 최대가 53000이라 넉넉히 60000개 뽑았다 . c = 2 age = 2 cnt = 3 df.loc[df[&#39;연령대&#39;] == 1, &#39;연령대&#39;] = &#39;20대초반&#39; for idx in [4, 9, 14, 19, 24]: # 변수에 대한 설명을 보면 9~10 에 해당하는 범주의 값은 4, 9, 14, 19, 24이다 df_ = df.loc[df[&#39;연령대&#39;] == idx, &#39;연령대&#39;] df.loc[df[&#39;연령대&#39;] == idx, &#39;연령대&#39;] = rs[: len(df_)] df.loc[df[&#39;연령대&#39;] == 0, &#39;연령대&#39;] = str(c) + &#39;0대후반&#39; c += 1 df.loc[df[&#39;연령대&#39;] == 1, &#39;연령대&#39;] = str(c) + &#39;0대초반&#39; for i in range(2, 27): if cnt &lt; 3: str_ = &#39;초반&#39; else: str_ = &#39;후반&#39; df.loc[df[&#39;연령대&#39;] == i, &#39;연령대&#39;] = str(age) + &#39;0대&#39; + str_ if cnt == 5: age += 1 cnt = 0 cnt += 1 df.loc[df[&#39;연령대&#39;] == 27, &#39;연령대&#39;] = &#39;75세이상&#39; . - 연령대의 도수분포표를 그려보겠다 . ft = df[&#39;연령대&#39;].value_counts() rft = df[&#39;연령대&#39;].value_counts() / len(df[&#39;연령대&#39;]) . age_group_table = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) age_group_table.sort_index() . Freq Relative freq . 20대초반 26699 | 0.026699 | . 20대후반 64616 | 0.064616 | . 30대초반 84083 | 0.084083 | . 30대후반 86639 | 0.086639 | . 40대초반 128580 | 0.128580 | . 40대후반 118978 | 0.118978 | . 50대초반 128976 | 0.128976 | . 50대후반 111352 | 0.111352 | . 60대초반 83300 | 0.083300 | . 60대후반 66487 | 0.066487 | . 70대초반 54385 | 0.054385 | . 75세이상 45905 | 0.045905 | . &#45936;&#51060;&#53552; EDA . - 기본적으로 고혈압_당뇨 진료내역에 따른 특성들을 확인할 것이다 . &#48276;&#51452;&#54805;&#48320;&#49688; &#53456;&#49353; . &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669; &#48712;&#46020; . - 우선 고혈압, 당뇨 진료내역 범주의 비율을 확인했다 . ft = df[&#39;고혈압_당뇨_진료내역&#39;].value_counts() rft = df[&#39;고혈압_당뇨_진료내역&#39;].value_counts() / len(df[&#39;고혈압_당뇨_진료내역&#39;]) . DIS_table = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) DIS_table . Freq Relative freq . 4 740662 | 0.740662 | . 2 162826 | 0.162826 | . 1 53398 | 0.053398 | . 3 43114 | 0.043114 | . count_by_cut = df.groupby(&#39;고혈압_당뇨_진료내역&#39;).size() count_by_cut . 고혈압_당뇨_진료내역 1 53398 2 162826 3 43114 4 740662 dtype: int64 . plt.pie(x = count_by_cut, labels = [&#39;고혈압,당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 고혈압/당뇨 둘 다 진료내역 없음이 74%로 가장 많이 차지한다 . - 당뇨 진료내역만 있는 경우는 4%, 고혈압 진료내역만 있는 경우는 16%, 둘다 있는 경우는 5%이다 . - 둘 다 진료내역이 있는 경우가 당뇨 진료내역만 있는 경우보다 많은 것으로 보아 당뇨가 있는 경우 고혈압도 있는 경우가 빈번한 것 같다 . - 고혈압/당뇨 진료내역에 따른 사람들의 연령대와 성별을 확인하겠다 . - 우선 고혈압/당뇨 진료내역에 따른 연령대를 확인하겠다 . &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669;&#44284; &#50672;&#47161;&#45824; &#48516;&#54624;&#54364; . # df[&#39;연령대&#39;] = pd.Categorical(df[&#39;연령대&#39;], [&#39;20대초반&#39;, &#39;20대후반&#39;, &#39;30대초반&#39;, &#39;30대후반&#39;, &#39;40대초반&#39;, &#39;40대후반&#39;, &#39;50대초반&#39;, &#39;50대후반&#39;, &#39;60대초반&#39;, &#39;60대후반&#39;, &#39;70대초반&#39;, &#39;75세이상&#39;]) . DIS_AGE_table = df.groupby([&#39;연령대&#39;, &#39;고혈압_당뇨_진료내역&#39;]).size().reset_index(name = &#39;cnt&#39;).pivot(index = &#39;고혈압_당뇨_진료내역&#39;, columns = &#39;연령대&#39;, values = &#39;cnt&#39;) # DIS_AGE_table = pd.crosstab(df[&#39;고혈압_당뇨&#39;], df[&#39;연령대&#39;], margins = True) . DIS_AGE_table . 연령대 20대초반 20대후반 30대초반 30대후반 40대초반 40대후반 50대초반 50대후반 60대초반 60대후반 70대초반 75세이상 . 고혈압_당뇨_진료내역 . 1 9 | 35 | 137 | 431 | 1358 | 2763 | 5362 | 7861 | 8818 | 9232 | 9300 | 8092 | . 2 80 | 359 | 1104 | 2936 | 7607 | 13091 | 21954 | 26180 | 24447 | 23256 | 21241 | 20571 | . 3 79 | 253 | 543 | 1233 | 2865 | 4400 | 6555 | 7371 | 6648 | 5524 | 4479 | 3164 | . 4 26531 | 63969 | 82299 | 82039 | 116750 | 98724 | 95105 | 69940 | 43387 | 28475 | 19365 | 14078 | . - 공통적으로 확인되는것은 4번의 경우가 가장 많은 것과 2번의 경우가 3번의 경우보다 더 많다는 것이다 . - 당뇨병보다는 고혈압이 흔한것 같다 . - 그리고 젊은 연령대에서는 1의 경우가 2, 3인 경우보다 더 적은데 50대 초반부터는 늙을수록 1의 경우가 3의 경우보다 더 많아진다 . - 50대 부터는 당뇨가 있는 경우 고혈압도 있는 경우가 흔한것같고 이는 연령대가 높아질수록 더 심해진다 . - 그런데 연령마다 총인원수가 다르기에 사람수로 판단하기 보다는 비율로 판단하는게 좋아보인다 . - 예로 70대초반에서 고혈압_당뇨 범주값이 1인 경우 count는 9300이고 75세이상의 경우는 8092여서 감소한것 같지만 70대초반 인구수와 75세이상 인구수가 다르기에 비율로 따져야 정확하다 . DIS_AGE_table_prob = DIS_AGE_table.apply(lambda x: x*100 / sum(x), axis = 0) # 상대도수를 구함 DIS_AGE_table_prob . 연령대 20대초반 20대후반 30대초반 30대후반 40대초반 40대후반 50대초반 50대후반 60대초반 60대후반 70대초반 75세이상 . 고혈압_당뇨_진료내역 . 1 0.033709 | 0.054166 | 0.162934 | 0.497466 | 1.056152 | 2.322278 | 4.157363 | 7.059595 | 10.585834 | 13.885421 | 17.100303 | 17.627709 | . 2 0.299637 | 0.555590 | 1.312988 | 3.388774 | 5.916161 | 11.002874 | 17.021771 | 23.511028 | 29.348139 | 34.978266 | 39.056725 | 44.812112 | . 3 0.295891 | 0.391544 | 0.645790 | 1.423147 | 2.228185 | 3.698163 | 5.082341 | 6.619549 | 7.980792 | 8.308391 | 8.235727 | 6.892495 | . 4 99.370763 | 98.998700 | 97.878287 | 94.690613 | 90.799502 | 82.976685 | 73.738525 | 62.809828 | 52.085234 | 42.827921 | 35.607245 | 30.667683 | . DIS_AGE_table_prob.T.plot.bar(stacked = True, rot = 0, figsize=(12 , 6)) plt.legend([&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;]) . &lt;matplotlib.legend.Legend at 0x19789d29880&gt; . - 일단 4(고혈압,당뇨 둘 다 없음)인 경우를 확인하겠다 . - 20대초반의 99%는 4인데 나이가 들어감에 따라 비율이 감소하여 75세이상에서는 4의 경우가 30%이다 . - 1과 2의 경우는 4의 경우와 반대로 나이가 들어가면서 비율이 높아진다 . - 3의 경우는 60대후반까지는 증가하다가 그 이후부터 줄어든다 . - 요약하면 나이를 먹을수록 4는 증가하고 1,2,3은 감소한다(건강한 사람보다는 병을 앓던 사람이 많다는 의미이다) . - 고혈압_당뇨 범주마다 연령대의 비율은 어느정도인지 시각화하겠다 . sequential_colors = sns.color_palette(&#39;RdPu&#39;, 12) . DIS_AGE_table_prob2 = DIS_AGE_table.apply(lambda x: x*100 / sum(x), axis = 1) # 상대도수를 구함 DIS_AGE_table_prob2.plot.bar(stacked = True, rot = 0, color = sequential_colors) plt.legend(loc = &#39;center left&#39;, bbox_to_anchor = (1, 0.5)) plt.show() . - 막대그래프의 밑에서부터 20대초반, 20대후반, $ cdots$, 70대 초반, 75세이상이다(색이 연하면 나이가 적고 진하면 많도록 설정했다) . - 고혈압_당뇨가 1, 2, 3인 경우는 비슷해보인다 . - 고혈압/당뇨 둘 다 진료내역이 없는 경우(4)에는 확실히 다르다(색이 전체적으로 연하다) . - 고혈압/당뇨가 1, 2, 3인 경우 30대 후반까지 차지하는 비중이 낮다(연한색의 비율이 작다) . - 하지만 4인 경우에는 30대 후반까지 차지하는 비중이 높아졌다(연한색의 비율이 크다) . &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669;&#44284; &#49457;&#48324; &#48516;&#54624;&#54364; . - 이제 고혈압/당뇨 진료내역에 따른 성별을 확인하겠다 . count = df.groupby(&#39;성별&#39;).size() plt.pie(x = count, labels = [&#39;남자&#39;, &#39;여자&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 우선 전체 백만명중 남자가 51% 여자가 49%로 둘이 비슷하다 . DIS_SEX_table = df.groupby([&#39;성별&#39;, &#39;고혈압_당뇨_진료내역&#39;]).size().reset_index(name = &#39;cnt&#39;).pivot(index = &#39;고혈압_당뇨_진료내역&#39;, columns = &#39;성별&#39;, values = &#39;cnt&#39;) . DIS_SEX_table . 성별 1 2 . 고혈압_당뇨_진료내역 . 1 27979 | 25419 | . 2 79892 | 82934 | . 3 23900 | 19214 | . 4 378456 | 362206 | . DIS_SEX_table_prob = DIS_SEX_table.apply(lambda x: x*100 / sum(x), axis = 1) # 상대도수를 구함 DIS_SEX_table_prob . 성별 1 2 . 고혈압_당뇨_진료내역 . 1 52.397094 | 47.602906 | . 2 49.065874 | 50.934126 | . 3 55.434430 | 44.565570 | . 4 51.096992 | 48.903008 | . DIS_SEX_table_prob.plot.bar(stacked = True, rot = 0) plt.legend([&#39;남자&#39;, &#39;여자&#39;]) . &lt;matplotlib.legend.Legend at 0x1978b011df0&gt; . - 당뇨진료내역이 있는 경우 남자의 비율이 여자보다 살짝 높고 나머지는 비슷하다 . - 표본크기가 매우커서 55%, 45%(당뇨 진료내역 있음) 정도면 차이가 있다고 할 수 있다 . - 그리고 52.4%, 47.6%(고혈압, 당뇨 진료내역 있음) 도 차이가 있다고 할 수 있다 . - 마찬가지로 고혈압 진료내역이 있는 경우도 차이가 있다고 할 수 있다 . - 비율 차이 검정을 통해 정확히 확인하겠다 . df.groupby([&#39;고혈압_당뇨_진료내역&#39;, &#39;성별&#39;]).size().reset_index(). rename(columns = {0:&#39;count&#39;}). merge(df.groupby([&#39;고혈압_당뇨_진료내역&#39;]).agg({&#39;성별&#39;:&#39;size&#39;}). rename(columns = {&#39;성별&#39;:&#39;total&#39;}).reset_index()).eval(&#39;prop = count / total&#39;). query(&#39;성별 == 1&#39;).eval(&#39;z = (prop - 0.5102) / sqrt(prop * (1-prop) / total)&#39;). assign(right_z_0 = norm.ppf(0.975), left_z_0 = norm.ppf(0.275)) . 고혈압_당뇨_진료내역 성별 count total prop z right_z_0 left_z_0 . 0 1 | 1 | 27979 | 53398 | 0.523971 | 6.371704 | 1.959964 | -0.59776 | . 2 2 | 1 | 79892 | 162826 | 0.490659 | -15.773216 | 1.959964 | -0.59776 | . 4 3 | 1 | 23900 | 43114 | 0.554344 | 18.441415 | 1.959964 | -0.59776 | . 6 4 | 1 | 378456 | 740662 | 0.510970 | 1.325525 | 1.959964 | -0.59776 | . - 고혈압, 당뇨 진료내역이 없는 경우를 제외하면 . - 고혈압, 당뇨 진료내역에 따라 남자와 여자의 비율에 차이가 있음을 알 수 있다 . - 고혈압 진료내역만 있는 경우는 여자가 남자보다 비율이 높고 . - 고혈압, 당뇨 진료내역과 당뇨 진료내역만 있는 경우는 남자가 여자보다 비율이 높다 . &#50577;&#51201;&#48320;&#49688; &#53456;&#49353; . &#44060;&#48324; &#48320;&#49688;&#51032; &#49884;&#44033;&#54868; . &#49688;&#52629;&#44592;&#54792;&#50517; . - 양적 변수인 수축기혈압, 이완기혈압, 공복혈당, BMI의 분포를 확인하겠다 . sns.histplot(data = df, x = &#39;수축기혈압&#39;, binwidth = 5) . &lt;AxesSubplot:xlabel=&#39;수축기혈압&#39;, ylabel=&#39;Count&#39;&gt; . - 분포의 모양을 크게 눈에 띄는 봉우리가 4개(100, 110, 120, 130) 존재한다 . - 즉 몇 군데(봉우리)에 데이터가 많이 몰려있다는 의미이다 . sns.boxplot(x = df[&#39;수축기혈압&#39;]) . &lt;AxesSubplot:xlabel=&#39;수축기혈압&#39;&gt; . - boxplot을 보니 수축기혈압의 이상점은 160을 넘는 경우인 듯 하다 . - 성별에 따라 수축기혈압이 다른지 궁금하다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;수축기혈압&#39;&gt; . df.groupby(&#39;성별&#39;)[&#39;수축기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 124.279954 | 13.547532 | 82.0 | 115.0 | 123.0 | 132.0 | 190.0 | . 2 489773.0 | 119.363001 | 15.146169 | 82.0 | 110.0 | 119.0 | 130.0 | 190.0 | . - 남자인 경우 여자인 경우보다 평균적으로 수축기혈압이 5정도 높다 . - 신기한건 남자가 여자보다 이완기 혈압이 평균적으로 4정도 높지만 두 봉우리의 위치는 남자와 여자가 동일하다 . - 그리고 표준편차는 여자가 1.5정도 더 높다(변동성이 더 크다) &gt; 남자쪽 봉우리가 더 뾰족해서인듯 하다(데이터가 몰려있다) . - 그런데 고혈압, 당뇨 진료내역에 따라 수축기혈압의 분포를 살펴봤는데 이 때도 봉우리의 위치는 4개다 동일하다 . - 남자가 여자보다 혈압이 평균적으로 더 높지만 봉우리의 위치가 같은건 어떤 의미인지 깊게 생각할 필요가 있다 . - 수축기혈압 분포에서 봉우리가 연령대에 의한건지 궁금하다 . b = sns.FacetGrid(data = df, row = &#39;연령대&#39;, height = 7) b.map(sns.histplot, &#39;수축기혈압&#39;, kde = False, binwidth = 5, color = &#39;gray&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x2117500c760&gt; . - 수축기혈압 분포에서 봉우리가 여러개인것이 연령대 때문은 아니다 . - 그런데 사실 고혈압/당뇨인 사람들은 어떤 특성을 가진 사람들인지가 궁금하다 . - 고혈압/당뇨에 따라 plot을 그려보겠다 . sns.boxplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . - 분포는 모두 대칭이고 종모양으로 보이며 봉우리가 많다 . - 고혈압_당뇨가 1,2인 경우는 130이 중심으로 보인다 . - 고혈압_당뇨가 3,4인 경우는 120이 중심으로 보인다 . - 고혈압/당뇨 둘다 진료내역이 없는 그룹은 수축기혈압이 낮은쪽에서는 이상점이 없다 . - 바이올린플랏을 그려 분포의 모양도 같이 확인하겠다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . - 봉우리가 많은 이유가 고혈압_당뇨 진료내역에 따라 분포가 상이하여 그럴것 같았지만 아니었다 . - 고혈압/당뇨 진료내역이 없는 사람들의 수축기 혈압은 다른 경우 비해 몇군데에 더욱 많이 몰렸있다 . - 봉우리가 많은 분포임은 넷다 동일하다 . - 데이터를 보면 1은 고혈압 당뇨 둘 다 진료내역이 있고 2는 고혈압만 3은 당뇨만 있고 4는 둘 다 진료 내역이 없는 경우이다 . - 2와 3을 보면 2가 수축기 혈압이 평균적으로 더 높다 . - 그런데 1과 2를 보면 거의 차이가 없어보인다 . - 3과 4를 보면 당뇨 진료내역이 있는 사람들이 그렇지 않은 사람보다 평균이 조금 더 크고 분포도 더 넓게 퍼져있다 . - 고협압/당뇨 둘 다 진료내역이 없는 상황에서 당뇨 진료내역이 추가되면 수축기 혈압이 높아지고 더 넓게 분포한다 . - 하지만 고혈압 진료내역이 있는 상태라면 당뇨 진료내역의 유무는 수축기 혈압에 거의 영향을 끼치지 못하는 것으로 보인다 . - 수치로 정확히 확인하겠다 . df.groupby(&#39;고혈압_당뇨_진료내역&#39;)[&#39;수축기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 고혈압_당뇨_진료내역 . 1 53398.0 | 130.563972 | 14.981472 | 82.0 | 120.0 | 130.0 | 140.0 | 190.0 | . 2 162826.0 | 130.551300 | 14.851658 | 82.0 | 120.0 | 130.0 | 140.0 | 190.0 | . 3 43114.0 | 123.322146 | 13.618274 | 83.0 | 114.0 | 122.0 | 130.0 | 190.0 | . 4 740662.0 | 119.252575 | 13.484496 | 82.0 | 110.0 | 120.0 | 130.0 | 190.0 | . - 고혈압 진료내역만 있는 경우와 둘 다 진료내역이 있는 경우에 둘의 수축기 혈압 분포는 거의 똑같다 . - 표준편차는 약 15이고 평균은 약 130이다 . - 둘 다 진료내역이 없는 경우가 당뇨 진료내역만 있는 경우보다 수축기 혈압이 평균 4정도 낮다 . - 표준편차는 두 분포 모두 약 13.5이다 . - 고혈압이 있는 경우 그렇지 않은 경우보다 수축기 혈압이 평균 10정도 높다 . - 위에서 말했듯이 고혈압 진료내역이 있는 상태라면 당뇨병 진료내역과 수축기혈압은 상관이 없다 . - 하지만 고혈압이 없고 당뇨만 있는 상태라면 없는 경우보다 수축기혈압이 높다 . - 고혈압, 당뇨 진료내역 말고도 연령대별 수축기혈압에 차이가 있을 수 있다 . - 일반적으로 연령대가 높아질수록 수축기혈압이 높아진다고 한다 . - 이를 확인해볼 필요가 있다 . - 이상점에 영향을 덜받고자 중앙값을 선택했다 . df_mid = df.groupby([&#39;연령대&#39;]).agg({&#39;수축기혈압&#39;:np.median}) df_mid . 수축기혈압 . 연령대 . 20대초반 113 | . 20대후반 115 | . 30대초반 118 | . 30대후반 119 | . 40대초반 120 | . 40대후반 120 | . 50대초반 120 | . 50대후반 122 | . 60대초반 125 | . 60대후반 128 | . 70대초반 130 | . 75세이상 130 | . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, data = df_mid) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, data = df_mid, legend = False) . &lt;AxesSubplot:xlabel=&#39;연령대&#39;, ylabel=&#39;수축기혈압&#39;&gt; . - 위 plot을 보면 연령별 수축기혈압의 평균은 증가함을 알 수 있다 . - 그런데 40대초반~50대초반에서 수축기혈압의 중앙값은 120으로 동일하다 . - 이는 70대초반과 75세이상의 경우에도 마찬가지이다(130) . - 중간에 정체하는 구간을 기준으로 나눠봤을 때 구간 전보다 후가 증가폭이 더 크다($7.5 to 10$) . - 그런데 연령대 말고도 고혈압, 당뇨 진료내역마다 수축기혈압에 차이가 존재한다 . - 연령대별 고혈압, 당뇨 진료내역마다 수축기혈압의 중앙값들을 구하고 연령대에 따른 변화를 살펴보겠다 . df_median = df.groupby([&#39;연령대&#39;, &#39;고혈압_당뇨_진료내역&#39;])[&#39;수축기혈압&#39;].median().reset_index(name = &#39;수축기혈압&#39;) . tab10_colors = sns.color_palette(&#39;tab10&#39;, 4) . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;수축기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median, legend = False) plt.legend([&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;]) . &lt;matplotlib.legend.Legend at 0x21101cffb80&gt; . - 고혈압, 당뇨 둘 다 진료내역이 있는 경우와 고혈압만 진료내역이 있는 경우는 거의 동일한 양상을 보인다 . - 위의 경우 30대후반부터 수축기혈압의 중앙값은 130으로 동일하다 . - 당뇨 진료내역만 있는 경우 50대후반까진 수축기혈압의 중앙값이 120이다가 증가한다 . - 고혈압, 당뇨 진료내역이 둘 다 없는 경우도 증가하는 양상을 보이는데 40대초반에 살짝 감소한다 . - 그리고 40대후반부터 60대초반까지 수축기혈압 중앙값은 120으로 동일하다가 증가한다 . - 이완기 혈압도 수축기 혈압과 비슷한 양상을 보이는지 확인하겠다 . &#51060;&#50756;&#44592;&#54792;&#50517; . sns.histplot(data = df, x = &#39;이완기혈압&#39;, binwidth = 2) . &lt;AxesSubplot:xlabel=&#39;이완기혈압&#39;, ylabel=&#39;Count&#39;&gt; . - 이완기 혈압도 수축기 혈압의 분포처럼 몇 군에데 데이터가 많이 몰려있는 분포(봉우리)이다 . - 짜잘한 봉우리가 많이 있긴한데 눈에 띄는 봉우리는 2개가 존재한다(쌍봉분포) . - 왜 봉우리가 2개(70, 80)인지 궁금하다 . - 연령대 때문인지가 궁금하다 . b = sns.FacetGrid(data = df, row = &#39;연령대&#39;, height = 7) b.map(sns.histplot, &#39;이완기혈압&#39;, kde = False, binwidth = 2, color = &#39;gray&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x2ba411253a0&gt; . - 그렇지는 않다 . - 30대 초반까진 70부근이 최빈값이고 그 이후부터는 80부근이 최빈값이다 . - 나이가 많은 사람은 이완기혈압이 크다고 해석할 수 있다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;이완기혈압&#39;&gt; . df.groupby(&#39;성별&#39;)[&#39;이완기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 77.614977 | 9.504481 | 50.0 | 70.0 | 79.0 | 83.0 | 120.0 | . 2 489773.0 | 73.884467 | 9.727230 | 50.0 | 68.0 | 73.0 | 80.0 | 120.0 | . - 남자인 경우 여자인 경우보다 평균적으로 이완기혈압이 4정도 높다 . - 신기한건 남자가 여자보다 이완기 혈압이 평균적으로 4정도 높지만 두 봉우리의 위치는 남자와 여자가 동일하다 . - 수축기혈압의 경우 여성이 편차가 더 컸는데 이완기혈압의 경우는 비슷하다 . - 수축기 혈압 분포와 이완기 혈압 분포를 같이 놓고 비교하겠다 . fig, (ax1, ax2) = plt.subplots(1,2) fig.set_figwidth(12) sns.histplot(data = df, x = &#39;수축기혈압&#39;, binwidth = 5, ax = ax1) sns.histplot(data = df, x = &#39;이완기혈압&#39;, binwidth = 2, ax = ax2) fig.tight_layout() . - 수축기 혈압 분포의 봉우리가 이완기 혈압 분포의 봉우리 개수보다 많다 . - 변동계수를 계산하면 비슷하다 &gt; 수축기혈압과 이완기혈압의 변동성은 비슷하다 . - 고혈압/당뇨에 따른 이완기 혈압 분포를 확인하겠다 . b = sns.FacetGrid(data = df, row = &#39;고혈압_당뇨_진료내역&#39;, height = 7) b.map(sns.histplot, &#39;이완기혈압&#39;, kde = False, binwidth = 2, color = &#39;gray&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x2ba452396d0&gt; . - 고혈압, 당뇨 둘 다 없는 경우 이완기혈압은 50~105에 분포하는 것으로 보이고 나머지는 60~105에 분포하는 것 같다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 이완기 혈압도 수축기혈압과 동일한 양상을 보인다 . - 수치를 통해 정확히 확인해보면 다음과 같다 . df.groupby(&#39;고혈압_당뇨_진료내역&#39;)[&#39;이완기혈압&#39;].describe() . count mean std min 25% 50% 75% max . 고혈압_당뇨_진료내역 . 1 53398.0 | 78.366193 | 9.874400 | 50.0 | 70.0 | 80.0 | 84.0 | 120.0 | . 2 162826.0 | 80.040417 | 10.050473 | 50.0 | 72.0 | 80.0 | 86.0 | 120.0 | . 3 43114.0 | 75.679478 | 9.137214 | 50.0 | 70.0 | 76.0 | 80.0 | 120.0 | . 4 740662.0 | 74.673427 | 9.471040 | 50.0 | 70.0 | 75.0 | 80.0 | 120.0 | . - 둘 다 없는 경우보다 당뇨만 있는 경우 이완기혈압의 평균이 1정도 높다 . - 고혈압이 있으면 위의 경우보다 혈압이 평균적으로 4~5정도 높다 . - 신기한건 고혈압만 있는 경우가 고혈압, 당뇨 둘 다 있는 경우보다 사분위수와 평균이 약 2정도 더 크다 . - 당뇨 진료내역 여부는 혈압에 영향을 별로 끼치지 못하는 것처럼 보인다 . - 정말로 그런지 진료내역이 없는 경우와 당뇨 진료내역만 있는 경우의 평균 차이에 대해 검정하도록 하겠다 . - 특정 값에 데이터가 많이 몰려있어 정규분포는 아닌것처럼 보이지만 표본크기가 매우 크고 종모양이기에 t검정을 실시하겠다 . - 우선 등분산인지 검정하겠다 . x_B = df.query(&#39;고혈압_당뇨_진료내역 == 3&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;고혈압_당뇨_진료내역 == 4&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=108.15121732780896, pvalue=2.4998221943218063e-25) . - p-value가 0이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False) . print(t_stat, pvalue) . 22.179011908568423 1.892237004554513e-108 . - t통계량에 근거한 p-value가 0이다 . - 당뇨 진료내역만 있는 경우와 진료내역이 없는 경우의 이완기혈압 평균의 차이는 존재한다 . - 하지만 그 차이가 1 뿐이기에 통계적으로는 유의한 차이지만 실질적인 차이는 거의 없다 . - 고혈압 진료내역이 있는 경우 수축기혈압과 이완기 혈압이 높은데 이는 당연하다(고혈압은 혈압이 높은것) . - 그리고 고혈압이 있는 경우가 그렇지 않은 경우보다 혈압이 높은데 수축기혈압의 증가폭(10)이 이완기혈압의 증가폭(5)보다 더 크다 . - 고혈압, 당뇨 진료내역 말고도 연령대별 이완기혈압에 차이가 있을 수 있다 . - 일반적으로 연령대가 높아질수록 이완기혈압이 높아진다고 한다 . - 이를 확인해볼 필요가 있다 . - 수축기혈압때처럼 연령대별 이완기혈압의 중앙값들을 구하고 연령대에 따른 변화를 살펴보겠다 . df_mid2 = df.groupby([&#39;연령대&#39;]).agg({&#39;이완기혈압&#39;:np.median}) df_mid2 . 이완기혈압 . 연령대 . 20대초반 70 | . 20대후반 70 | . 30대초반 74 | . 30대후반 75 | . 40대초반 75 | . 40대후반 77 | . 50대초반 78 | . 50대후반 78 | . 60대초반 78 | . 60대후반 78 | . 70대초반 78 | . 75세이상 78 | . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, data = df_mid2) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, data = df_mid2, legend = False) . &lt;AxesSubplot:xlabel=&#39;연령대&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 위 plot을 보면 이완기혈압의 중앙값은 증가함을 알 수 있다 . - 그런데 50대초반부터는 이완기혈압의 중앙값은 78로 동일하다 . - 그리고 30대후반~40대초반에 이완기혈압이 75로 동일하다 . - 중간에 정체하는 구간을 기준으로 나눠봤을 때 구간 전보다 후가 증가폭이 더 크다($5 to 3$) . - 그런데 연령대 말고도 고혈압, 당뇨 진료내역마다 이완기혈압에 차이가 존재한다 . - 연령대별 고혈압, 당뇨 진료내역마다 이완기혈압의 중앙값들을 구하고 연령대에 따른 변화를 살펴보겠다 . df_median2 = df.groupby([&#39;연령대&#39;, &#39;고혈압_당뇨_진료내역&#39;])[&#39;이완기혈압&#39;].median().reset_index(name = &#39;이완기혈압&#39;) . plt.figure(figsize = (12, 6)) sns.lineplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median2) sns.scatterplot(x = &#39;연령대&#39;, y = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors, data = df_median2, legend = False) plt.legend([&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;]) . &lt;matplotlib.legend.Legend at 0x1978bc6f280&gt; . - 이완기혈압을 연령대별로 라인플랏을 그려봤을땐 감소하는 구간이 없었다 . - 또한 히스토그램을 확인했을 때도 마찬가지였다 . - 그런데 고혈압, 당뇨 진료내역에 따라 그래프를 나눠그리니 감소하는 구간이 생겼다 . - 위에서 나이가 들수록 이완기혈압이 높아진다고 했는데 고혈압, 당뇨 진료내역이 없는 사람을 제외하면 그렇지 않다 . - 공통적으로 30대 후반까지는 이완기혈압 중앙값이 증가한다 . - 그런데 그 이후부터는 고혈압, 당뇨 둘다 없는 경우를 제외하면 이완기혈압 중앙값이 감소한다 . - 중앙값이 문제일 수 있어서 평균으로 바꿔 그려봤으나 문제가 없었다 . - 수축기혈압 중앙값은 나이가 들수록 증가하는 반면 이완기혈압 중앙값은 진료내역이 없는 경우를 제외하면 증가하다가 감소한다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; &#51060;&#50756;&#44592;&#54792;&#50517; &#44256;&#52272; . - 위에서 수축기혈압과 이완기혈압의 분포를 살펴봤는데 고혈압 진료내역이 있지만 혈압이 낮은 사람도 있고 고혈압 진료내역이 없지만 혈압이 높은사람도 있었다 . - 고혈압 진료내역이 있지만 혈압이 정상범주안에 있는 사람은 혈압관리가 잘되고 있는것으로 간주할 수 있을 것 같다 . - 이들의 비율을 확인하겠다 . - 고혈압은 우리나라 기준 수축기 혈압 140mmHg 이상이거나 이완기 혈압 90mmHg 이상인 경우라고 한다 . - 참고 : http://hqcenter.snu.ac.kr/archives/jiphyunjeon/%EA%B3%A0%ED%98%88%EC%95%95 . - 위에 고혈압 기준을 넘어가는 혈압을 가진 사람들은 고혈압으로 그렇지 않는 사람은 정상혈압으로 간주하겠다 . - 그런데 수축기혈압, 이완기혈압의 분포를 보면 혈압이 매우 낮은 사람도 존재함을 알 수 있다 . - 이들은 저혈압으로 간주할 수 있을 것 같다 . - 저혈압은 일반적으로 수축기 혈압 90mmHg 미만이거나 이완기 혈압 60mmHg 미만인 경우라고한다 . - 참고 : https://health.kdca.go.kr/healthinfo/biz/health/gnrlzHealthInfo/gnrlzHealthInfo/gnrlzHealthInfoView.do?cntnts_sn=4616 . def f(x, y): if x &gt;= 140 or y &gt;= 90: z = &#39;고혈압&#39; elif x &lt; 90 or y &lt; 60: z = &#39;저혈압&#39; else: z = &#39;정상혈압&#39; return z . df[&#39;혈압범주&#39;] = list(map(f, df[&#39;수축기혈압&#39;], df[&#39;이완기혈압&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | . count = df.groupby(&#39;혈압범주&#39;).size() . plt.pie(x = count, labels = [&#39;고혈압&#39;, &#39;저혈압&#39;, &#39;정상혈압&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 정상혈압은 약 84%, 고혈압은 약 14%, 저혈압은 약 3% 이다 . - 저혈압보다는 고혈압이 흔한것같다 . - 고혈압 진료내역이 있는 사람이 약 22%정도였는데 7%p정도 차이가 있다 . tab = pd.crosstab(df[&#39;혈압범주&#39;], df[&#39;고혈압_당뇨_진료내역&#39;]) tab . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압범주 . 고혈압 16318 | 51261 | 5696 | 62049 | . 저혈압 773 | 1518 | 1056 | 23435 | . 정상혈압 36307 | 110047 | 36362 | 655178 | . tab.apply(lambda x: x*100 / sum(x), axis = 0) . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압범주 . 고혈압 30.559197 | 31.482073 | 13.211486 | 8.377506 | . 저혈압 1.447620 | 0.932284 | 2.449320 | 3.164061 | . 정상혈압 67.993183 | 67.585644 | 84.339194 | 88.458433 | . - 위를 보면 고혈압_당뇨 둘 다 없더라도 12%정도는 혈압에 문제가 있는것을 알 수 있다 . - 신기한건 고혈압 진료내역이 있는 경우인데 고혈압 진료내역이 있지만 실제 고혈압인 경우는 약 31%이고 68%는 정상혈압 나머지 1%는 저혈압이다 . tab2 = pd.crosstab(df[&#39;혈압범주&#39;], df[&#39;성별&#39;]) tab2.apply(lambda x: x*100 / sum(x), axis = 0) . 성별 1 2 . 혈압범주 . 고혈압 15.345719 | 11.643353 | . 저혈압 1.360375 | 4.051060 | . 정상혈압 83.293906 | 84.305586 | . - 남자가 여자보다 혈압이 더 높은건 고혈압 환자가 많아서였다 . - 참고로 백만명중 남자는 51% 여자는 49%이다 . &#54792;&#50517;&#48276;&#51452; &#49464;&#48516;&#54868; . - 같은 고혈압이더라도 수축기혈압만 높은지 이완기혈압만 높은지 아니면 둘 다 높은지가 다를것이다 . - 그런데 위와 같이 나누면 이를 구분할 수 없다 . - 게다가 수축기혈압은 고혈압인데 이완기혈압은 저혈압인 경우도 있다고 한다 . - 혈압범주를 세분화시키면 정확도는 올라가지만 편의성이 떨어진다 . - 세분화시킬 필요가 있을지 확인하겠다 . ref : https://m.health.chosun.com/svc/news_view.html?contid=2018053103892 | . - 일단 혈압범주를 세분화시킨 새로운 컬럼을 만들고 시각화하겠다 . def blood_pressure(x, y): if x &gt;= 140 and y &gt;= 90: z = &#39;HH&#39; elif x &lt; 90 and y &lt; 60: z = &#39;LL&#39; elif x &gt;= 140 and 60 &lt;= y &lt; 90: z = &#39;HN&#39; elif x &gt;= 140 and 60 &gt; y: z = &#39;HL&#39; elif 90 &lt;= x &lt; 140 and 60 &lt;= y &lt; 90: z = &#39;NN&#39; elif 90 &lt;= x &lt; 140 and 60 &gt; y: z = &#39;NL&#39; elif 90 &lt;= x &lt; 140 and y &gt;= 90: z = &#39;NH&#39; elif 90 &gt; x and 90 &lt;= y: z = &#39;LH&#39; elif 90 &gt; x and 60 &lt;= y &lt; 90: z = &#39;LN&#39; return z . - 혈압세부범주를 혈압범주로 치환하면 아래와 같다 . - HH, HN, HL, NH, LH &gt; 고혈압 . - LL, NL, LN &gt; 저혈압 . - NN &gt; 정상혈압 . - 혈압범주에서는 수축기고혈압 + 이완기저혈압이면 고혈압으로 표기했다(하지만 저혈압이기도 함) . - 혈압범주를 나누는 함수내부를 보면 if else문에서 고혈압을 먼저 판단하고 저혈압을 판단해서 그렇다 . - 하지만 혈압세부범주에서는 그럴일은 없다 . - 진료내역별 혈압세부범주를 확인하겠다 . df[&#39;혈압세부범주&#39;] = list(map(blood_pressure, df[&#39;수축기혈압&#39;], df[&#39;이완기혈압&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 맥압 혈압범주 혈압세부범주 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 38 | 정상혈압 | NN | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 40 | 정상혈압 | NN | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 40 | 정상혈압 | NN | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 41 | 정상혈압 | NN | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 40 | 정상혈압 | NN | . tab = pd.crosstab(df[&#39;혈압세부범주&#39;], df[&#39;고혈압_당뇨_진료내역&#39;]) tab . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압세부범주 . HH 6348 | 23684 | 2141 | 28800 | . HL 25 | 44 | 7 | 17 | . HN 8059 | 19684 | 2503 | 16395 | . LL 12 | 37 | 42 | 1443 | . LN 5 | 33 | 24 | 952 | . NH 1886 | 7849 | 1045 | 16837 | . NL 756 | 1448 | 990 | 21040 | . NN 36307 | 110047 | 36362 | 655178 | . tab.apply(lambda x: x*100 / sum(x), axis = 0) . 고혈압_당뇨_진료내역 1 2 3 4 . 혈압세부범주 . HH 11.888086 | 14.545589 | 4.965904 | 3.888413 | . HL 0.046818 | 0.027023 | 0.016236 | 0.002295 | . HN 15.092326 | 12.088978 | 5.805539 | 2.213560 | . LL 0.022473 | 0.022724 | 0.097416 | 0.194826 | . LN 0.009364 | 0.020267 | 0.055666 | 0.128534 | . NH 3.531967 | 4.820483 | 2.423807 | 2.273237 | . NL 1.415783 | 0.889293 | 2.296238 | 2.840702 | . NN 67.993183 | 67.585644 | 84.339194 | 88.458433 | . - 그런데 위에서 확인했듯이 고혈압 진료내역이 있다고 현재도 고혈압인것은 아니다 . - 그러니 혈압범주와 혈압세부범주를 비교하겠다 . - 또한 혈압범주를 혈압세부범주로 나눈것이 얼마나 유용할지도 판단하겠다 . tab2 = pd.crosstab(df[&#39;혈압세부범주&#39;], df[&#39;혈압범주&#39;]) tab2 . 혈압범주 고혈압 저혈압 정상혈압 . 혈압세부범주 . HH 60973 | 0 | 0 | . HL 93 | 0 | 0 | . HN 46641 | 0 | 0 | . LL 0 | 1534 | 0 | . LN 0 | 1014 | 0 | . NH 27617 | 0 | 0 | . NL 0 | 24234 | 0 | . NN 0 | 0 | 837894 | . - 우선 수축기고혈압이면서 이완기저혈압인사람은 93명이다 &gt; 백만명중에 93명이니 무시할만한 수준이다 . - 그리고 수축기저혈압이면서 이완기고혈압인 사람은 없다! . - 또한 혈압범주에서 정상이었으면 혈압세부범주에서도 정상이다 . - 저혈압인 사람중에서 둘다 저혈압인 사람은 적은데 고혈압인 사람중에서 둘다 고혈압인 사람은 50%정도이다 . - 그래서 혈압범주와 혈압세부범주는 얼마나 차이가 있는가? . - 간단히 plot을 통해 확인하겠다 . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;공복혈당&#39;&gt; . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;BMI&#39;&gt; . - 일단 혈압범주나 혈압세부범주를 가지고 수축기혈압이나 이완기혈압의 boxplot등을 그려보는것은 별로 유용하지 않다 . - 왜냐하면 애초애 수축기, 이완기혈압을 통해 혈압범주들을 구했기 때문이다(상관관계 매우큼) . - 또한 수축기혈압과 이완기혈압의 상관계수는 0.7이 넘는다 . - 당연히 고혈압인 사람은 혈압이 높게나오고 저혈압인 사람은 혈압이 낮게 나올것이다 . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;수축기혈압&#39;&gt; . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;수축기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;수축기혈압&#39;&gt; . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;이완기혈압&#39;&gt; . sns.violinplot(x = &#39;혈압세부범주&#39;, y = &#39;이완기혈압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압세부범주&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 그래서 결론은 혈압세부범주는 사용안하고 혈압범주만 사용할것이다 . - 문제가 되었던 고혈압과 저혈압을 둘다 가지고 있지만 혈압범주를 나누는 함수에서 고혈압을 먼저 처리하여 고혈압이 된 사람들은 문제가 없다 . - 왜냐하면 HL인 사람은 93명밖에 없으면 LH인 사람은 0명이기 때문이다 . - 애초애 저혈압인 사람은 3만명도 안되는데 고혈압인 사람은 12만명이 넘는다 . - 정상혈압인 사람은 혈압세부범주에서 NN인 사람으로 동일하다 . - 그리고 저혈압인 경우 HL, NL, LL 총 3가지가 있는데 대부분 HL(90%)이어서 문제 없다 . - 제일 차이가 나는건 고혈압인 경우이다(HH, HN, NH) . - HH인경우가 50%이고 HN은 30%, NH는 20%정도이다 . - 만약 둘다 고혈압인 경우와 하나만 고혈압인 경우가 많이 다르다면 고려할만 하지만 차이가 별로 없다 . - 하지만 위에서 그린 공복혈당, BMI 바이올린플랏을 보면 알수있듯이 거의 차이가 없다 . - 혈압범주를 세분화시킨건 여러개의 봉우리가 생긴원인이 이때문인지 확인하려고 한 것이다 . - 그런데 세분화시켰음에도 이는 동일하다 &gt; 그러니 혈압은 고혈압, 저혈압, 정상혈압으로만 나누겠다 . - 결론 : 혈압을 세분화시켜도 차이가 거의 없으니 시각화하기 편하게 3가지로만 나눈다 . df = df.drop(&#39;혈압세부범주&#39;, axis = 1) . &#47589;&#50517; . - 수축기혈압과 이완기혈압의 차이를 맥압이라고 하는데 수축기혈압과 이완기혈압 둘다 정상 범주에 속하더라도 맥압이 높다면 건강상에 문제가 있을 수 있다고 한다 . - 성인의 경우 35~45mmHg가 정상범주라고 한다 . - 참고 : http://assinmun.kr/m/page/view.php?no=4162&amp;code=20140925141337_5787&amp;d_code=20140925150830_7887&amp;ds_code= . - 맥압의 분포는 어떻게 되는지 살펴보도록 하겠다 . df[&#39;맥압&#39;] = df[&#39;수축기혈압&#39;] - df[&#39;이완기혈압&#39;] . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 맥압 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | 38 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | 40 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | 40 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | 41 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | 40 | . sns.histplot(data = df, x = &#39;맥압&#39;, binwidth = 5) . &lt;AxesSubplot:xlabel=&#39;맥압&#39;, ylabel=&#39;Count&#39;&gt; . - 눈에 띄는 봉우리가 2개 보인다(쌍봉 분포) . - 이완기혈압의 히스토그램을 그려봤을 때 봉우리가 2개(70, 80)였는데 10차이이다 . - 맥압의 경우 40과 50부근에 봉우리가 있는데 이역시 10차이이다 . - 맥압은 수축기혈압과 이완기혈압의 차이이므로 이완기혈압에 영향을 당연히 받는다 . - 중요한건 이완기혈압의 분포가 왜 쌍봉 분포인지를 파악하는것이다 . - 고혈압, 당뇨 진료내역에 따른 박스플랏을 그려보겠다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;맥압&#39;&gt; . - 고혈압, 당뇨 진료내역에 따른 수축기혈압, 이완기혈압 분포를 확인했을땐 당뇨병만 진료내역이 있는 경우와 둘 다 없는 경우의 분포가 비슷했는데 맥압의 경우는 다르다 . - 고혈압 진료내역이 있지만 현재는 혈압이 정상범주에 속해있을 수 도 있다 . - 그러니 고혈압, 당뇨 진료내역의 따른 맥압의 분포말고 건강검진을 받았을 당시의 혈압으로 구분하겠다 . - 혈압이 정상범주인 경우의 맥압의 분포와 그렇지 않은 경우 맥압의 분포를 비교하겠다 . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;맥압&#39;&gt; . - 저혈압의 경우 종모양을 띄고있다 . - 고혈압의 경우 눈에띄는 봉우리가 4개정도 보인다 . - 바이올린플랏을 보면 정상혈압에서 유달리 눈에띄는 2개의 봉우리를 볼 수 있는데 이 때문에 맥압이 쌍봉분포의 형태를 띄는것으로 보인다 . - 고혈압인 경우 맥압이 정상혈압, 저혈압인 경우보다 높다 . - 혈압이 오르면 수축기혈압의 상승폭이 이완기혈압의 상승폭보다 높다고 해석할 수 있다 . - 수축기혈압이 이완기혈압보다 기본적으로 높기에 어찌보면 당연하다 . - 한편 위의 출처에 나와있는 설명을 보면 나이가 들어감에따라 맥압이 높아진다고 한다 . - 연령대에 따른 박스플랏을 그려보겠다 . plt.figure(figsize = (12, 6)) sns.violinplot(x = &#39;연령대&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;연령대&#39;, ylabel=&#39;맥압&#39;&gt; . - 연령대가 높아질수록 평균 맥압은 증가하는것으로 보인다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;맥압&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;맥압&#39;&gt; . df.groupby(&#39;성별&#39;)[&#39;맥압&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 46.664977 | 9.35818 | 8.0 | 40.0 | 46.0 | 51.0 | 130.0 | . 2 489773.0 | 45.478534 | 10.20447 | 4.0 | 40.0 | 44.0 | 50.0 | 140.0 | . - 남자인 경우 여자인 경우보다 평균적으로 수축기혈압이 5정도 높았고 이완기혈압은 4정도 높았는데 맥압의 경우는 1정도 차이가 난다 . - 수축기혈압(5) - 이완기혈압(4) = 맥압(1) . - 하지만 통계적으로 유의한 차이가 아닐 수 도 있기에 평균차이검정을 실시하겠다 . - 특정값에 집중적으로 몰려있어 정규분포라 하기 어려울 수 있지만 종모양이고 표본 크기가 매우 크므로 t검정을 실행할 것이다 . x_B = df.query(&#39;성별 == 1&#39;)[&#39;맥압&#39;] ## 남자 x_NB = df.query(&#39;성별 == 2&#39;)[&#39;맥압&#39;] ## 여자 . # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=1875.218691424608, pvalue=0.0) . - 분산의 동일성 검정에서 p-value가 각각 0.0, 0.0으로 전체적으로 판단했을 때 . - 두 그룹의 분산이 동일하지 않으므로 이분산 가정 하에서 t검정을 실시한다 . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False) print(t_stat, pvalue) . 60.525582091193876 0.0 . - t통계량에 근거한 p-value가 0.0이므로 남자와 여자의 맥압은 다르다고 할 수 있다 . &#54792;&#50517;&#51032; &#45149;&#51088;&#47532;&#49688; &#54200;&#54693; . - 혈압의 끝자리수 편향에 대해 얘기하기전에 수축기혈압과 이완기혈압의 분포를 다시한번 시각화하겠다 . fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2) sns.histplot(data = df, x = &#39;수축기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors[::-1], binwidth = 5, ax = ax1) sns.histplot(data = df, x = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, palette = tab10_colors[::-1], binwidth = 2, ax = ax2) sns.histplot(data = df, x = &#39;수축기혈압&#39;, hue = &#39;혈압범주&#39;, binwidth = 5, ax = ax3) sns.histplot(data = df, x = &#39;이완기혈압&#39;, hue = &#39;혈압범주&#39;, binwidth = 2, ax = ax4) ax1.legend([&#39;없음&#39;, &#39;당뇨&#39;, &#39;고혈압&#39;, &#39;고혈압, 당뇨&#39;]) ax2.legend([&#39;없음&#39;, &#39;당뇨&#39;, &#39;고혈압&#39;, &#39;고혈압, 당뇨&#39;]) fig.tight_layout() . - 일단 고혈압, 당뇨 진료내역이 둘 다 없는 경우가 대부분이다 . - 진료내역이 아닌 고혈압, 정상혈압, 저혈압으로 나눠도 정상혈압이 대부분이다(혈당의 경우도 정상혈당이 대부분) . - 처음에 수축기혈압과 이완기혈압의 히스토그램을 그려봤을 때 봉우리가 많은것이 신기했다 . - 혈당이나 BMI의 히스토그램같이 종모양일 줄 알았기 때문이었다 . - 왜 혈압분포의 경우 봉우리가 많은지에 대해 성별, 연령대, 혈압범주로 나누어 살펴봤지만 알 수 없었다 . - 위의 분포를 보면 알겠지만 혈압범주로 나누는건 의미가 없고 성별, 연령대의 경우도 마찬가지었다 . - 봉우리가 너무 특정구간에만 몰려있는것이 이상했다 . - 그래서 혈압을 측정함에 있어 문제가 있는것이 아닐까 생각했다 . - 혈압을 측정하여 소수점이 나오면 이를 자연수로 만듦으로써 소수점 이하를 없애는데 측정자의 주관이 개입한것이다 . - 예컨대 수축기혈압이 138.7mmHg가 나왔다면 반올림하면 139mmHg이지만 숫자를 깔끔하게 하기 위해 140mmHg로 처리하는 것이다 . - 정말 그런건지 확인하겠다 . df[&#39;수축기_혈압_끝자리수&#39;] = list(map(lambda x: int(str(x)[-1]), df[&#39;수축기혈압&#39;])) df[&#39;이완기_혈압_끝자리수&#39;] = list(map(lambda x: int(str(x)[-1]), df[&#39;이완기혈압&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 맥압 수축기_혈압_끝자리수 이완기_혈압_끝자리수 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | 38 | 6 | 8 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | 40 | 0 | 0 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | 40 | 0 | 0 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | 41 | 1 | 0 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | 40 | 0 | 0 | . - 특정 숫자가 혈압의 끝자리수로 많이 등장할 이유는 없을 것이다 . - 그렇다면 끝자리수로 숫자마다 대략 10만개씩 등장할 것이다 . df.groupby(by = [&#39;수축기_혈압_끝자리수&#39;]).agg(&#39;size&#39;).reset_index().rename(columns = {0:&#39;count&#39;}). plot.bar(x = &#39;수축기_혈압_끝자리수&#39;, y = &#39;count&#39;, rot = 0, legend = False) . &lt;AxesSubplot:xlabel=&#39;수축기_혈압_끝자리수&#39;&gt; . - 수축기혈압의 전체 count수가 100만인데 약 40만개의 끝자리수가 $0$이다! . - $0$ 다음으로 많이 등장하는 숫자는 $5$이다 . - $0$과 $5$를 제외하고보면 홀수보다는 짝수가 더 많이 등장한다 . - 이완기혈압도 수축기혈압과 같은 양상을 보이는지 확인하겠다 . df.groupby(by = [&#39;이완기_혈압_끝자리수&#39;]).agg(&#39;size&#39;).reset_index().rename(columns = {0:&#39;count&#39;}). plot.bar(x = &#39;이완기_혈압_끝자리수&#39;, y = &#39;count&#39;, rot = 0, legend = False) . &lt;AxesSubplot:xlabel=&#39;이완기_혈압_끝자리수&#39;&gt; . - 이완기혈압도 수축기혈압과 마찬가지다 . - 수축기혈압과 이완기혈압의 분포에서 봉우리가 많이보인것은 끝자리수 편향 때문이었다 . - 눈에 띄게 높은 봉우리는 편향에 의한 끝자리수 $0$에 의한것이었고 자잘자잘한 봉우리는 $5$와 홀수보다 짝수가 더 선호되기 때문이었다 . - 수축기혈압의 봉우리가 이완기혈압의 봉우리보다 많은것은 수축기혈압이 이완기혈압보다 더 넓게 분포되었기 때문이다(ex) 끝자리가 $0$인 숫자의 개수가 더 많다) . df = df.drop([&#39;수축기_혈압_끝자리수&#39;, &#39;이완기_혈압_끝자리수&#39;], axis = 1) . - 이제 공복혈당의 분포를 확인하겠다 . &#44277;&#48373;&#54792;&#45817; . sns.histplot(data = df, x = &#39;공복혈당&#39;, binwidth = 5) . &lt;AxesSubplot:xlabel=&#39;공복혈당&#39;, ylabel=&#39;Count&#39;&gt; . - 오른쪽으로 꼬리가 긴 분포이다 . - 성별에 따라 공복혈당이 다른지 확인하겠다 . sns.violinplot(x = &#39;성별&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;성별&#39;, ylabel=&#39;공복혈당&#39;&gt; . - 성별에 따라 공복혈당은 비슷해보인다 . - 수치로 확인하겠다 . df.groupby(&#39;성별&#39;)[&#39;공복혈당&#39;].describe() . count mean std min 25% 50% 75% max . 성별 . 1 510227.0 | 101.141925 | 24.891629 | 60.0 | 88.0 | 96.0 | 106.0 | 358.0 | . 2 489773.0 | 96.491818 | 20.538645 | 60.0 | 86.0 | 93.0 | 101.0 | 358.0 | . - 남자가 여자보다 공복혈당이 평균 5정도 높고 표준편차가 4정도 높다 . - 혈압과 혈당을 보면 남자가 여자보다 살짝 높은정도를 제외하면 차이가 없다 . - $ text{남자} = text{여자} + alpha$ 와 같이 어느 한쪽으로 나머지를 나타낼 수 있어 보인다 . - 이제껏 분석한 내용을 보면 성별은 그다지 중요한 정보가 아닌것 같다 . - 고혈압_당뇨 진료내역에 따른 공복혈당의 분포를 확인하겠다 . sns.violinplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;공복혈당&#39;&gt; . df.groupby(&#39;고혈압_당뇨_진료내역&#39;)[&#39;공복혈당&#39;].describe() . count mean std min 25% 50% 75% max . 고혈압_당뇨_진료내역 . 1 53398.0 | 130.447114 | 40.524698 | 60.0 | 104.0 | 122.0 | 145.0 | 358.0 | . 2 162826.0 | 99.671023 | 16.816511 | 60.0 | 90.0 | 97.0 | 106.0 | 351.0 | . 3 43114.0 | 134.759892 | 45.923753 | 60.0 | 104.0 | 124.0 | 151.0 | 358.0 | . 4 740662.0 | 94.320677 | 15.557456 | 60.0 | 86.0 | 93.0 | 100.0 | 358.0 | . - 4개의 분포 모두 공복혈당이 큰 쪽에 이상점이 매우 많다 . - 고혈압, 당뇨 둘 다 진료내역이 있는 경우와 당뇨 진료내역이 있는 경우의 분포는 당뇨만 있는 경우가 조금 더 넓게 퍼진것을 빼면 동일하다 . - 분포의 중심은 125인것으로 보인다 . - 고혈압, 당뇨 둘 다 진료내역이 없는 경우와 고혈압만 있는 경우의 분포는 고혈압만 있는 경우가 조금 더 넓게 퍼진것을 빼면 동일하다 . - 분포의 중심은 95인것으로 보인다 . - 당뇨가 있다면 공복혈당이 평균적으로 30정도 높다 . - 위의 그림을 통해 공복혈당의 분포는 당뇨병의 진료내역이 좌지우지하는것으로 보인다(고혈압 진료내역은 거의 영향을 끼치지 못한다) . sns.violinplot(x = &#39;혈압범주&#39;, y = &#39;공복혈당&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;공복혈당&#39;&gt; . - 고혈압인 경우 공복혈당이 고혈압이 아닌경우보다 더 높은것으로 보인다 . - 고혈압이 있는 사람들중 공복혈당이 높은 사람이 많다 . &#44277;&#48373;&#54792;&#45817; &#44256;&#52272; . - 위에서 공복혈당 분포를 살펴봤는데 당뇨 진료내역이 있지만 공복혈당이 낮은 사람도 있고 당뇨 진료내역이 없지만 공복혈당이 높은사람도 있었다 . - 당뇨 진료내역이 있지만 공복혈당이 정상범주안에 있는 사람은 혈당조절을 잘하고 있는것으로 간주할 수 있을 것 같다 . - 이들의 비율을 확인하겠다 . - 당뇨병의 진단에 있어 혈당치의 기준은 공복 혈당치 126 mg/dL 이상(고혈당)이라고 한다 . - 참고 : https://www.diabetes.or.kr/general/class/index.php?idx=5 . - 위에서 기준을 넘어가는 혈당을 가진 사람들은 고혈당으로 그렇지 않는 사람은 정상혈당으로 간주하겠다 . - 공복혈당이 너무 낮으면(60 mg/dL이하) 저혈당으로 간주하나 거의 최소값이 60 mg/dL임으로 무시하겠다 . def g(x): if x &gt;= 126: y = &#39;고혈당&#39; else: y = &#39;정상혈당&#39; return y . df[&#39;혈당범주&#39;] = list(map(g, df[&#39;공복혈당&#39;])) . df.head() . 성별 연령대 수축기혈압 이완기혈압 공복혈당 고혈압_당뇨_진료내역 BMI 혈압범주 혈당범주 . 0 1 | 20대초반 | 116 | 78 | 94 | 4 | 16.6 | 정상혈압 | 정상혈당 | . 1 1 | 20대초반 | 100 | 60 | 79 | 4 | 22.3 | 정상혈압 | 정상혈당 | . 2 1 | 20대초반 | 100 | 60 | 87 | 4 | 21.9 | 정상혈압 | 정상혈당 | . 3 1 | 20대초반 | 111 | 70 | 72 | 4 | 20.2 | 정상혈압 | 정상혈당 | . 4 1 | 20대초반 | 120 | 80 | 98 | 4 | 20.0 | 정상혈압 | 정상혈당 | . count = df.groupby(&#39;혈당범주&#39;).size() . plt.pie(x = count, labels = [&#39;고혈당&#39;, &#39;정상혈당&#39;], autopct = &#39;%.2f%%&#39;) plt.show() . - 정상혈당은 약 93%, 고혈당은 약 7% 이다 . tab = pd.crosstab(df[&#39;혈당범주&#39;], df[&#39;고혈압_당뇨_진료내역&#39;]) tab.apply(lambda x: x*100 / sum(x), axis = 0) . 고혈압_당뇨_진료내역 1 2 3 4 . 혈당범주 . 고혈당 44.911794 | 5.178534 | 47.938025 | 2.412976 | . 정상혈당 55.088206 | 94.821466 | 52.061975 | 97.587024 | . - 위를 보면 고혈압_당뇨 둘 다 없는경우 2.5%정도는 혈당에 문제가 있는것을 알 수 있다 . - 앞서 봤던 고혈압(12%)에 비하면 매우 적은 수치이다 . - 고혈압만 있는 경우 고혈당인 경우는 5%정도로 고혈압 당뇨 둘다 없는경우와 비슷한 수치이다 . - 당뇨 진료내역이 있는 경우 고혈당인 경우는 47%정도이다 . - 고혈압 진료내역이 있는 경우 고혈압인 경우는 31%정도였다 . - 이와 비교하면 고혈압에서 정상혈압에 속하는 것보다 고혈당에서 정상혈당에 속하는것이 흔치않음을 알 수 있다 . - 전체 인구를 혈압, 혈당에 따라 나타내 확인하겠다 . tab = pd.crosstab(df[&#39;혈압범주&#39;], df[&#39;혈당범주&#39;]) tab*100 / 1000000 . 혈당범주 고혈당 정상혈당 . 혈압범주 . 고혈압 1.7877 | 11.7447 | . 저혈압 0.0918 | 2.5864 | . 정상혈압 5.2159 | 78.5735 | . - 전체 중 고혈당은 8%, 고혈압은 12%이다 . - 혈압, 혈당 모두 정상인 사람은 78%이다 . - 결론 : 당뇨가 고혈압보다 흔하며 당뇨인 사람중 고혈압인 비율보다 고혈압인 사람중 당뇨인 비율이 더 낮다 . &#54792;&#50517;, &#54792;&#45817; &#48276;&#51452; vs &#44256;&#54792;&#50517;, &#45817;&#45544; &#51652;&#47308;&#45236;&#50669; . - 한가지 의문점이 든다 . - 위에서 봤듯이 고혈압, 당뇨 진료내역이 있다고 현재도 고혈압, 당뇨인것은 아니다 . - 그러면 고혈압, 당뇨 진료내역은 쓸모있는지가 의문이다 . - 그냥 혈압, 혈당 범주로 대체하면 될것같다 . - 고혈압, 당뇨 진료내역에 따라 수축기혈압에 차이가 있었다 . - 그런데 이 차이가 그냥 고혈압에 의한것이라면?? . - 고혈압 진료내역이 있으면 혈압이 정상범주더라도 높은쪽에 위치할것이라 생각했다 . - 이것이 아니라면 굳이 애매모호한 고혈압 진료내역 대신에 혈압범주를 사용하는것이 좋을것이다(당뇨도 마찬가지) . - 이를 평균 차이 검정을 통해 확인하겠다 . - 혈압(수축기, 이완기)과 혈당에 대해 특정 값에 데이터가 많이 몰려있어 정규분포는 아닌것처럼 보이지만 . - 표본크기가 매우 크고 종모양이기에 t검정을 실시하겠다 . - 우선 등분산인지 검정하겠다 . &#49688;&#52629;&#44592; &#54792;&#50517; . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;정상혈압&quot;&#39;), y = &#39;수축기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;수축기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;수축기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=3281.337451885476, pvalue=0.0) . - p-value가 0이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (123.56359921833364, 117.8503658501316) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = True, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 183.60168146108893 0.0 . - t통계량에 근거한 p-value가 0이다 . - 정상혈압 범주에 속하더라도 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 수축기혈압이 높다고 할 수 있다 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;고혈압&quot;&#39;), y = &#39;수축기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;수축기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;수축기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=5.967971491616882, pvalue=0.014569299214451329) . - p-value가 0.015이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (146.45712425457612, 143.02040002952248) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 56.10982828533957 0.0 . - t통계량에 근거한 p-value가 0이다 . - 고혈압 범주에 속하더라도 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 수축기혈압이 높다고 할 수 있다 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;저혈압&quot;&#39;), y = &#39;수축기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;수축기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;수축기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;수축기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=294.86340294030697, pvalue=9.754371916406274e-66) . - p-value가 0이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (108.05237887385421, 100.26552611163285) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 32.08308134495256 1.7389384139189746e-190 . - t통계량에 근거한 p-value가 0이다 . - 저혈압 범주에 속하더라도 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 수축기혈압이 높다고 할 수 있다 . &#51060;&#50756;&#44592; &#54792;&#50517; . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;정상혈압&quot;&#39;), y = &#39;이완기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;정상혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=2356.370080988216, pvalue=0.0) . np.mean(x_B),np.mean(x_NB) . (75.8151400030064, 73.81038696243168) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 98.5367189947476 0.0 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;고혈압&quot;&#39;), y = &#39;이완기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;고혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=886.1776754493117, pvalue=4.221002676847139e-194) . np.mean(x_B),np.mean(x_NB) . (88.67230944524186, 90.75784190715181) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . -43.85799935873388 1.0 . sns.boxplot(data = df.query(&#39;혈압범주 == &quot;저혈압&quot;&#39;), y = &#39;이완기혈압&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;이완기혈압&#39;&gt; . x_B = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 1) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 2)&#39;)[&#39;이완기혈압&#39;] x_NB = df.query(&#39;(혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 3) or (혈압범주 == &quot;저혈압&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;이완기혈압&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=15.370482832670643, pvalue=8.85777173868185e-05) . np.mean(x_B),np.mean(x_NB) . (56.317765168048886, 56.322322485811114) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . -0.07423781188396941 0.5295867869938078 . - 이완기혈압은 수축기혈압과 다른 양상을 보였다 . - 정상혈압에 속하는 경우를 제외하면 고혈압 진료내역이 있는 경우 그렇지 않은 경우보다 . - 이완기혈압이 더 높다고 할 수 없다 . &#44277;&#48373;&#54792;&#45817; . sns.boxplot(data = df.query(&#39;혈당범주 == &quot;고혈당&quot;&#39;), y = &#39;공복혈당&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;공복혈당&#39;&gt; . x_B = df.query(&#39;(혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 1) or (혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 3)&#39;)[&#39;공복혈당&#39;] x_NB = df.query(&#39;(혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 2) or (혈당범주 == &quot;고혈당&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;공복혈당&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=723.8340005554786, pvalue=1.234539994480611e-158) . - p-value가 0.015이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (165.37926091825307, 152.71555656934308) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 41.82511929437937 0.0 . - t통계량에 근거한 p-value가 0이다 . - 고혈당 범주에 속하더라도 당뇨 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 공복혈당이 높다고 할 수 있다 . sns.boxplot(data = df.query(&#39;혈당범주 == &quot;정상혈당&quot;&#39;), y = &#39;공복혈당&#39;, x = &#39;고혈압_당뇨_진료내역&#39;) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;공복혈당&#39;&gt; . x_B = df.query(&#39;(혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 1) or (혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 3)&#39;)[&#39;공복혈당&#39;] x_NB = df.query(&#39;(혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 2) or (혈당범주 == &quot;정상혈당&quot; and 고혈압_당뇨_진료내역 == 4)&#39;)[&#39;공복혈당&#39;] # print(stats.bartlett(x_B, x_NB)) print(stats.levene(x_B, x_NB)) . LeveneResult(statistic=7492.881978979407, pvalue=0.0) . - p-value가 0.015이다 . - 그러니 이분산 가정하에 t검정을 실시하겠다 . np.mean(x_B),np.mean(x_NB) . (103.95798465157533, 93.5627473825332) . t_stat, pvalue = stats.ttest_ind(x_B, x_NB, equal_var = False, alternative = &#39;greater&#39;) . print(t_stat, pvalue) . 171.357714380074 0.0 . - t통계량에 근거한 p-value가 0이다 . - 정상혈당 범주에 속하더라도 당뇨 진료내역이 있는 경우 그렇지 않은 경우보다 . - 평균 공복혈당이 높다고 할 수 있다 . - plot을 그려보고 가설검정을 통해 진료내역이 영향을 끼치는 것을 알 수 있었다 . - 이제 BMI의 분포를 확인하겠다 . BMI . sns.histplot(data = df, x = &#39;BMI&#39;, hue = &#39;성별&#39;, binwidth = 0.5) . &lt;AxesSubplot:xlabel=&#39;BMI&#39;, ylabel=&#39;Count&#39;&gt; . - 종모양인 것 같지만 오른쪽으로 꼬리가 조금 길다 . - BMI도 다른 양적변수와 마찬가지로 남자가 여자보다 조금 더 높은것을 제외하면 동일하다 . - BMI의 분포를 혈압범주, 혈당범주에 따라 시각화해보자 . sns.boxplot(x = &#39;혈압범주&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈압범주&#39;, ylabel=&#39;BMI&#39;&gt; . df.groupby(&#39;혈압범주&#39;)[&#39;BMI&#39;].describe() . count mean std min 25% 50% 75% max . 혈압범주 . 고혈압 135324.0 | 25.242038 | 3.448873 | 14.8 | 22.9 | 25.0 | 27.3 | 40.3 | . 저혈압 26782.0 | 21.835046 | 2.736182 | 14.8 | 19.9 | 21.6 | 23.5 | 38.0 | . 정상혈압 837894.0 | 23.634720 | 3.213817 | 14.8 | 21.4 | 23.4 | 25.6 | 40.3 | . - 고혈압은 정상혈압보다 BMI가 평균적으로 1.6 크다 . - 정상혈압은 저혈압보다 BMI가 평균적으로 1.8 크다 . sns.boxplot(x = &#39;혈당범주&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;혈당범주&#39;, ylabel=&#39;BMI&#39;&gt; . df.groupby(&#39;혈당범주&#39;)[&#39;BMI&#39;].describe() . count mean std min 25% 50% 75% max . 혈당범주 . 고혈당 70954.0 | 25.168695 | 3.396526 | 14.8 | 22.9 | 24.9 | 27.1 | 40.3 | . 정상혈당 929046.0 | 23.699806 | 3.266234 | 14.8 | 21.4 | 23.5 | 25.7 | 40.3 | . - 고혈당인 경우 정상혈당보다 BMI가 평균적으로 1.5정도 크다 . - 고혈압과 당뇨가 끼치는 영향을 같이 확인하겠다 . sns.boxplot(x = &#39;고혈압_당뇨_진료내역&#39;, y = &#39;BMI&#39;, data = df) . &lt;AxesSubplot:xlabel=&#39;고혈압_당뇨_진료내역&#39;, ylabel=&#39;BMI&#39;&gt; . - 고혈압 진료내역만 있는 경우가 당뇨 진료내역만 있는 경우보다 BMI가 크다 . - 여기까지 개별 양적변수에 대한 분포를 확인했다 . - 그런데 수축기혈압과 이완기혈압같이 두 변수사이에 관계가 있을 수 있다 . - 그렇기에 산점도를 그려 변수사이에 관계를 확인하겠다 . &#46160; &#48320;&#49688;&#51032; &#49884;&#44033;&#54868; . &#49345;&#44288;&#44288;&#44228; &#54665;&#47148; . - 우선 양적변수간의 상관관계 행렬을 그려보겠다 . corr_df = df.loc[:, (&#39;수축기혈압&#39;, &#39;이완기혈압&#39;, &#39;맥압&#39;, &#39;공복혈당&#39;, &#39;BMI&#39;)] . corr_matrix = corr_df.corr(method = &#39;pearson&#39;) # 상관관계 행렬 . corr_matrix . 수축기혈압 이완기혈압 맥압 공복혈당 BMI . 수축기혈압 1.000000 | 0.743006 | 0.743398 | 0.186501 | 0.304383 | . 이완기혈압 0.743006 | 1.000000 | 0.104699 | 0.138717 | 0.275492 | . 맥압 0.743398 | 0.104699 | 1.000000 | 0.138498 | 0.176977 | . 공복혈당 0.186501 | 0.138717 | 0.138498 | 1.000000 | 0.173688 | . BMI 0.304383 | 0.275492 | 0.176977 | 0.173688 | 1.000000 | . sns.heatmap(corr_matrix, annot = True, cbar = False) . &lt;AxesSubplot:&gt; . - 수축기혈압과 이완기혈압은 상관계수가 0.74로 높다 . - 혈압과 혈당끼리는 상관관계가 강하지 않다 . - BMI와 혈압과는 약한 양의 상관관계가 있다 . - BMI는 혈당보다는 혈압에 영향을 더 받는다 . - 신기한게 맥압은 수축기혈압과 이완기혈압의 차이여서 이완기혈압과의 상관관계가 당연히 크다고 생각했는데 아니었다 . - 맥압과 이완기혈압의 상관계수는 0.1이다(서로 상관이 없는 수준이다) . - 이제 두 변수 사이의 관계를 시각화하겠다 . def jitter(values, i): return values + np.random.normal(i, 0.5, len(values)) . sns.scatterplot(x = jitter(df.수축기혈압, 1), y = jitter(df.이완기혈압, 1), alpha = 0.01, s = 20) . &lt;AxesSubplot:xlabel=&#39;수축기혈압&#39;, ylabel=&#39;이완기혈압&#39;&gt; . - 문제가 있는데 관측치(점의 개수)가 너무 많아 시각화가 제대로 되지 않는다 . - 전체의 1%(10000개) 정도만 무작위 추출하여 산점도를 그려보겠다 . - 참고 : https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html . np.random.seed(2021) df_s = df.sample(frac = 0.01) . ft = df_s[&#39;고혈압_당뇨_진료내역&#39;].value_counts() rft = df_s[&#39;고혈압_당뇨_진료내역&#39;].value_counts() / len(df_s[&#39;고혈압_당뇨_진료내역&#39;]) DIS_table2 = pd.DataFrame({&#39;Freq&#39;: ft, &#39;Relative freq&#39;: rft}) DIS_table2 . Freq Relative freq . 4 7336 | 0.7336 | . 2 1664 | 0.1664 | . 1 560 | 0.0560 | . 3 440 | 0.0440 | . - 원본과 비율이 거의 동일하다 . - 새로운 데이터프레임을 사용해 시각화하겠다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; &#51060;&#50756;&#44592;&#54792;&#50517; . sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;이완기혈압&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) . &lt;seaborn.axisgrid.FacetGrid at 0x21109aacac0&gt; . - 수축기혈압은 90~140, 이완기 혈압은 60~90사이에 데이터가 많이 몰려있다 . model = smf.ols(formula = &#39;이완기혈압 ~ 수축기혈압&#39;, data = df) result = model.fit() result.params # 추정된 직선의 기울기 및 절편 . Intercept 14.887860 수축기혈압 0.499706 dtype: float64 . - 임의로 이완기혈압을 종속변수, 수축기혈압을 독립변수로 설정하고 회귀선을 추정하면 다음과 같다 . - 추정된 회귀선 : $ widehat{ text{이완기혈압}}=14.887860+0.499706 times text{수축기혈압}$ . - 이를 통해 수축기혈압이 1단위 올라갈 때 이완기혈압은 0.5단위 올라간다는 것을 알 수 있다 . - 위에서 수축기혈압에 대해 얘기할 때 수축기혈압의 증가폭(10)이 이완기혈압의 증가폭(5)보다 더 크다고 했었다 . - 이를 추정된 회귀선을 통해 해석하면 수축기혈압이 10mmHg 상승했으니 이완기혈압이 5mmHg 상승했다고 할 수 있다 . - 근데 사실 시각화의 목적은 진료내역에 따른 차이를 확인하는 것이다 . - 고혈압_당뇨 진료내역을 색깔변수로 하여 산점도를 그려보겠다 . lmplot = sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;이완기혈압&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;이완기혈압 ~ 수축기혈압&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 24.020584 수축기혈압 0.416237 dtype: float64 - 고혈압 Intercept 20.632209 수축기혈압 0.455056 dtype: float64 - 당뇨 Intercept 20.112536 수축기혈압 0.450584 dtype: float64 - 없음 Intercept 11.217272 수축기혈압 0.532116 dtype: float64 - . - 진료내역이 없는 경우 회귀선의 기울기가 고혈압 진료내역이 있는 경우 회귀선의 기울기보다 더 크다 . - 즉 고혈압 진료내역이 있는 경우 진료내역이 없는 경우보다 수축기혈압이 상승했을 때 이완기혈압의 상승폭이 작다는 의미이다 . - 고혈압, 당뇨병 진료내역 둘다 없는 사람들의 경우 수축기혈압은 80~140, 이완기 혈압은 50~90사이에 데이터가 많이 몰려있다 . - 우선 고혈압_당뇨가 진료내역이 2(고혈압만)인 경우와 1(둘 다 있음)인 경우 비슷한 산점도를 보인다 . - 그런데 고혈압_당뇨가 진료내역이 3(당뇨만)인 경우 고혈압_당뇨 진료내역이 1,2인 경우보다 이완기혈압과 수축기혈압이 낮은쪽에 점이 위치하고 있음을 알 수 있다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; &#44277;&#48373;&#54792;&#45817; . lmplot = sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;공복혈당&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . - 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 공복혈당은 60~140 수축기혈압은 90~150사이에 대부분의 데이터가 존재한다 . - 당뇨 진료내역은 없고 고혈압 진료내역만 있는 경우 확실히 당뇨 진료내익이 있는 경우보다 공복혈당이 낮은곳에 데이터가 분포함을 확인할 수 있다 . - 고혈압 진료내역만 있는 경우는 고혈압, 당뇨 진료내역 둘 다 없는 경우의 산점도와 비슷하다 . - 당뇨 진료내역이 있다면 추가로 고혈압 진료내역이 있다고해서 산점도가 달라지지는 않는것으로 보이며 둘이 비슷하다 . - 추세선을 보면 당뇨 진료내역 유무에 따른 차이가 확실히 보인다 . - 당뇨 진료내역 없다면 공복혈당은 확실히 낮다 . - 당뇨병은 혈당으로 판단하기에 당연한 결과이긴 하다 . &#49688;&#52629;&#44592;&#54792;&#50517;&#44284; BMI . lmplot = sns.lmplot(x = &#39;수축기혈압&#39;, y = &#39;BMI&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;BMI ~ 수축기혈압&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 22.524843 수축기혈압 0.021394 dtype: float64 - 고혈압 Intercept 22.313435 수축기혈압 0.019930 dtype: float64 - 당뇨 Intercept 18.758148 수축기혈압 0.044647 dtype: float64 - 없음 Intercept 14.351341 수축기혈압 0.076078 dtype: float64 - . - 위의 회귀선을 보면 진료내역이 없는 경우의 기울기가 크고 . - 고혈압 진료내역 있는 경우의 기울기는 작다 . - 하지만 절편을 보면 고혈압 진료내역이 있는 경우가 진료내역이 없는 경우보다 더 크다 . - 이는 진료내역이 없는 경우 변동성이 꽤 있어 기울기가 크고 . - 고혈압 진료내역이 있는 경우 기본적으로 BMI가 높으므로 더 높아지기 어려우니 기울기가 작다고 볼 수 있다 . - 한편 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 BMI은 17~30 수축기혈압은 90~150사이에 대부분의 데이터가 존재하며 . - 진료내역이 있는 경우보다 BMI와 수축기혈압이 낮은곳에 더 많은 데이터가 분포한다 . - 산점도를 보면 당뇨 진료내역만 있는 경우 수축기혈압이 낮은 곳에 데이터가 분포하고 있으며 . - BMI도 고혈압 진료내역이 있는 경우보다 낮은 곳에 분포함을 알 수 있다 . - 당뇨 진료내역만 있는 경우 수축기혈압은 90~140, BMI는 17~30사이에 데이터가 몰려있다 . - 고혈압 진료내역이 있는 경우에는 수축기혈압은 100~160, BMI는 17~33사이에 데이터가 몰려있다 . - 고혈압 진료내역만 있는 경우와 둘 다 있는 경우의 분포는 서로 유사하다 . - 추세선을 보면 약한 양의 상관관계가 있긴하다 . - 당뇨 진료내역만 있는 경우 추세선의 기울기 조금더 가파르다 . - 당뇨 진료내역만 있는 경우의 데이터가 고혈압 진료내역만 있는 경우의 데이터보다 덜 퍼져있어서 그런것으로 보인다 . &#51060;&#50756;&#44592;&#54792;&#50517;&#44284; &#44277;&#48373;&#54792;&#45817; . lmplot = sns.lmplot(x = &#39;이완기혈압&#39;, y = &#39;공복혈당&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . - 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 공복혈당은 60~140 이완기혈압은 50~90사이에 대부분의 데이터가 존재한다 . - 당뇨 진료내역은 없고 고혈압 진료내역만 있는 경우 확실히 당뇨 진료내역이 있는 경우보다 공복혈당이 낮은곳에 데이터가 분포함을 확인할 수 있다 . - 고혈압 진료내역만 있는 경우는 고혈압, 당뇨 진료내역 둘 다 없는 경우의 산점도와 비슷하다 . - 당뇨 진료내역이 있다면 추가로 고혈압 진료내역이 있다고해서 산점도가 달라지지는 않는것으로 보이며 둘이 비슷하다 . - 추세선을 보면 당뇨 진료내역 유무에 따른 차이가 확실히 보인다 . - 당뇨 진료내역이 없다면 공복혈당은 확실히 낮다 . - 이완기혈압은 혈압의 일종이며 상관계수도 높기에 수축기혈압과 거의 동일한 양상을 보였다 . &#51060;&#50756;&#44592;&#54792;&#50517;&#44284; BMI . lmplot = sns.lmplot(x = &#39;이완기혈압&#39;, y = &#39;BMI&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;BMI ~ 이완기혈압&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 21.618056 이완기혈압 0.047214 dtype: float64 - 고혈압 Intercept 22.023624 이완기혈압 0.036128 dtype: float64 - 당뇨 Intercept 19.093825 이완기혈압 0.068319 dtype: float64 - 없음 Intercept 16.095016 이완기혈압 0.098144 dtype: float64 - . - 위의 회귀선을 보면 수축기혈압의 경우와 마찬가지로 진료내역이 없는 경우의 기울기가 크고 . - 고혈압 진료내역 있는 경우의 기울기는 작다 . - 하지만 절편을 보면 고혈압 진료내역이 있는 경우가 진료내역이 없는 경우보다 더 크다 . - 이는 진료내역이 없는 경우 변동성이 꽤 있어 기울기가 크고 . - 고혈압 진료내역이 있는 경우 기본적으로 BMI가 높으므로 더 높아지기 어려우니 기울기가 작다고 볼 수 있다 . - 한편 고혈압, 당뇨 진료내역 둘 다 없는 경우 산점도를 보면 BMI은 16~30 이완기혈압은 55~90사이에 대부분의 데이터가 존재하며 . - 고혈압 또는 당뇨 진료내역이 있는 경우보다 BMI와 이완기혈압이 낮은곳에 더 많은 데이터가 분포한다 . - 산점도를 보면 당뇨 진료내역만 있는 경우 이완기혈압이 낮은 곳에 데이터가 분포하고 있으며 . - BMI도 고혈압 진료내역이 있는 경우보다 낮은 곳에 분포함을 알 수 있다 . - 당뇨 진료내역만 있는 경우 이완기혈압은 60~90, BMI는 17~28사이에 데이터가 몰려있다 . - 고혈압 진료내역이 있는 경우에는 이완기혈압은 60~100, BMI는 17~33사이에 데이터가 몰려있다 . - 고혈압 진료내역만 있는 경우와 고혈압, 당뇨 진료내역이 둘다 있는 경우의 산점도는 서로 유사하다 . - 추세선을 보면 약한 양의 상관관계가 있긴하다 . - 당뇨 진료내역만 있는 경우 추세선의 기울기 조금더 가파르다 . - 당뇨 진료내역만 있는 경우의 데이터가 고혈압 진료내역만 있는 경우의 데이터보다 덜 퍼져있어서 그런것으로 보인다 . - 이완기혈압과 BMI의 산점도는 수축기혈압과 BMI의 산점도와 비슷한 양상을 보였다 . &#44277;&#48373;&#54792;&#45817;&#44284; BMI . lmplot = sns.lmplot(x = &#39;공복혈당&#39;, y = &#39;BMI&#39;, hue = &#39;고혈압_당뇨_진료내역&#39;, scatter_kws = {&#39;alpha&#39;:0.4, &#39;s&#39;:20}, height = 7, data = df_s) for lh in lmplot._legend.legendHandles: lh.set_alpha(1) lh._sizes = [50] . str_ = [&#39;고혈압, 당뇨&#39;, &#39;고혈압&#39;, &#39;당뇨&#39;, &#39;없음&#39;] for i in [1, 2, 3, 4]: model = smf.ols(formula = &#39;BMI ~ 공복혈당&#39;, data = df.query(&#39;고혈압_당뇨_진료내역 == @i&#39;)) result = model.fit() print(str_[i-1]) print(result.params) # 추정된 직선의 기울기 및 절편 print(&#39;-&#39;) . 고혈압, 당뇨 Intercept 24.775887 공복혈당 0.004156 dtype: float64 - 고혈압 Intercept 22.707251 공복혈당 0.022154 dtype: float64 - 당뇨 Intercept 23.707968 공복혈당 0.004127 dtype: float64 - 없음 Intercept 19.893091 공복혈당 0.037433 dtype: float64 - . - 위의 회귀선을 보면 진료내역이 없는 경우와 고혈압 진료내역 있는 경우 기울기가 크고 . - 당뇨 진료내역 있는 경우의 기울기는 작다 . - 절편도 진료내역이 없는 경우를 제외하면 큰 차이가 있지는 않다 . - 이는 진료내역이 없는 경우 변동성이 꽤 있어 기울기가 크고 . - 당뇨 진료내역이 있는 경우 기본적으로 공복혈당이 높으므로 더 높아지기 어려우니 기울기가 작다고 볼 수 있다 . - 한편 고혈압, 당뇨 진료내역이 없는 산점도를 보면 BMI는 16~33, 공복혈당은 60~130인 구간에 대부분의 데이터가 존재함을 알 수 있다 . - 당뇨 진료내역 유무에 따라 공복혈당에는 큰 차이가 있다 . - 고혈압 진료내역만 있는 경우에 그렇지않은 경우보다 BMI가 더 넓게 퍼져있다 . - 당뇨 진료내역만 있는 경우에는 BMI가 조금 더 좁게 퍼져있는 것으로 보인다 . - 추세선을 보면 당뇨 진료내역만 있는 경우에는 약한 양의 상관관계가 있는 것으로 보여진다 . - 그 외에 경우에는 BMI와 공복혈당은 관계가 없는 것으로 보인다 . &#44208;&#47200; . - 고혈압/당뇨 둘 다 진료내역 없음이 74%로 가장 많이 차지한다 . - 당뇨 진료내역만 있는 경우는 4%, 고혈압 진료내역만 있는 경우는 16%, 둘다 있는 경우는 5%이다 . - 대체로 남자는 여자보다 수축기혈압과 이완기혈압, 맥압, 공복혈당, BMI가 높다 . - 수축기혈압과 이완기혈압의 상관계수는 0.74이고 BMI와 혈압의 상관계수는 약 0.3이다 . - 이들을 제외한 나머지 변수사이의 상관계수는 0.2보다 작은 수준이다 . - 연령대가 높아질수록 수축기혈압, 이완기혈압은 높아지는 경향을 보인다 . - 그러나 이완기혈압의 경우 고혈압, 당뇨 진료내역이 없는 경우를 제외하면 높아지다가 내려가는 경향을 보인다 . - 고혈압 또는 당뇨 진료내역이 있는 사람은 진료내역이 없는 사람과 비교하여 . - 이완기혈압을 제외하면 평균적으로 혈압 또는 혈당이 높다 . - 정상혈압인 경우를 제외하면 오히려 이완기 혈압이 더 낮았다 . - 수축기혈압과 이완기혈압의 분포에서 많은 봉우리를 관찰할 수 있는데 이는 혈압의 끝자리수 편향때문이다 .",
            "url": "https://jaesu26.github.io/green/python/visualization/2021/10/01/%ED%98%88%EC%95%95%ED%98%88%EB%8B%B9%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D.html",
            "relUrl": "/python/visualization/2021/10/01/%ED%98%88%EC%95%95%ED%98%88%EB%8B%B9%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "자료구조 덱(deque)",
            "content": "&#45937;(deque) . - 양쪽 끝에서 삽입과 삭제가 모두 가능한 자료 구조의 한 형태 . - 두 개의 포인터를 사용하여 양쪽에서 삭제와 삽입을 발생 시킬 수 있음 &gt; 큐와 스택을 합친 형태 . - 참고: 자료구조 덱 . &#45937;(deque) &#49324;&#50857; . - 파이썬에서 deque는 from collections import deque를 실행한 후 deque()통해 구현할 수 있다 . - deque.append(x)를 통해 덱에 x를 오른쪽(뒤)에 push한다 . - deque.appendleft(x)를 통해 덱에 x를 왼쪽(앞)에 push한다 . - deque.pop()를 통해 덱에서 뒤의 원소를 pop한다 . - deque.popleft()를 통해 덱에서 앞의 원소를 pop한다 . - 참고: deque in python . &#50696;&#51228; . from collections import deque ## 덱(deque)를 사용하기 위해 deque라이브러리 import deque = deque([1, 2, 3, 4, 5]) ## 큐(queue) 자료구조 생성 &gt; deque([1, 2, 3, 4, 5]) deque.append(1) ## 덱의 뒤에 1 추가 &gt; deque([1, 2, 3, 4, 5, 1]) deque.appendleft(2) ## 덱의 앞에 2 추가 &gt; deque([2, 1, 2, 3, 4, 5, 1]) deque.popleft() ## 덱에서 앞의 원소를 추출함 &gt; deque([1, 2, 3, 4, 5, 1]) deque.pop() ## 덱에서 뒤의 원소를 추출함 &gt; deque([1, 2, 3, 4, 5]) deque . deque([1, 2, 3, 4, 5]) .",
            "url": "https://jaesu26.github.io/green/python/data%20structure/2021/09/19/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EB%8D%B1.html",
            "relUrl": "/python/data%20structure/2021/09/19/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EB%8D%B1.html",
            "date": " • Sep 19, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "행렬(matrix)",
            "content": "- 참고 교재1 : SAS와 R을 활용한 선형회귀분석(자유아카데미) . - 참고 교재2 : 통계수학강의(자유아카데미) . - 행렬의 기초를 간단히 정리하자 . &#54665;&#47148; . - 벡터와 행렬은 볼드체로 적어야 함 . - 행렬의 원소는 볼드체 사용 안함 &gt; 행렬의 원소가 벡터 또는 행렬이면 볼드체 사용 . - 행렬의 기본인 벡터를 알고가자 . - 열벡터($ boldsymbol{a}$) : $m times 1$ 행렬 &gt; 보통 벡터라고 하면 열벡터임 . - 행벡터($ boldsymbol{a&#39;}$) : $1 times n$ 행렬 . - 스칼라 : 원소가 하나인 행렬 . - ${ bf 0}$ : 모든 원소가 $0$인 벡터 . - ${ bf 1}$ : 모든 원소가 $1$인 벡터 . - $ boldsymbol{e_i}$ : $i$번째 원소만 $1$이고 나머지 원소는 모두 $0$인 벡터 . &#54665;&#47148;&#51032; &#51333;&#47448; . - 행렬(matrix)은 다음과 같이 $m$ 개의 행(row) 과 $n$ 개의 열(column) 을 $mn$ 개의 숫자로 채운 모양 . $$ boldsymbol{A} = begin{pmatrix} a_{11} &amp; a_{12} &amp; cdots &amp; a_{1n} a_{21} &amp; a_{22} &amp; cdots &amp; a_{2n} vdots &amp; vdots &amp; ddots &amp; vdots a_{m1} &amp; a_{m2} &amp; cdots &amp; a_{mn} end{pmatrix}$$ - 정사각행렬(square matrix) : $m=n$ 인 행렬 . - 대각행렬(diagonal matrix, $ boldsymbol{D}$) : 정사각행렬 중에 대각원소를 제외한 모든 원소가 $0$인 행렬 . - 단위행렬(identity matrix, $ boldsymbol{I}$) : 대각행렬 중에 대각의 원소가 모두 $1$인 행렬 &gt; $ boldsymbol{I_m}$(차수가 $m$) . - 위삼각행렬(upper triangular matrix) : 대각원소와 그 오른쪽 위의 원소를 제외한 나머지 원소는 모두 $0$인 행렬 . - 아래삼각행렬(lower triangular matrix) : 대각원소와 그 왼쪽 아래의 원소를 제외한 나머지 원소는 모두 $0$인 행렬 . - 전치행렬(transpose matrix) : 행과 열이 바뀐 행렬 &gt; $m times n$ 행렬의 전치행렬은 $n times m$ 이 되고 $ boldsymbol{A&#39;}$ 또는 $A^T$ 로 표현 . - 대칭행렬(symmetric matrix) : $ boldsymbol{A = A^T}$ . &#54665;&#47148;&#51032; &#50672;&#49328; . - 행렬의 덧셈 뺄셈은 교재 참고 . &#54665;&#47148;&#51032; &#44273; . - 각 행렬은 행벡터 또는 열벡터로 분할될 수 있음 . - 행렬의 곱 $ boldsymbol{AB}$ 는 행렬 $ boldsymbol A$ 가 $m$ 개의 행벡터로 분할되어 있고 행렬 $ boldsymbol B$ 가 $n$ 개의 열벡터로 분할되어 있다고 할 때 곱의 계산을 나타낸 것 &gt; 교재 참고 . $$ boldsymbol{AB}= begin{pmatrix} { boldsymbol{a_{1 , cdot}}} ,&#39; { boldsymbol{a_{2 , cdot}}} ,&#39; vdots { boldsymbol{a_{m , cdot}}} ,&#39; end{pmatrix} big( boldsymbol{b_{ , cdot ,1}}, , boldsymbol{b_{ , cdot ,2}}, , cdots, , boldsymbol{b_{ , cdot , n}} big) = begin{pmatrix} { boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}} &amp; { boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,2}} &amp; cdots &amp; { boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}} { boldsymbol{a_{2 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}} &amp; { boldsymbol{a_{2 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,2}} &amp; cdots &amp; { boldsymbol{a_{2 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}} vdots &amp; vdots &amp; ddots &amp; vdots { boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}} &amp; { boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,2}} &amp; cdots &amp; { boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}} end{pmatrix}$$ . . - ${ boldsymbol{a_{1 , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,1}}$ 부터 ${ boldsymbol{a_{m , cdot}}} ,&#39; boldsymbol{b_{ , cdot ,n}}$ 까지 각각은 스칼리임 . - 위 식에서 행렬 $ boldsymbol{A}$ 가 $p$ 개의 열벡터로 행렬 $ boldsymbol{B}$ 가 $p$ 개의 행벡터로 분할되어 있다고 하자 . - 그러면 행렬의 곱 $ boldsymbol{AB}$ 는 아래와 같이도 표현 가능함 . $$ boldsymbol{AB}= big( boldsymbol{a_{ , cdot ,1}}, , boldsymbol{a_{ , cdot ,2}}, , cdots, , boldsymbol{a_{ , cdot , p}} big) begin{pmatrix} { boldsymbol{b_{1 , cdot}}} ,&#39; { boldsymbol{b_{2 , cdot}}} ,&#39; vdots { boldsymbol{b_{p , cdot}}} ,&#39; end{pmatrix} = boldsymbol{a_{ , cdot ,1}}{ boldsymbol{b_{1 , cdot}}} ,&#39; + cdots + boldsymbol{a_{ , cdot ,p}}{ boldsymbol{b_{p , cdot}}} ,&#39;$$ . . - $ boldsymbol{a_{ , cdot ,1}}{ boldsymbol{b_{1 , cdot}}} ,&#39;$ 부터 $ boldsymbol{a_{ , cdot ,p}}{ boldsymbol{b_{p , cdot}}} ,&#39;$ 까지 각각은 $p times p$ 행렬임 . &#45824;&#44033;&#54633;(trace) . - 정사각행렬의 특성을 나타내는 수치 . - 행렬의 대각원소의 합 . - $ operatorname{tr}( boldsymbol{A}) = sum limits_{i=1}^{m}a_{ii}$ . &#45824;&#44033;&#54633;&#51032; &#49457;&#51656; . - $ operatorname{tr}( boldsymbol{A}) = operatorname{tr}( boldsymbol{A&#39;})$ . - $ operatorname{tr}( boldsymbol{AB}) = operatorname{tr}( boldsymbol{BA})$ . - 나머지는 간단하니 교재 참고 . &#50669;&#54665;&#47148; . . - 행렬식(determinant) : $ begin{vmatrix} boldsymbol{A} end{vmatrix}$ or $ det( boldsymbol{A})$ . - 행렬 $ begin{vmatrix} boldsymbol{A} end{vmatrix}$ 가 $m times m$ 일 때 $| boldsymbol{A}|= sum limits_{i=1}^{m}(-1)^{i+1}a_{1i} begin{vmatrix} boldsymbol{M_{1i}} end{vmatrix}$ . - $ boldsymbol{M_{ij}}$ 는 행렬 $ boldsymbol{A}$ 에서 $i$ 번째 행과 $j$ 번째 열을 제외한 $(m-1) times(m-1)$ 부분행렬 . - $ boldsymbol{A_{ij}} = (-1)^{i+j} boldsymbol{M_{ij}} longrightarrow boldsymbol{A_{ij}}$ 를 원소 $a_{ij}$ 의 여인수라고 함 . - 행렬 $ boldsymbol{A}$ 의 역행렬의 $(i,j)$ 번째 원소 $ boldsymbol{{(A^{-1})}_{ij}} = cfrac{1}{ begin{vmatrix} boldsymbol{A} end{vmatrix}}(-1)^{i+j} begin{vmatrix} boldsymbol{M_{ij}} end{vmatrix}$ . - 대각행렬, 위삼각행렬, 아래삼각행렬의 행렬식은 대각선 원소들의 곱 . - 특이행렬(singular matrix) : 행렬식이 $0$인 행렬 . - 정칙행렬(nonsingular matrix) : 행렬식이 $0$이 아닌 행렬 . . &#54665;&#47148;&#49885;&#51032; &#49457;&#51656; . - 스칼라 $ alpha$ 와 $m times m$ 행렬 $ boldsymbol{A,B}$ 에 대하여 다음이 성립 . $ det( boldsymbol{A}) = det( boldsymbol{A&#39;})$ . | $ det( alpha boldsymbol{A}) = alpha^{m}( det( boldsymbol{A}))$ . | $ boldsymbol{A}$ 가 대각행렬이면 $ det( boldsymbol{A}) = a_{11} times a_{22} times cdots times a_{mm}$ . | 행렬 $ det( boldsymbol{AB}) = det( boldsymbol{A}) times det( boldsymbol{B})$ . | 정사각행렬 $ boldsymbol{P, ,Q}$ 에 대하여 $ begin{vmatrix} begin{pmatrix} boldsymbol{P} &amp; boldsymbol{0} boldsymbol{X} &amp; boldsymbol{Q} end{pmatrix} end{vmatrix} = begin{vmatrix} boldsymbol{P} end{vmatrix} cdot begin{vmatrix} boldsymbol{Q} end{vmatrix}$ . | . $n$ &#52264; &#50672;&#47549;&#48169;&#51221;&#49885;&#51032; &#54644; . - $n$ 개의 미지수 $(x_1,x_2, cdots,_n)&#39;=x$에 대하여 $n$ 차 연립방정식을 생각해보자 . $$a_{11}x_1 + a_{12}x_2+ cdots+a_{1n}x_n=d_1 a_{21}x_1 + a_{22}x_2+ cdots+a_{2n}x_n=d_2 quad vdots a_{n1}x_1 + a_{n2}x_2+ cdots+a_{nn}x_n=d_n$$- 위의 $n$ 차 연립방정식은 다음과 같이 표현이 가능 $ to boldsymbol{Ax} = boldsymbol{d}$ . - 만약 $ boldsymbol{A^-1}$이 존재하면 $ boldsymbol{A^{-1}Ax} = boldsymbol{A^{-1}d} Longrightarrow boldsymbol{x} = boldsymbol{A^{-1}d}$ . &#50669;&#54665;&#47148;&#51032; &#49457;&#51656; . - 스칼라 $ alpha$ 와 $m times m$ 정칙행렬 $ boldsymbol{A,B}$ 에 대하여 다음을 만족 . $( alpha boldsymbol{A})^{ boldsymbol{-1}}= alpha^{-1} boldsymbol{A^{-1}}$ . | $( boldsymbol{A&#39;})^{ boldsymbol{-1}}=( boldsymbol{A^{-1}})&#39;$ . | $ begin{vmatrix} boldsymbol{A^{-1}} end{vmatrix}= begin{vmatrix} boldsymbol{A} end{vmatrix}^{-1}$ . | $ boldsymbol{A} = operatorname{diag}(a_{11},a_{22}, cdots,a_{mm}) Longrightarrow boldsymbol{A^{-1}} = operatorname{diag}(a_{11}^{ ,-1},a_{22}^{ ,-1}, cdots,a_{mm}^{ ,-1})$ . | $( boldsymbol{AB})^{ boldsymbol{-1}}= boldsymbol{B^{-1}} boldsymbol{A^{-1}}$ . | 정칙행렬 $ boldsymbol{P}, boldsymbol{Q}$ 에 대하여 $ begin{pmatrix} boldsymbol{P} &amp; 0 0 &amp; boldsymbol{Q} end{pmatrix}^{ boldsymbol{-1}} = begin{pmatrix} boldsymbol{P^{-1}} &amp; 0 0 &amp; boldsymbol{Q^{-1}} end{pmatrix}$ . | &#51649;&#44368;&#54665;&#47148; . - 직교행렬(orthogonal matrix) : 정사각행렬 중에 전치행렬이 역행렬인 행렬 $ longrightarrow boldsymbol{A&#39;} = boldsymbol{A^{-1}}$ . &#51649;&#44368;&#54665;&#47148;&#51032; &#51312;&#44148; . $${a_j}&#39;a_j = begin{cases} 1 &amp; text{for $i=j$} 0 &amp; text{for $i neq j$} end{cases}$$ . - 각 열벡터는 길이가 $1$이고 다른 열벡터와 직교한다 &gt; 정규직교벡터 . - $ boldsymbol{P}$ 가 직교행렬이면 $ begin{vmatrix} boldsymbol{PP&#39;} end{vmatrix} = { begin{vmatrix} boldsymbol{P} end{vmatrix}}^{2} = 1$ 이므로 직교행렬의 행렬식은 $ pm 1$ . &#47729;&#46321;&#54665;&#47148; . - 멱등행렬(idempotent matrix) : $ boldsymbol{A}^2= boldsymbol{AA}= boldsymbol{A}$ 를 만족하는 행렬 . - 멱등행렬의 대표적인 예(회귀분석) &gt; $ boldsymbol{H} = boldsymbol{X{(X{ ,&#39;}X)}^{-1}X{ ,&#39;}}$ . - 다양한 예는 교재 참고 . 2&#52264;&#54805;&#49885; . - 2차형식(quadratic form) : 대칭행렬을 사이에 두고 양옆에 같은 벡터가 곱해지는 형태($ boldsymbol{x&#39;Ax}$) . (&#51456;)&#51221;&#48512;&#54840;&#54665;&#47148; . - 모든 벡터 $ boldsymbol{x} neq 0$ 에 대하여 각 조건을 만족시키는 대칭행렬 $ boldsymbol{A}$ 는 다음과 같이 정의함 . $ boldsymbol{x&#39;Ax} &gt; 0$ 이면 $ boldsymbol{A}$ : 양의 정부호행렬(positive definite matrix) &gt; 양정치 . | $ boldsymbol{x&#39;Ax} geq 0$ 이면 $ boldsymbol{A}$ : 양의 준정부호행렬(positive semi-definite matrix) &gt; 양반정치 . | &#48289;&#53552;&#44277;&#44036; . &#48289;&#53552;&#44277;&#44036;(vector space) . - 벡터들을 포함하는 집합 $S$가 다음을 만족하면 벡터공간이라 한다 . 1. $ boldsymbol{0} in S$ . 2. $ boldsymbol{x} in S, ; boldsymbol{y} in S longrightarrow boldsymbol{x}+ boldsymbol{y} in S$ . 3. $ boldsymbol{x} in S longrightarrow alpha boldsymbol{x} in S$ . &#49440;&#54805;&#44208;&#54633; . - 다음과 같은 벡터 $ boldsymbol{v}= sum limits_{i=1}^{n} alpha_i boldsymbol{x_i} $를 벡터 $ boldsymbol{x_1}, cdots, boldsymbol{x_n}$의 선형결합(linear combination)이라고 한다 . &#49373;&#49457;&#51665;&#54633; . - 벡터공간 $S$에 속하는 모든 벡터 $ boldsymbol{s}$에 대해 $ boldsymbol{s}=c_1 boldsymbol{x_1}+ cdots+c_m boldsymbol{x_m}$을 만족하는 . - 벡터 $ boldsymbol{c}=(c_1, cdots,c_m)^ top in mathbb{R}^m$가 존재할 때 $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$을 $S$의 생성집합(spanning set)이라고 한다 . - 예컨대 $S_2 = (a,b,a+b)^ top$의 경우 $ {(1,0,1)^ top,(0,1,1)^ top }$가 생성집합의 예가 될 수 있다 . - 두 개의 벡터공간 $S_a,S_b$에 대해 $S_a subset S_b$이면 $S_a$를 $S_b$의 벡터 부분공간(subspace)라고 표현하기도 한다 . &#49440;&#54805;&#46021;&#47549;&#44284; &#49440;&#54805;&#51333;&#49549; . - 벡터공간 $S$에 포함되는 영벡터가 아닌 $m$개의 벡터로 이루어진 집합 $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$에 대해 . - $ sum limits_{i=1}^{m} alpha_i boldsymbol{x_i}= boldsymbol{0}$을 만족시키는 벡터 $ alpha neq boldsymbol{0}$가 존재하면 . - $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$는 선형종속(linearly dependent)이다 . - $ sum limits_{i=1}^{m} alpha_i boldsymbol{x_i}= boldsymbol{0}$을 만족시키는 벡터 $ alpha neq boldsymbol{0}$가 존재하지 않을 때 . - $ { boldsymbol{x_1}, cdots, boldsymbol{x_m} }$는 선형독립(linearly independent)이다 . . Note: 임의의 벡터집합이 선형종속이기 위한 필요충분조건은 벡터집합의 최소한 하나의 벡터는 다른 벡터들의 선형결합으로 표현되는 것 . &#54665;&#47148;&#51032; &#44228;&#49688; . - 선형독립인 벡터들의 모임 $ boldsymbol{x_1}, cdots, boldsymbol{x_m}$이 벡터공간 $S$의 생성집할일 때 . - 이를 벡터공간 $S$의 기저(basis)라고 하고 벡터의 수 $m$을 벡터공간 $S$의 차원(dimension)이라고 한다 . - 정규직교기저(orthonormal basis) : 벡터공간 $S$의 기저 $B$를 이루는 다음을 만족하는 벡터, $ lVert boldsymbol{x} rVert= 1, lVert boldsymbol{y} rVert = 1, ; boldsymbol{x^ top} boldsymbol{y} = 0, ; forall boldsymbol{x}, boldsymbol{y} in B$ . - 쉽게 말하면 각 벡터의 크기는 $1$이며 벡터들은 서로 직교한다 . &#54665;&#47148;&#51032; &#44228;&#49688;&#50752; &#44288;&#47144;&#46108; &#49457;&#51656; . - $ boldsymbol{A} : m times n$ 행렬, $ boldsymbol{B} : n times p$ 행렬, $ boldsymbol{C} : n times n$ 행렬, $ boldsymbol{H} :$ 멱등행렬 . 1. $ operatorname{rank}( boldsymbol{A}) = operatorname{rank}( boldsymbol {A^ top}) = operatorname{rank}( boldsymbol {AA^ top}) = operatorname{rank}( boldsymbol{A^{ top}A})$ . 2. $ operatorname{rank}( boldsymbol{A}) leq min(m,n)$ . 3. $ operatorname{rank}( boldsymbol{AB}) leq min( operatorname{rank}( boldsymbol{A}), , operatorname{rank}( boldsymbol{B}))$ . 4. $m=n$ 일 때, $ det( boldsymbol{A})=0$이면 $ operatorname{rank}( boldsymbol{A})&lt;m$ . 5. $ operatorname{rank}( boldsymbol{AC}) = operatorname{rank}( boldsymbol{A})$ . 6. $ operatorname{rank}( boldsymbol{H}) = operatorname{tr}( boldsymbol{H})$ . &#44256;&#50976;&#44050;&#44284; &#44256;&#50976;&#48289;&#53552; . - $m times m$ 정사각행렬 $ boldsymbol{A}$에 대하여 $ boldsymbol{0}$이 아닌 벡터 $ boldsymbol{x} in mathbb{R}^m$와 스칼라 $ lambda$가 $ boldsymbol{Ax}= lambda boldsymbol{x}$를 만족할 때 . - $ boldsymbol{x}$를 고유값(eigenvalue) $ lambda$에 대응하는 고유벡터(eigenvector)라고 한다 . - $ boldsymbol{x} neq boldsymbol{0}$에 대하여 $ boldsymbol{Ax}- lambda boldsymbol{Ix}=( boldsymbol{A}- lambda boldsymbol{I}) boldsymbol{x}= boldsymbol{0}$ . - 한편, $ boldsymbol{B}=( boldsymbol{A}- lambda boldsymbol{I})$일 때 만약 $ boldsymbol{B}$의 역행렬이 존재한다면 . - $ boldsymbol{B^{-1}Bx} = boldsymbol{B^{-1}0}$이므로 $ boldsymbol{x}$는 영벡터인데 조건에서 $ boldsymbol{x}$는 영벡터가 아니라고 했으므로 . - $( boldsymbol{A}- lambda boldsymbol{I})$는 특이행렬이고 그 행렬식은 $0$이다 . - 즉 $ operatorname{det}( boldsymbol{A}- lambda boldsymbol{I}) = 0$을 통해 고유값 $ lambda$를 구하고 . - 각 고유값 $ lambda$에 대하여 $ boldsymbol{Ax}= lambda boldsymbol{x}$를 통해 고유벡터 $ boldsymbol{x}$를 구한다 . &#44256;&#50976;&#44050;&#44284; &#44256;&#50976;&#48289;&#53552;&#50640; &#45824;&#54620; &#49457;&#51656; . 1. 행렬 $ boldsymbol{A}$의 고유값과 행렬 $ boldsymbol{A^ top}$의 고유값은 동일하다 . 2. $ lambda_{i}^{k}$는 행렬 $ boldsymbol{A^k}$의 고유값이고 이에 대응하는 고유벡터는 $ boldsymbol{x_i}$이다(고유벡터는 동일함) . 3. $f( boldsymbol{A})$의 고유값은 $f( lambda)$이다(ex : $ boldsymbol{A} to lambda, ; boldsymbol{A^2+A} to lambda^2 + lambda$ .",
            "url": "https://jaesu26.github.io/green/math/2021/09/16/%ED%96%89%EB%A0%AC.html",
            "relUrl": "/math/2021/09/16/%ED%96%89%EB%A0%AC.html",
            "date": " • Sep 16, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Boole's inequality and Bonferroni's inequality",
            "content": "Boole&#39;s inequality . - Boole의 부등식: $P bigg( bigcup limits_{i=1}^{ infty} A_i bigg) leq sum limits_{i=1}^{ infty}P(A_i)$ . Boole&#51032; &#48512;&#46321;&#49885; &#51613;&#47749; . - $B_1=A_1, ,B_2=A_2 cap A^c_1, , cdots, ,B_i = A_i cap bigg( bigcup limits_{j=1}^{i-1}A_j bigg)^c$ . - 사건 $B_i$는 사건 $A_i$에는 속하면서 사건 $A_j ,(1 leq j &lt;i$)에는 속하지 않는다 . - 그렇기에 $B_i$와 $B_j(i neq j)$는 서로 배반 사건임 &gt; 배반 사건이므로 $P( cup B_i) = sum P(B_i)$ . - 그리고 $ cup A_i= cup B_i$ 임을 알 수 있음 . - 또 $B_i subset A_i$ 이므로 $P( cup A_i)= P( cup B_i)= sum P(B_i) leq sum P(A_i)$ 가 성립한다 . Bonferroni&#39;s inequality . - Bonferroni의 부등식: $P bigg( bigcap limits^{k}_{i=1}A_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c)$ . Bonferroni&#51032; &#48512;&#46321;&#49885; &#51613;&#47749; . - 드 모르간의 법칙: $ bigg( bigcap limits_{i=1}^{k}A_i bigg)^c = bigcup limits_{i=1}^{k}A^c_i longrightarrow bigcap limits_{i=1}^{k}A_i= bigg( bigcup limits_{i=1}^{k}A^c_i bigg)^c$ . $P bigg( bigcap limits^{k}_{i=1}A_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c) qquad therefore bigcap limits_{i=1}^{k}A_i= bigg( bigcup limits_{i=1}^{k}A^c_i bigg)^c$ . | $P bigg( bigg( bigcup limits_{i=1}^{k}A^c_i bigg)^c bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c) qquad therefore P(A^c)=1-P(A)$ . | $1-P bigg( bigcup limits_{i=1}^{k}A^c_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c)$ . | $P bigg( bigcup limits_{i=1}^{k}A^c_i bigg) leq sum limits_{i=1}^{k}P(A_i^c) qquad therefore$ $A^c_i$ 대신 $A_i$ 사용해도 상관없음 . | $P bigg( bigcup limits_{i=1}^{k}A_i bigg) leq sum limits_{i=1}^{k}P(A_i) longrightarrow $ 이 식이 성립하는지 수학적 귀납법을 사용하여 증명하자 . | . - $k=1$일 때 $P(A_1) leq P(A_1)$이므로 성립한다 . - $k=n$일 때 성립한다 가정하고 $k=n+1$일 때도 성립하는지 확인하자 . $P bigg( bigcup limits_{i=1}^{n+1}A_i bigg)= P bigg( bigg( bigcup limits_{i=1}^{n}A_i bigg) cup A_{n+1} bigg) = P bigg( bigcup limits_{i=1}^{n}A_i bigg)+P(A_{n+1})-P bigg( bigg( bigcup limits_{i=1}^{n}A_i bigg) cap A_{n+1} bigg)$ . | $P bigg( bigcup limits_{i=1}^{n+1}A_i bigg) leq P bigg( bigcup limits_{i=1}^{n}A_i bigg) + P(A_{n+1}) qquad therefore P bigg( bigg( bigcup limits_{i=1}^{n}A_i bigg) cap A_{n+1} bigg) geq 0$ . | $P bigg( bigcup limits_{i=1}^{n+1}A_i bigg) leq P bigg( bigcup limits_{i=1}^{n}A_i bigg) + P(A_{n+1}) leq sum limits_{i=1}^{n}P(A_i)+P(A_{n+1})= sum limits_{i=1}^{n+1}P(A_i)$ . | . - 따라서 $k=n+1$일 때도 성립한다 . - 수학적 귀납법에 의해 모든 유한개의 사건 $k$에 대해 $P bigg( bigcap limits^{k}_{i=1}A_i bigg) geq 1 - sum limits_{i=1}^{k}P(A_i^c)$ 가 성립함 . - ref: https://dawoum.ddns.net/wiki/Boole%27s_inequality .",
            "url": "https://jaesu26.github.io/green/statistics/math/2021/09/12/%EB%B6%80%EC%9A%B8-%EB%B3%B8%ED%8E%98%EB%A5%B4%EB%8B%88-%EB%B6%80%EB%93%B1%EC%8B%9D.html",
            "relUrl": "/statistics/math/2021/09/12/%EB%B6%80%EC%9A%B8-%EB%B3%B8%ED%8E%98%EB%A5%B4%EB%8B%88-%EB%B6%80%EB%93%B1%EC%8B%9D.html",
            "date": " • Sep 12, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "포함배제의 원리",
            "content": "- 수통 과제에 포함배제의 원리 증명이 있는데 헷갈려서 따로 정리함 . &#54252;&#54632;&#48176;&#51228;&#51032; &#50896;&#47532;(&#54869;&#47456;&#51032; &#44221;&#50864;) . - 임의의 유한개의 사건 $A_1, cdots, A_k in S$ 에 대하여 아래가 성립함 . $P Big( bigcup limits^{K}_{i=1}A_i Big) = sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P Big( bigcap limits_{i=1}^{k}A_i Big)$ | . - 이제 증명을 해보자 &gt; 수학적 귀납법을 활용할 것 임 . - $n = 1$일 때 식이 성립함을 증명 &gt; $n=k$일 때 성립한다 가정하고 $n=k+1$일 때 식이 성립함을 증명 . - $n=k$일 때 성립하면 $n=k+1$일 때도 성립한다고 했음 &gt; $n = 1$일 때 성립하면 $n=2$일 때도 성립 &gt; $n = 1$일 때 식이 성립함&gt; $n=2$일 때 식이 성립 . - 이제 $n=2$일 때 성립하면 $n=3$일 때도 성립 &gt;$n = 2$일 때 식이 성립함 &gt; $n=3$일 때 식이 성립 . - 이런식으로 나아가면 모든 자연수에 대해서 성립함을 알 수 있음 . - $n=1$대신 $n=a$로 바뀐다면 $a$이후의 자연수에 대해서 성립함을 알 수 있음 . &#54252;&#54632;&#48176;&#51228;&#51032; &#50896;&#47532; &#51613;&#47749; . - $A cap B = C to C cap A = C, ; C cap B = C,C cup A = A, ; C cup B = B$ &gt; 당연하지만 알아두자 . - $n=1$일 때 $P(A_1) = P(A_1)$이므로 성립함 . - 이제 $n=k$일 때 성립한다 가정하고 $n=k+1$일 때 성립하는지 살펴보자 . $P bigg( bigcup limits_{i=1}^{k+1}A_i bigg) = P bigg( bigg( bigcup limits_{i=1}^{k}A_i bigg) bigcup A_{k+1} bigg) quad therefore text{나열해서 보면 당연한 소리} = P bigg( bigcup limits_{i=1}^{k}A_i bigg) + P(A_{k+1}) - P bigg( bigg( bigcup limits_{i=1}^{k}A_i bigg) bigcap A_{k+1} bigg) therefore P(X cup Y) = P(X)+P(Y)-P(X cap Y), quad X to bigcup limits^k_{i=1}A_i, ;Y to A_{k+1} =P bigg( bigcup limits_{i=1}^{k}A_i bigg) + P(A_{k+1}) - P bigg( bigcup limits_{i=1}^{k} big(A_i cap A_{k+1} big) bigg) therefore text{집합의 분배법칙,} ; P bigg( bigcup limits_{i=1}^{k} X_i bigg) = sum limits_{i=1}^{k}P(X_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(X_i cap X_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}X_i bigg) = bigg { sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}A_i bigg) bigg } +P(A_{k+1})- bigg { sum limits_{i=1}^{k}P(A_i cap A_{k+1}) - sum limits_{1 leq i &lt; j leq k}^{k}P((A_i cap A_{k+1}) cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}(A_i cap A_{k+1}) bigg) bigg } = sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}A_i bigg) +P(A_{k+1})- sum limits_{i=1}^{k}P(A_i cap A_{k+1}) + sum limits_{1 leq i &lt; j leq k}^{k}P((A_i cap A_{k+1}) cap A_j) - cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg) therefore- ,(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}(A_i cap A_{k+1}) bigg) = (-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg) = sum limits_{i=1}^{k+1}P(A_i) - sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j) + cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg) therefore text{그러므로 $n=k+1$일 때도 성립한다}$ | . - 마지막 부분이 이해가 안될 수 도 있음 . - 일단 $ sum limits_{i=1}^{k}P(A_i)$ 와 $P(A_{k+1})$를 더해서 $ sum limits_{i=1}^{k+1}P(A_i)$가 되는것은 알 것임 . - 그건 맞다고 치자 &gt; 그 다음부터는 뭐임?? . - $- sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j)$ &gt; 이건 어떻게 도출됨?? . - 아래식을 보자 . - $ - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j)- sum limits_{i=1}^{k}P(A_i cap A_{k+1}) = - sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j)$ . - 위 식이 성립하는 것만 이해하면 전부다 이해 가능 &gt; 왜 성립함? &gt; 그냥 나열해보면 성립하는 것을 알 수 있음 &gt; 설명을 더 해보자 . - $P bigg( bigcup limits^{K}_{i=1}A_i bigg)$에서 $P bigg( bigcup limits^{K+1}_{i=1}A_i bigg)$로 업그레이드(?)시킬 수 있다는 것은 $n=k$가 성립하면 $n=k+1$일 때 도 성립한다는 뜻 . - 잘보면 왼쪽식에서 오른쪽식으로 나아가기 위해서는 사건$A_{k+1}$과 연관된 식이 있어야 함 . - 예컨데 $k=3$이라고 해보자 . - $ sum limits_{1 leq i &lt; j leq 3}^{3}P(A_i cap A_j)=P(A_1 cap A_2)+P(A_1 cap A_3)+P(A_2 cap A_3) ; cdots text{식 (1)}$ . - 여기서 $k$대신 $k+1$을 넣어보자 . - $ sum limits_{1 leq i &lt; j leq 3+1}^{3+1}P(A_i cap A_j)=P(A_1 cap A_2)+P(A_1 cap A_3)+P(A_1 cap A_4)+P(A_2 cap A_3)+P(A_2 cap A_4)+P(A_3 cap A_4)$ . - 즉 우리에겐 $n=k$일 때는 존재하지 않는 사건 $A_{k+1}$과 연관된 식인 $P(A_1 cap A_4)+P(A_2 cap A_4)+P(A_3 cap A_4) ; cdots text{식 (2)}$가 있어야 $n=k+1$일 때의 식으로 나아갈 수 있음 &gt; 이 식이 바로 $- sum limits_{i=1}^{k}P(A_i cap A_{k+1})$ . - 식 (1)과 식 (2)가 합쳐져서 $n=k+1$일 때의 식을 만들어 내는 것임 . - $ sum limits_{i=1}^{k}P(A_i) - sum limits_{1 leq i &lt; j leq k}^{k}P(A_i cap A_j) + cdots+(-1)^{k-1}P bigg( bigcap limits_{i=1}^{k}A_i bigg)$ &gt; 식 (1)의 역할, $P(A_{k+1})- sum limits_{i=1}^{k}P(A_i cap A_{k+1}) + sum limits_{1 leq i &lt; j leq k}^{k}P((A_i cap A_{k+1}) cap A_j) - cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg)$ &gt; 식 (2)의 역할 . - 위의 두 식($n leq k$까지의 정보와 $n=k+1$일 때의 정보)이 합쳐져서 $P bigg( bigcup limits^{K+1}_{i=1}A_i bigg)= sum limits_{i=1}^{k+1}P(A_i) - sum limits_{1 leq i &lt; j leq k+1}^{k+1}P(A_i cap A_j) + cdots+(-1)^{k+1-1}P bigg( bigcap limits_{i=1}^{k+1}A_i bigg)$ ($n leq k$까지의 정보)가 되는 것임 .",
            "url": "https://jaesu26.github.io/green/statistics/math/2021/09/11/%ED%8F%AC%ED%95%A8%EB%B0%B0%EC%A0%9C%EC%9D%98%EC%9B%90%EB%A6%AC.html",
            "relUrl": "/statistics/math/2021/09/11/%ED%8F%AC%ED%95%A8%EB%B0%B0%EC%A0%9C%EC%9D%98%EC%9B%90%EB%A6%AC.html",
            "date": " • Sep 11, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "자료구조 큐(queue)",
            "content": "&#53328;(queue) . - 큐(queue)는 기본적인 자료 구조 + 스택(stack)과 반대되는 개념 . - 큐는 먼저 집어 넣은(push) 데이터가 먼저 나오는(pop) FIFO(First In First Out)구조로 되어 있음 &gt; 식당에서 줄 기다리기 &gt; 먼저 줄을 선 사람이 먼저 줄에서 나감( =식당으로 들어감) . - 참고: 자료구조 큐 . &#53328;(queue) &#49324;&#50857; . - 파이썬에서 queue은 from collections import deque를 실행한 후 deque()통해 구현할 수 있다 . - queue.append(x)를 통해 큐에 x를 오른쪽(뒤)에 push한다 . - queue.popleft()를 통해 큐에서 앞의 원소(왼쪽)를 pop한다 . - 참고: queue in python . &#50696;&#51228; . from collections import deque ## 큐(queue)를 사용하기 위해 deque라이브러리 import queue = deque() ## 큐(queue) 자료구조 생성 &gt; deque([]) queue.append(1) ## 큐에 1 추가 &gt; deque([1]) queue.append(2) ## 큐에 2 추가 &gt; deque([1, 2]) queue.popleft() ## 큐에서 앞의 원소를 추출함 &gt; 선입선출 구조 &gt; deque([2]) queue . deque([2]) .",
            "url": "https://jaesu26.github.io/green/python/data%20structure/2021/09/05/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%81%90.html",
            "relUrl": "/python/data%20structure/2021/09/05/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%81%90.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "수리통계학",
            "content": "- 수리통계학 내용 정리 . - 참고 : 수리통계학 제5판 송성주$ cdot$전명식 지음 . &#54869;&#47456;&#51060;&#47200; . - 확률모형 &gt; 동전 던지기와 같이 가능성(chance)에 의존 . &#54364;&#48376;&#44277;&#44036;&#44284; &#49324;&#44148; . - 표본공간(sample space) : 모든 관찰 가능한 결과들의 집합 &gt; $S$ 또는 $ Omega$ . - 사건(event) : 표본공간의 일부분(부분집합) &gt; $A, B$ 등 영어 알파벳 대문자 . - 실험(experiment) 또는 시행 (trial) : 어떤 현상의 관찰결과를 얻기위한 과정 . 예시 | . - 동전의 앞면을 H, 뒷면을 T라 할 때 동전을 2회 던지는 실험을 시행하자 . - 표본공간 $S = {HH, HT, TH, TT }$ . - 1회 앞면이 나오는 사건 $A = {HT, TH }$ . - 2회 뒷면이 나오는 사건 $B = {TT }$ . 정의 | . - 사건 $A$와 $B$가 동시에 속하는 사건 &gt; $A$와 $B$의 공통부분(intersection) &gt; $A cap B$ . - 사건 $A$ 또는 $B$에 속하는 사건 &gt; $A$와 $B$의 합(union) &gt; $A cup B$ . - $A cap B$ = $ phi$ &gt; 두 사건 $A$와 $B$는 상호배반(mutually exclusive) . - 사건 $A$에 포함되지 않은 모든 $S$의 원소의 집합 &gt; $A$의 여사건(complement) &gt; $A^c$ . 사건에 대한 분배법칙과 드 모르간 법칙 | . - $(A cup B)^c = A^c cap B^c$ &gt; 드 모르간(De Morgan) 법칙 . - $(A cap B)^c = A^c cup B^c$ &gt; 드 모르간 법칙 . - $A cup (B cap C) = (A cup B) cap (A cup C)$ &gt; 분배법칙 . - $A cap (B cup C) = (A cap B) cup (A cap C)$ &gt; 분배법칙 . &#54869;&#47456;&#51032; &#51221;&#51032; . - 확률은 함수임 . 고전적 정의 | . - 표본공간이 유한 개($N$)의 결과로 구성되고 모든 가능한 실험결과들이 일어날 가능성이 동일한경우 $M$개의 실험결과로 이루어진 사건 $A$의 확률 $P(A) = dfrac{M}{N}$ . 상대도수의 극한 | . - 실험을 독립적으로 n회 반복했을 때 사건 $A$의 발생횟수를 m이라 하면 실험이 무한히 반복되면 $P(A) = dfrac{m}{n}$ . &#54869;&#47456; &#44277;&#47532; . 1. 임의의 사건 $A$에 대해 $P(A) geq 0$ . 2. $P(S)=1$ . 3. 표본공간 $S$에 정의된 사건열 $A_1, A_2, cdots$가 있다고 할 때 모든 $i neq j$에 대하여 $A_i cap A_j = phi$이면 $P bigg( bigcup limits_{i=1}^{ infty} A_i bigg) = P(A_1 cup A_2 cup A_3 cup cdots) = sum limits_{i=1}^{ infty} P(A_i)$ . - 3번째 공리는 쉽게 말하자면 서로소인 두 사건 $A$와 $B$에 대해 $P(A) + P(B) = p(A cup B)$이다 + 집합열 이해 안되면 통계수학 책 참고하셈 . - 확률 &gt; 표본공간의 부분집합의 모임(특별한 성질 만족)을 정의역으로 하면서 확률공리를 만족하는 함수 . 정리 | . - 증명은 교재 참고 . 1. $P(A^c) = 1- P(A)$ . 2. $P( phi) = 0$ . 3. $A subset B$이면 $P(A) leq P(B)$ . 4. $P(A cup B)=P(A)+P(B)-P(A cap B)$ . - 정리 4번 사건 3개 버전 . - $P(A cup B cup C) = P(A) + P(B) + P(C) - P(A cap B) - P(B cap C) - P(C cap A) + P(A cap B cap C)$ &gt; 벤 다이어그램을 그려보면 간단히 알 수 있음 . &#51312;&#44148;&#48512; &#54869;&#47456; . - 사건$A$와 $B$가 표본공간 $S$상에 정의되어 있으며 $P(B) &gt; $일 때 $B$가 일어났다는 가정하에 사건 $A$가 일어날 조건부 확률은$P(A mid B) = cfrac{P(A cap B)}{P(B)}$로 정의됨 . - 조건부 확률도 확률 공리를 만족함 . &#51204;&#54869;&#47456; &#44277;&#49885;(total probability) . - 사건 $B_1, B_2, cdots,B_k$ 는 상호배반이며 $(B_1 cap B_j = phi, ;i neq j), ; bigcup limits_{i=1}^{k}B_{i}=S$라고 하자 . - 이때 임의의 사건 $A$에 대하여 $P(A) = sum limits_{i=1}^{k}P(B_i)P(A mid B_i)$가 성립함 . - 증명: $P(A) = P(A cap S) = P bigg[A cap bigg( bigcup limits_{i=1}^{k}B_i bigg) bigg] = sum limits_{i=1}^{k}P(A cap B_i)= sum limits_{i=1}^{k}P(B_i)P(A mid B_i)$ . &#48288;&#51060;&#51592; &#51221;&#47532;(Bayes&#39; theorem) . - 사건 $B_1, B_2, cdots,B_k$ 는 상호배반이며 $(B_1 cap B_j = phi, ;i neq j), ; bigcup limits_{i=1}^{k}B_{i}=S$라고 하자 . - 이때 사건 $A$가 일어났다는 조건하에서 사건 $B_j$가 일어날 확률은 $P(B_j mid A)= cfrac{P(B_j)P(A mid B_j)}{ sum limits_{i=1}^{k}P(B_i)P(A mid B_i)}$ . - 증명(전확률 공식 사용): $P(B_j mid A)= cfrac{P(A cap B_j)}{P(A)}= cfrac{P(B_j)P(A mid B_j)}{P(A)}= cfrac{P(B_j)P(A mid B_j)}{ sum limits_{i=1}^{k}P(B_i)P(A mid B_i)}$ . - $P(B_1), cdots,P(B_k)$는 $B$의 사전확률(prior probability) . - 사건 $A$가 일어났다는 정보가 추가됨 &gt; $P(B_1 mid A), cdots,P(B_k mid A)$는 $B$의 사후확률(posteriori probability) . &#49324;&#44148;&#51032; &#46021;&#47549; . - 두 사건 $A$와 $B$가 $P(A cap B) = P(A) cdot P(B)$를 만족시키면 서로 독립(independent)이라고 함 . &#44221;&#50864;&#51032; &#49688; . &#49692;&#50676;(permutation) . - 서로 다른 n개의 원소 중에서 r개를 선택하여 순서 있게 놓는 것(${_n rm P_r}$) . &#51312;&#54633; . - 서로 다른 n개의 원소 중에서 순서에 관계없이 r개를 선택하는 것($_n rm C_r$) . &#51060;&#54637;&#51221;&#47532; . - $(a+b)^n = sum limits_{k=0}^{n} dbinom{n}{k}a^{k} b^{n-k}$ . &#44057;&#51008; &#44163;&#51060; &#51080;&#45716; &#49692;&#50676; . - $ dbinom{n}{ ;r_1 ; r_2 ; cdots ;r_k ;} = cfrac{n!}{r_1! ; r_2! ; cdots ; r_k!}$ . &#45796;&#54637;&#51221;&#47532; . - $(a_1+a_2+ cdots+a_k)^n= sum limits_{r_1, cdots,r_k in mathbb N}^{r_1+ cdots+r_k=n} dbinom{n}{ ;r_1 ; r_2 ; cdots ;r_k ;} ,a_1^{r_1} ,a_2^{r_2} cdots a_k^{r_k}$ . &#54869;&#47456;&#48320;&#49688; . - 확률변수(random variable) : 실험결과를 표현하는 수치적인 양 . - 확률변수의 값은 실험결과에 따라 정해지므로 비결정적(non-deterministic) . - 확률분포(probability distribution) : 확률변수의 값들이 나올 가능성 . &#54869;&#47456;&#48320;&#49688;&#51032; &#51221;&#51032; . - 확률변수 $ to$ 표본공간 $ Omega$에 정의된 실수값을 가지는 함수(real-valued function) &gt; $X: Omega to mathbb{R}$ . - 예컨대 $X( omega)=x$, 참고로 $x$를 realization(실현)이라고 한다 . - 이산형(discrete) - 가질 수 있는 값이 유한개 (finite) 또는 셀 수 있는 무한개(countably infinite)인 확률변수 . - 연속형(continuous) - 가질 수 있는 값의 범위가 실직선상의 어떤 구간인 확률변수 . - 혼합형 - ex) $ {1, 2, (5, 10) }$ . &#54869;&#47456;&#44277;&#44036;(probability space) . - 확률 공간($ Omega, mathcal{F}, Pr)$ 은 전체 측도가 $1$인 측도 공간이다 . - 측도는 집합에 크기를 부여하기 위해 만든 개념으로 가산집합에 실수로 가는 함수를 부여한 것 . - 확률적인 현상에서 확률공간의 측도는 확률을 정의한다 . - 확률공간이 같다는건 $ Omega$가 동일하고 (주사위 던지기 $ Omega= {1,2,3,4,5,6 }$) . - $ mathcal{F}$가 동일하고(예컨대 짝수, 홀수에만 관심이 있어서 $ mathcal{F}= { phi, {1,3,5 }, {2,4,6 }, Omega }$) . - $Pr$이 동일하다는 것(예컨대 짝수, 홀수가 나올 가능성이 다른 주사위라 확률측도가 다음과 같다) . $$ begin{aligned} Pr( phi)&amp;=0.0 Pr( {1,3,5 })&amp;=0.4 Pr( {2,4,6 })&amp;=0.6 Pr( Omega)&amp;=1.0 end{aligned}$$ . - 참고 : https://ko.wikipedia.org/wiki/%ED%99%95%EB%A5%A0_%EA%B3%B5%EA%B0%84 . &#54364;&#48376;&#44277;&#44036; . - 확률실험에서 발생할 수 있는 모든 결과들의 집합을 표본공간(Sample Space) 이라고 한다 . - 표본공간은 $S$ 또는 $ Omega$ 기호로 나타낸다 . - $ Omega= { omega_1, omega_2, cdots, omega_n }$는 가능한 모든 결과를 포함하고 각 원소끼리는 배반이다 . - 예컨대 동전던지기 실험에서 표본공간은 다음과 같이 나타낼 수 있음 &gt; $ Omega= {H,T }$ . - 참고 : https://en.wikipedia.org/wiki/Sample_space . &#49324;&#44148;&#44277;&#44036; . - 표본공간 $ Omega$의 $ sigma$-field를 사건공간(event space) 이라 한다 . - 사건공간의 원소를 사건이라고 한다 . - 사건 : 표본공간의 부분집합 . - 사건공간($ mathcal{F}$) : 사건의 집합 $ Longleftrightarrow$ 표본공간의 $ sigma$-field . - 동전던지기의 경우 사건은 $ phi, {H }, {T }, Omega$이므로 사건공간 중 하나를 다음과 같이 나타낼 수 있음 . - $ mathcal{F}= { phi, {H }, {T }, Omega }$ &gt; $ mathcal{F}$의 원소 하나하나가 사건에 해당함 . - 사건공간 중 하나라고 표현한건 $ sigma$-field 정의에 의해 사건공간은 여러개가 될 수 있기 때문 . - 예컨대 주사위 던지기의 경우에서 주사위의 특정값이 아닌 단지 짝인지 홀인지에만 관심이 있으면 $ mathcal{F}= { phi, {1,3,5 }, {2,4,6 }, Omega }$로 설정해도 된다 . - 참고 : https://en.wikipedia.org/wiki/%CE%A3-algebra . &#54869;&#47456;&#52769;&#46020; . - 측도공간 $( Omega, mathcal{F})$에 대해서 어떤 함수 $ Pr: mathcal{F} to [0,1]$가 다음 세 조건(확률 공리)을 만족하면 $ Pr$을 확률측도라고 한다 . 1. $ Pr(A) geq 0, quad forall A in mathcal{F}$ . 2. $ Pr( Omega)=1$ . 3. Countable, pairwise disjoint set $ {A_1,A_2, cdots mid A_i in mathcal{F} }$에 대하여 $ Pr bigg( bigcap limits_{i=1}^{ infty}A_i bigg)= sum limits_{i=1}^{ infty} Pr(A_i)$ . - 예컨대 동전던지기의 사건공간이 $ mathcal{F}= { phi, {H }, {T }, Omega }$ 라면 위의 조건을 만족하는 확률측도를 아래와 같이 만들 수 있다 . $$ begin{aligned} Pr( phi)&amp;=0.0 Pr( {H })&amp;=0.5 Pr( {T })&amp;=0.5 Pr( Omega)&amp;=1.0 end{aligned}$$ . - 위의 경우 함수 $ Pr(A)$는 $ cfrac{ text{집합 $A$의 원소 개수}}{ text{표본공간 $ Omega$의 원소 개수}}$로 정의된다고 할 수 있다 . - 바로 위의 $ Pr$정의에 따르면 동전 던지기나 주사위 굴리기 같은 것은 $ Pr$이 동일하다 . - 그러나 확률측도는 위의 세 조건인 Kolmogorov axioms를 만족하기만 하면 되기에 확률측도는 하나가 아니다 . - 예컨대 아래와 같이 확률측도를 일반적이지 않게 만들 수 도 있다는 것 . $$ begin{aligned} Pr( phi)&amp;=0.0 Pr( {H })&amp;=0.4 Pr( {T })&amp;=0.6 Pr( Omega)&amp;=1.0 end{aligned}$$ . - 참고로 함수 $ Pr$의 정의역은 $ mathcal{F}$이고 치역은 $ {s in R:0 leq s leq 1 }$이다 . - 참고 : https://gem763.github.io/probability%20theory/%ED%99%95%EB%A5%A0%EC%9D%98-%EC%9D%B4%ED%95%B4.html . - 그런데 $ Pr$이랑 $P$랑 다른거야? &gt; https://stats.stackexchange.com/questions/108441/which-notation-and-why-textp-pr-textprob-or-mathbbp . &#54869;&#47456;&#44277;&#44036; &#52628;&#44032; &#51221;&#47532; . - 찾아볼수록 더 헷갈려서 추가로 정리함 . - 틀릴 수 있음 . - Q1 : 확률변수 $X_1$과 $X_2$가 동일한 확률공간에서 정의될 때 둘의 CDF는 다를 수 있는가? . - 확률공간이 같은데 둘의 CDF가 다르다라...... . - 가능하다 . - $ Omega = {T }$라고 하자 . - 즉 확률실험에서 발생할 수 있는 모든 결과가 $ {T }$ 하나다 &gt; 예컨대 앞면 뒷면 둘다 학이 그려진 동전을 던진다면 항상 학만 나올 것임 . - $ mathcal{F}= { phi, Omega }$라고 하자 . - 그러면 $ Pr( Omega)=1, ; Pr( phi)=0$ &gt; 확률공리를 만족시켜야 하니까 . - 이제 $X_1=0,X_2=2$라고 하자($X_1(T)=0,X_2(T)=2$와 동일함) . - 확률변수 $X_1$과 $X_2$는 같은 확률공간에서 정의됐으며 둘의 차이점이라곤 $ Omega$의 원소 $T$를 $0$으로 맵핑하냐 $2$로 맵핑하냐 뿐이다 . - 자 $X_1&gt;1$일 확률과 $X_2&gt;1$일 확률이 같은가? &gt; 아니다 $ Pr(X_1&gt;1)=0, ; Pr(X_2&gt;1)=1$이다 . - 그러니 CDF는 다르다 . - $ Pr(X_1&gt;1)=0, ; Pr(X_2&gt;1)=1$을 보고 둘다 $X&gt;1$일 확률인데 값이 다르니 $ Pr$도 다르다고 하면 안된다 . - $X_1&gt;1 = phi$이고 $X_2&gt;1= Omega$이다, $ Pr( phi)$와 $ Pr( Omega)$는 당연히 다르다 . - 하지만 $ Pr$은 동일하다($ Pr( phi)=0$, $ Pr( Omega)=1$) . - 다른 예시도 있음 . - 주사위던지기를 생각하자 . - $ Omega= {1,2,3,4,5,6 }$ 이고 $ mathcal{F}= { phi, {1 }, {2 }, {3 }, {4 }, {5 }, {6 }, Omega }$라 하자 . - 즉 주사위를 한번 던져서 나온 결과에만 관심이 있음 . - 그리고 $ Pr( { omega })= dfrac{1}{6}, ,1 leq omega leq 6$ . - 확률변수 $X( omega)=I( text{$ omega$ is odd})$라 하고 $Y( omega)= omega$라고 하자 . - 즉 확률변수 $X$는 주사위를 던져서 나온값이 홀수이면 $1$로 맵핑하고 짝수이면 $0$으로 맵핑한다 . - 반면 확률변수 $Y$는 주사위를 던져서 나온값으로 맵핑한다(확률변수 $Y$는 항등함수) . - 확률변수 $X$와 $Y$는 같은 확률공간을 가진다, 둘의 차이점이라곤 주사위를 던져서 나온값은 어떤 실수로 맵핑하냐 뿐이다 . - 하지만 둘의 cdf는 다르다 . $$F_X(x)= begin{cases}0, quad x&lt;0 frac{1}{2}, quad 0 leq x &lt;1 1, quad x geq 1 end{cases}$$ . $$F_Y(y)= begin{cases}0, quad y&lt;1 [5pt] dfrac{1}{6}, quad 1 leq y &lt;2 [7pt] dfrac{2}{6}, quad 2 leq y &lt;3 [7pt] dfrac{3}{6}, quad 3 leq y &lt;4 [7pt] dfrac{4}{6}, quad 4 leq y &lt;5 [7pt] dfrac{5}{6}, quad 5 leq y &lt;6 [5pt] 1, quad y geq 6 end{cases}$$- 참고로 cdf뿐만 아니라 pdf도 다르다 . - 참고 : https://math.stackexchange.com/questions/2596665/x-and-y-are-defined-on-the-same-probability-space-omega-mathcalf-ma?rq=1 . - Q2 : 확률변수 $X$가 임의의 확률분포를 따른다는건 무슨 의미일까? . - 예컨대 $X sim B(10,0.5)$ . - 내 생각 : $X$의 pdf는 $B(10,0.5)$이다 . - 또한 등호($=$)를 쓰지않고 $ sim$을 쓰는건 확률변수는 시행마다 다른 값을 가질 수 있기 때문이다 . &#54869;&#47456;(probability) . - 확률공간 $( Omega, mathcal{F}, Pr)$과 특정사건 $A in mathcal{F}$에 대하여 $Pr(A)$을 사건 $A$의 확률이라고 한다 . &#54869;&#47456;&#48128;&#46020;&#54632;&#49688;(pdf) &#48143; &#45572;&#51201;&#48516;&#54252;&#54632;&#49688;(cdf) . &#54869;&#47456;&#48128;&#46020;&#54632;&#49688;(probability density function, pdf) . &#51060;&#49328;&#54805;&#51032; &#44221;&#50864; pdf&#51032; &#51312;&#44148; . 1. 모든 실수 $x$에 대하여 $f(x) geq 0$ . 2. 확률변수 $X$가 가질 수 있는 값 $x_1, ,x_2, , cdots$ 에 대하여 $f(x_i)&gt;0$ 이며 $ sum f(x_i)=1$ . - $f(x)$는 $P(X=x)=f(x)$ 를 만족하고 확률질량함수(probability mass function, pmf)라고도 함 . &#50672;&#49549;&#54805;&#51032; &#44221;&#50864; pdf&#51032; &#51312;&#44148; . 1. 모든 실수 $x$에 대하여 $f(x) geq 0$ . 2. $ int^{ infty}_{- infty}f(x) ,dx = 1$ . - 연속형 확률변수는 가질 수 있는 값이 셀 수 없는 무한개이므로 가능한 값 하나하나에 확률을 부여하지 않음 . - 대신에 구간에 확률을 부여함 . - $P(X=x)=0$ 이고 $- infty &lt; a &lt; b &lt; infty longrightarrow int_{a}^{b}f(x) ,dx=P(a leq X leq b)$ . &#45572;&#51201;&#48516;&#54252;&#54632;&#49688;(cumulative distribution function, cdf) . - 누적분포함수 $F(x) = P(X leq x)$ . - $X sim f(x)$ : 확률변수 $X$가 확률밀도함수 $f(x)$를 가진다 . - $X sim F(x)$ : 확률변수 $X$가 누적분포함수 $F(x)$를 가진다 . - $P(a&lt; X leq b) = F(b) - F(a)$ . - $f(x) = dfrac{d}{dx}F(x)$ . &#45572;&#51201;&#48516;&#54252;&#54632;&#49688;&#51032; &#51312;&#44148; . 1. $ lim limits_{x to- infty}F(x)=0$ . 2. $ lim limits_{x to infty}F(x)=1$ . 3. $ lim limits_{h to0+}F(x+h)=F(x) longrightarrow$ 우연속 함수 . 4. $a&lt;b$ 이면 $F(a) leq F(b)$ . &#44208;&#54633; &#48143; &#51312;&#44148;&#48512; &#54869;&#47456;&#48516;&#54252; . &#44208;&#54633; &#54869;&#47456;&#48516;&#54252; . - 여러 개의 확률변수들을 한번에 고려하는 경우에 사용 &gt; ex) 아빠와 아들의 키를 함께 고려 . - 확률벡터 &gt; $ boldsymbol{X} = (X_1, ,X_2, , cdots, ,X_k)$ . - 두 확률변수 $X$와 $Y$의 결합 확률밀도함수 $f_{ ,X, ,Y}(x,y)$ . - 이산형인 경우 : $f_{ ,X, ,Y}(x,y)=P(X=x, ,Y=y)$ . - 연속형인 경우 : 임의의 영역 $A$에 대하여 $P[(X, ,Y) in A]= iint_{ ,A}f_{ ,X, ,Y}(x,y) ,dxdy$ 를 만족하는 $f_{ ,X, ,Y}(x,y)$ . - 통계수학 교재의 통계학에서의 적분과 미분적분학 교재의 적분 공부하기 . &#44208;&#54633; &#45572;&#51201;&#48516;&#54252;&#54632;&#49688; . - 결합 누적분포함수 : $F(x_1, ,x_2, , cdots, ,x_k) = P(X_1 leq x_1, ,X_2 leq x_2, , cdots, ,X_k leq x_k)$ . - $f(x_1, ,x_2, , cdots, ,x_k) = cfrac{ partial^k}{ partial x_1 cdots partial x_k}F(x_1, ,x_2, , cdots, ,x_k)$ . &#51452;&#48320; &#54869;&#47456;&#48516;&#54252; . - 결합분포가 주어졌다고 하자 그런데 각 변수만의 분포가 필요할 수 있음 . - 결합 확률밀도함수 $f_{X,Y}(x,y)$가 주어졌을 때 $f_X(x), ;f_Y(y)$를 주변 확률밀도함수라고 함 . - 주변 확률밀도함수 &gt; marginal probability density function . 이산형인 경우 | . $$f_X(x) = sum limits_{ text{모든 $y$}}f_{X,Y}(x,y), quad f_Y(y) = sum limits_{ text{모든 $x$}}f_{X,Y}(x,y)$$ . 연속형인 경우 | . $$f_X(x) = int^{ infty}_{- infty}f_{X,Y}(x,y) ,dy, quad f_Y(y) = int^{ infty}_{- infty}f_{X,Y}(x,y) ,dx$$ . - 여러개의 확률변수에 대해서도 확장 가능함 . &#51312;&#44148;&#48512; &#54869;&#47456;&#48516;&#54252; . - 조건부 확률의 확률변수 버전 . - 어떤 몇 개의 확률변수 값이 주어졌을 때 다른 확률변수들의 분포 . - $X=x$가 주어졌을 때 $Y mid X=x$의 조건부 확률밀도함수는 $f_{Y mid x}(y mid x)$ 이다 . - 편의상 $Y mid X = x Longleftrightarrow Y mid x$ . - 조건부 확률밀도함수 &gt; conditional probability density function . $$f_{Y mid X=x}(y mid x)= cfrac{f_{X,Y}(x,y)}{f_X(x)} qquad text{단, } f_X(x)&gt;0$$ . &#46021;&#47549;&#54869;&#47456;&#48320;&#49688; . - 두 확률변수 $X$와 $Y$는 임의의 실구간 $A$와 $B$에 대하여 $$ P(X in A, ,Y in B)=P(X in A) cdot P(Y in B)$$ 가 성립할 때 서로 독립(independent)이라고 함 . - 위의 정리를 확률밀도함수를 사용하여 나타내보자 . - 두 확률변수 $X$와 $Y$가 서로 독립일 필요충분조건은 $$f_{X,Y}(x,y)=f_X(x) cdot f_Y(y)$$ . - 두 확률변수 $X$와 $Y$의 독립여부 파악하는 방법! . 1. 결합 확률밀도함수를 통해 $X$와 $Y$의 주변 확률밀도함수를 구한다 . 2. 그리고 $f_{X,Y}(x,y)=f_X(x) cdot f_Y(y)$가 성립하는지 확인한다 . . Tip: 쉬운방법은 $f_{X,Y}(x,y)$가 $X$만의 함수와 $Y$만의 함수로 인수분해 되는지 파악하는 것 . &#44592;&#45843;&#44050; . - 확률변수 $X$의 확률밀도함수가 $f(x)$일 때 $X$의 기댓값(expectation)은 $$E(X)= begin{cases} sum limits_{ text{모든 }x_i}x_{i}f(x_i) quad text{이산형인 경우} int_{- infty}^{ infty}xf(x) ,dx quad text{연속형인 경우} end{cases}$$ . - 단 $E(|X|)&lt; infty$ . - 확률변수 $X$의 기댓값이 아닌 $2X+3$이나 $X^2$ 같은 확률변수의 기댓값이 궁금할 수 있다 . - $Y=g(X)$의 확률밀도함수를 $f_Y(y)$라고 하면 $$E_X[g(X)]=E_Y(Y)= begin{cases} sum limits_{ text{모든 }y_i}y_{i}f_{Y}(y_i) quad text{이산형인 경우} int_{- infty}^{ infty}yf_{Y}(y) ,dy quad text{연속형인 경우} end{cases}$$ . - 만약 $X$의 확률밀도함수를 알고 있으면 $Y$의 확률밀도함수를 구할 필요가 없다 . $$E_X[g(X)]=E_Y(Y)= begin{cases} sum limits_{ text{모든 }x_i}g(x_{i})f_{X}(x_i) quad text{이산형인 경우} int_{- infty}^{ infty}g(x)f_{X}(x) ,dx quad text{연속형인 경우} end{cases}$$ . - $Y=g(X)$의 기댓값을 구하는 데는 위의 두 가지 방법이 가능함 . &#44592;&#45843;&#44050;&#51032; &#49457;&#51656; . - $E(c)=c$ . - $E(aX+b)=aE(X)+b$ . - 두 확률변수 $X$와 $Y$가 서로 독립인 경우 . - $E(XY)=E(X) cdot E(Y)$ . - $E(g(X)h(Y)]=E[g(X)] cdot E[h(Y)]$ . &#48516;&#49328;&#44284; &#44277;&#48516;&#49328; . $$Var(X)=E[X-E(X)]^2=E(X^2)-[E(X)]^2 sigma_{X}= sqrt{Var(X)}$$ - 두 확률변수 $X,Y$의 공분산은 다음과 같다 . $$ begin{aligned}Cov(X,Y)&amp;=E[(X-EX)(Y-EY)] &amp;=E(XY)-E(X)E(Y) end{aligned}$$ &#48516;&#49328;&#51032; &#49457;&#51656; . 1. $Var(aX+b)=a^2Var(X)$ . 2. 확률변수들이 서로 독립이면 $Var bigg( sum limits^{n}_{i=1}X_{i} bigg)= sum limits^{n}_{i=1}Var(X_i)$ . 3. $Cov(X,X)=Var(X)$ . 4. 두 확률변수가 서로 독립이면 $Cov(X,Y)=0$ . 5. $Cov(aX+b,cY+d)=acCov(X,Y)$ . 6. $Var bigg( sum limits^{n}_{i=1}X_{i} bigg)= sum limits^{n}_{i=1}Var(X_{i})+2 mathop{ sum sum} limits_{j&lt;k}Cov(X_j,X_k)$ . &#51312;&#44148;&#48512; &#44592;&#45843;&#44050; . $$E(Y mid X=x)=E_Y(Y)= begin{cases} sum limits_{ text{모든 }y_i}y_{i}f_{Y mid x}(y_i mid x) quad X,Y text{가 이산형인 경우} int_{- infty}^{ infty}yf_{Y mid x}(y mid x) ,dy quad X,Y text{가 연속형인 경우} end{cases}$$ . - (이중 기댓값 정리) 두 확률변수 $X,Y$에 대하여 $E[E(Y mid X)]=E(Y)$ 가 성립함 . - 확률변수 $X$와 $Y$가 독립이면 $E(Y mid x)=E(Y), ;E(X mid y)=E(X) to$ 사건의 독립 확률변수 버전 . - 조건부 분산 : $Var(Y mid x)=E[ {Y-E(Y mid x) }^2 mid x] = E(Y^2 mid x)-[E(Y mid x)]^2$ . - 분산 분해 : $Var(Y) = E[Var(Y mid X)]+Var[E(Y mid X)]$ . - 조건부 분산($E[Var(Y mid X)]$)이 무조건부 분산($Var(Y))$보다 평균적으로 더 작음 . - $Var(E(Y mid X)) leq Var(Y) longrightarrow$ 개별 개체의 산포보다 그룹별 평균의 산포가 작음 . &#54869;&#47456;&#48512;&#46321;&#49885; . - 마코프 확률부등식 : 실함수 $u(X) &gt; 0$라고 할 때 $P[u(X) geq c] leq dfrac{E[u(X)]}{c}$ . - 체비셰프 부등식 : $P(|X- mu| &lt; k sigma) geq 1- dfrac{1}{k^2}$ . - 코시-슈바르츠 부등식 : $[E(XY)]^2 leq E(X^2) cdot E(Y^2)$ . &#54364;&#48376;&#48516;&#54252; &#48143; &#44536;&#51032; &#44540;&#49324; . &#45824;&#49688;&#51032; &#48277;&#52825;&#44284; &#51473;&#49900;&#44537;&#54620;&#51221;&#47532; . &#54869;&#47456; &#49688;&#47156; . - 확률변수의 열 $X_1,X_2, cdots,X_n, cdots$과 확률변수 $X$가 같은 확률공간에 정의된다고 하자 . - 확률변수의 열을 모르면 다음을 참고하자 : https://www.probabilitycourse.com/chapter7/7_2_2_sequence_of_random_variables.php . - 확률변수의 수렴 : https://www.probabilitycourse.com/chapter7/7_2_0_convergence_of_random_variables.php . - 만약 임의의 $ epsilon&gt;0$에 대해 $ lim limits_{n to infty}P(|X_n-X| geq epsilon)=0$ 또는 $ lim limits_{n to infty}P(|X_n-X|&lt; epsilon)=1$ 이라면 . - $X_n$이 $X$로 확률적으로 수렴한다고 하고 $X_n{ xrightarrow{~~p~~}} X$로 표기 : 확률 수렴(convergence in probability) . - 확률 수렴이 무엇인지 뭔가 직관적으로 와닿지 않는다 . - 일단 수열의 수렴을 생각해보자 . - 예컨데 $1, frac{1}{2}, frac{1}{4}, frac{1}{8}, cdots $ 와 같은 수열이 있다고 하자 . - 위의 수열을 다음과 같이 나타낼 수 있음 &gt; $a_n= dfrac{1}{2^n}, ;n in mathbb{N}$ . - 여기서 $n to infty$ 이면 $a_n to 0$임을 알 수 있다 . - 즉 $n$이 커지면 어떠한 상수 $a$로 수렴한다는 것 . - 수열 대신 확률변수의 열인 경우도 똑같이 생각하면 된다 . - 예컨대 다음과 같은 확률변수의 열이 있다고 해보자 . - $X_1,X_2, cdots,X_n$ &gt; $n$에 의존한다 . - 그런데 $X_1 sim EXP(1), ; X_2 sim EXP(2), ; cdots, ;X_n sim EXP(n)$ 라고 하자 . - 즉 $X_n sim EXP(n)$, 예컨대 $n=3$이면 $X_3 sim EXP(3)$ . - 참고로 $EXP(n)$에서 $n$은 포아송분포의 모수 $ lambda$를 의미한다 . - 만약 $n to infty$ 이면 $X_n to 0$가 되고 이는 $X_n xrightarrow{~~p~~}0$ . $$ begin{aligned} lim limits_{n to infty} P(|X_n-X| geq epsilon)&amp;= lim limits_{n to infty} P(|X_n-0| geq epsilon) &amp;= lim limits_{n to infty} P(X_n geq epsilon) quad (X_n geq 0 text{ as } X_n sim EXP(n)) &amp;= lim limits_{n to infty} 1-F_{X_n}( epsilon) &amp;= lim limits_{n to infty} 1-(1-e^{-n epsilon}) &amp;= lim limits_{n to infty} e^{-n epsilon} &amp;=0, quad forall epsilon geq 0 end{aligned}$$- 따라서 $X_n xrightarrow{~~p~~}0$ . - 다시 말하자면 확률변수의 열 $X_1,X_2, cdots,X_n$은 zero random variable $X$로 확률 수렴한다 . - 참고 : https://www.probabilitycourse.com/chapter7/7_2_5_convergence_in_probability.php . - 근데 문득 궁금한점이 생겼다 . - $X_1,X_2, cdots,X_n$은 같은 확률공간에 존재하는건가? . - $ Omega, mathcal{F}$는 같다 . - 그런데 $ Pr$은? . - $ Pr$이 같다면 예컨대 $ Pr(1&lt;X&lt;2)$가 $X_1,X_2, cdots,X_n$에 대해서 같아야 하는거 아닌가? . - 하지만 $X_1,X_2, cdots,X_n$ 각각의 pdf는 다르기에 $ Pr(1&lt;X&lt;2)$도 다르다 . - 그럼 같은 확률공간이 아닌건가? . - 아니면 임의의 실수 $a$에 대해서 $ Pr(a)=0$이니까 똑같나? . - 그냥 내가 확률공간의 의미를 잘못알고 있는 걸수도... . - 위에 대한 나의 생각 : $ Pr$은 $ mathcal{F}$를 $[0,1]$로 맵핑하는 함수다 &gt; 예컨대 동전던지기의 경우 $ Pr( {H })= dfrac{1}{2}$ . - $ Pr(1&lt;X&lt;2)$에서 $1&lt;X&lt;2$는 $ mathcal{F}$ 중에서 하나의 사건에 해당한다(?) . - $ Pr$은 $1&lt;X&lt;2$를 $f_X(x)$ 그래프 상에서 전체면적($1$) 대비 $1&lt;x&lt;2$ 아래의 면적의 차지 비율에 맵핑한다 . - 예컨대 정규분포의 경우 $ Pr(0&lt;X&lt; infty) = 0.5$이다 . - 위의 경우 $ Pr$은 $ mathcal{F}$를 $f_X(x)$ 그래프 상에서 전체면적($1$) 대비 $ mathcal{F}$에 해당하는 아래의 면적의 차지 비율에 맵핑한다 . - 즉 $X_1,X_2, cdots,X_n$ 각각의 pdf는 다르기에 $ Pr(1&lt;X&lt;2)$도 다르지만 $ Pr$ 함수의 규칙은 같으므로 같은 확률공간에 있다고 한다(?) . - $ Pr(A)= int_A f(x)dx, quad A in mathcal{F}$ &gt; $ Pr$은 동일함! . - 다시 말하지만 $ Pr$은 함수이다 . - $y=f(x)$에서 함수는 $f$이다 &gt; 예컨대 $y=2x$이면 함수는 $ times 2$, $x$는 input, $y$는 output . - 당연히 $x$가 달라지면 $y$도 달라진다 &gt; $y=2x$에서 $x=1$이면 $y=2$, $x=2$이면 $y=4$ . - 아니 그런데 $1&lt;X&lt;2$는 다 같은거 아님? . - $1&lt;X&lt;2$는 pdf상에서 $1&lt;x&lt;2$인 영역이므로 pdf에 따라 다르다(?) &gt; 그러니 $1&lt;X&lt;2$는 다 같은것이 아니다(?) . import matplotlib.pyplot as plt import numpy as np from scipy.stats import expon xx = np.linspace(0, 6, 1000) x = np.linspace(2, 4, 100) y1 = expon.pdf(x, scale = 1) y2 = expon.pdf(x, scale = 2) with plt.style.context(&#39;seaborn-darkgrid&#39;): fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5)) ax1.plot(xx, expon.pdf(x = xx, scale = 1)) ax1.set_title(&#39;$ lambda = 1$&#39;) ax1.set_xlim(0, 6) ax1.set_ylim(0, 1) ax1.fill_between(x, y1, 0) ax2.plot(xx, expon.pdf(x = xx, scale = 2)) ax2.set_title(&#39;$ lambda = 0.5$&#39;) ax2.set_xlim(0, 6) ax2.set_ylim(0, 1) ax2.fill_between(x, y2, 0) fig.suptitle(&#39;exp dist&#39;, fontsize = 16) plt.show() . . - 결론은 $ Pr$은 보통의 연속형확률변수이면 지수분포이든 정규분포이든 면적을 구하는 함수이니 동일하다는 것 . &#45824;&#49688;&#51032; &#48277;&#52825; . - 평균이 $ mu&lt; infty$인 확률밀도함수 $f(x)$로부터 랜덤표본($i.i.d$) $X_1,X_2, cdots,X_n$을 얻었다면 $ overline{X}_n xrightarrow{~~p~~} mu$가 성립 : 대수의 법칙(law of large numbers) . &#48516;&#54252; &#49688;&#47156; . - 확률변수의 열 $X_1,X_2, cdots,X_n, cdots$이 누적분포함수 $F_{X_1},F_{X_2}, cdots,F_{X_n}, cdots$을 각각 갖고 $X sim F_X$라고 하자 . - 만약 함수 $F_X$가 연속인 모든 점 $x$에서 $ lim limits_{n to infty}F_{X_n}=F_X(x)$가 만족된다면 . - $X_n$이 $X$로 분포 수렴한다고 말하고 $X_n{ xrightarrow{~~d~~}} X$로 표기 : 분포 수렴(convergence in distribution) . - 여기서 $X$의 분포를 $X_n$의 극한분포(Limiting Distribution) 또는 점근적분포(Asymptotic Distribution)라고 한다 . . Note: $X_n{ xrightarrow{~~p~~}} X$ 이면 $X_n{ xrightarrow{~~d~~}} X$ 이지만 역은 항상 성립하진 않는다 . - 참고 : https://www.probabilitycourse.com/chapter7/7_2_4_convergence_in_distribution.php . . Note: $c$가 상수일 때 $X_n{ xrightarrow{~~p~~}} c$ 와 $X_n{ xrightarrow{~~d~~}} c$ 는 서로 동치이다 . &#51473;&#49900;&#44537;&#54620;&#51221;&#47532; . - 확률변수 $X_1,X_2, cdots$의 cdf가 $F_1,F_2, cdots$이고 mgf가 $M_1(t),M_2(t), cdots$라고 하자 . - 이때 어떤 $t$의 개구간 $-h&lt;t&lt;h$에 대하여 $ lim limits_{n to infty}M_n(t)=M(t)$이고 . - $M(t)$가 누적분포함수 $F(x)$를 갖는 어떤 확률분포의 mgf라고 하면 $F(x)$가 연속인 모든 점에서 $ lim limits_{n to infty}F_n(x)=F(x)$가 성립한다 . - 즉, 적률생섬함수열의 극한이 임의의 확률변수 $X$의 mgf로 수렴하면 $X_n{ xrightarrow{~~d~~}} X$가 성립한다 . - 평균과 분산이 각각 $ mu$와 $ sigma^2&lt; infty$인 $f(x)$로부터 랜덤표본 $X_1,X_2, cdots,X_n$을 얻었다면 이때 확률변량 . $$Z_n= dfrac{ sum limits_{i=1}^{n}X_i-E left( sum limits_{i=1}^{n}X_i right)}{ sqrt{Var left( sum limits_{i=1}^{n}X_i right)}}= dfrac{ sum limits_{i=1}^{n}(X_i- mu)}{ sqrt{n} sigma} = dfrac{ overline{X}_n-E( overline{X}_n)}{ sqrt{Var( overline{X}_n)}}= dfrac{ overline{X}_n- mu}{ left. sigma middle/ sqrt n right.}$$- 는 표본의 크기 $n$이 무한대에 접근함에 따라 표준정규분포 $N(0,1)$로 분포수렴한다 : 중심극한정리(central limit theorem) . Slutsky &#51221;&#47532; . . Note: 확률변수열 $u_n$과 임의의 함수 $g$와 상수 $u$에 대하여 $u_n xrightarrow{~~p~~}u$이면 $g(u_n) xrightarrow{~~p~~}g(u)$가 성립한다 . - 확률변수열 $X_1,X_2, cdots,X_n$이 상수 $c$로 확률적으로 수렴($X_n xrightarrow{~~p~~}c$)하며 . - 확률변수열 $Y_1,Y_2, cdots,Y_n$은 확률변수 $Z$로 분포수렴($Y_n xrightarrow{~~d~~}Z$)한다고 하면 . - $X_n+Y_n xrightarrow{~~d~~}Z+c$와 $X_nY_n xrightarrow{~~d~~}cZ$가 성립한다 . - Slutsky 정리 응용 예시 . - 평균과 분산이 각각 $ mu$와 $ sigma^2 &lt; infty$인 모분포루터 랜덤표본 $X_1,X_2, cdots,X_n$을 얻었다고 하자 . - $ dfrac{ overline{X}_n - mu}{ left. S_n middle/ sqrt n right.} sim t(n-1)$를 스튜던트화된 표본평균이라 한다 . - 그런데 중심극한정리에 의해 $ dfrac{ overline{X}_n - mu}{ left. sigma middle/ sqrt n right.} xrightarrow{~~d~~}N(0,1)$ 이고 $S_n xrightarrow{~~p~~} sigma$ 이므로 다음이 성립한다 . - $ dfrac{ overline{X}_n - mu}{ left. S_n middle/ sqrt n right.}= dfrac{ overline{X}_n - mu}{ left. sigma middle/ sqrt n right.} times dfrac{ sigma}{S_n} xrightarrow{~~d~~}N(0,1)$ . &#45944;&#53440; &#48169;&#48277; . - 임의의 함수 $g( theta)$의 연속인 도함수 $g&#39;( theta)$가 존재하고 $0$이 아니라고 하자 . - 확률변수의 열 $X_1,X_2, cdots,X_n, cdots$에 대해서 $ sqrt{n}(X_n- theta) xrightarrow{~~d~~}N(0, sigma^2)$ 이라고 하자 . - 평균값 정리에 의하여 $X_n$과 $ theta$ 사이에 있는 $ tilde{ theta}$에 대하여 $ dfrac{g(X_n)-g( theta)}{X_n- theta}=g&#39;( tilde{ theta})$가 성립한다 . - 한편 $X_n xrightarrow{~~p~~} theta$이므로 $X_n$과 $ theta$사이에 있는 $ tilde{ theta}$에 대해서도 $ tilde{ theta} xrightarrow{~~p~~} theta$이며 $g&#39;( tilde{ theta}) xrightarrow{~~p~~}g&#39;( theta)$가 성립한다 . - 따라서 $ sqrt{n} big[(g(X_n)-g( theta) big]=g&#39;( tilde{ theta}) sqrt{n}(X_n- theta)$으로부터 슬럿츠키 정리를 사용하여 . - $ sqrt{n}(g(X_n)-g( theta)) xrightarrow{~~d~~}N(0, sigma^2[g&#39;( theta)]^2)$을 보일 수 있다 . - 델타 방법은 때로는 점근적 정규성에 대한 가정을 하지 않고 확률변수 $g(X)$의 기댓값과 분산을 확률변수 $X$를 통해 근사할 때도 사용된다 . - 테일러 전개 : $E big[g(X) big] approx E big[(g( mu)+g&#39;( mu)(X- mu) big]=g( mu)=g big(E(X) big)$ . - 테일러 전개 : $Var big(g(X) big) approx Var big((g( mu)+g&#39;( mu)(X- mu) big)=g( mu)= big {g&#39;( mu) big }^2 Var(X)$ . &#49692;&#49436;&#53685;&#44228;&#47049; . - 확률밀도함수가 $f(x)$이고 누적분포함수가 $F(x)$인 모집단으로부터 . - 크기가 $n$인 랜덤표본 $X_1,X_2, cdots,X_n$을 얻었다고 하자 . - 이때 랜덤표본을 작은 것부터 크기순으로 나열하여 다음과 같은 순서통계량(order statistic)을 구할 수 있다 . $$X_{(1)} leq X_{(2)} leq cdots leq X_{(n-1)} leq X_{(n)}$$ . - 예컨대 모집단이 표준정규분포일 때 크기가 $n$인 랜덤표본 $X_1,X_2, cdots,X_n$를 얻었다면 . - 확률변수의 순서통계량은 $1:1$ 변환이 아니다($n!:1$ 변환) . - 그렇기에 순서통계량의 결합 확률밀도함수는 $n!f(x_{(1)})f(x_{(2)}) cdots f(x_{(n)})$이다 . - 한편, $k$번째 순서통계량 $X_{(k)}$의 확률밀도함수는 다음과 같다 . $$f_{X_k}(x_{(k)})= cfrac{n!}{(k-1)!(n-k)!}(F(x_{(k)}))^{k-1}(1-F(x_{(k)}))^{n-k}f(x_{(k)})$$ .",
            "url": "https://jaesu26.github.io/green/statistics/2021/09/03/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99.html",
            "relUrl": "/statistics/2021/09/03/%EC%88%98%EB%A6%AC%ED%86%B5%EA%B3%84%ED%95%99.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "이진 탐색(Binary search)",
            "content": "&#51060;&#51652; &#53456;&#49353;(Binary search) . - 오름차순으로 정렬된 리스트에서 특정한 값의 위치를 찾는 알고리즘 . - 처음 중간의 값을 임의의 값으로 선택하고 그 값과 찾고자 하는 값의 크고 작음을 비교하는 방식을 사용 . - 처음 선택한 중앙값이 만약 찾는 값보다 크면 그 값은 새로운 최댓값이 되며 작으면 그 값은 새로운 최솟값이 됨 . - 검색 원리상 정렬된 리스트에만 사용할 수 있다는 단점이 있지만 검색이 반복될 때마다 목표값을 찾을 확률은 두 배가 되므로 속도가 빠르다는 장점 &gt; $O(logN)$ . - 참고: 이진 탐색 . &#51060;&#51652; &#53456;&#49353; &#44396;&#54788; . - 정렬된 array에서 target의 위치를 이진 탐색으로 찾는 코드를 구현하자 . - 이 코드를 통해 1~100 숫자(arr)에서 88(target)을 찾는 과정을 살펴보자 . def binary_search(arr, target): arr.sort() ## 리스트를 오름차순으로 정렬 low = 0 high = len(arr) - 1 ## arr의 첫번째 인덱스(low)부터 마지막 인덱스(high)까지 탐색 while low &lt;= high: mid = (high + low) // 2 print(&#39;low: {} nhigh: {} nmid: {}&#39;.format(low, high, mid)) if arr[mid] == target: ## 원하는 값을 찾으면 mid(인덱스)를 반환 return mid elif arr[mid] &gt; target: ## 원하는 값이 중간점보다 작은 경우 왼쪽 부분 탐색 high = mid - 1 else: low = mid + 1 ## 원하는 값이 중간점보다 큰 경우 오른쪽 부분 탐색 return False ## 원하는 값이 arr에 없는 경우 . arr = list(range(1, 101)) target = 88 binary_search(arr, target) . low: 0 high: 99 mid: 49 low: 50 high: 99 mid: 74 low: 75 high: 99 mid: 87 . 87 . - 우리가 찾는 target인 88은 arr의 87번째 인덱스 값이라고 한다 . arr[87] . 88 . - 진짜임 . - 어떤 과정을 거쳐서 87번째 인덱스라는 것을 알려준 것일까? . - arr은 1부터 100까지의 값임 . 1. 1 2 3 $ cdots$ 98 99 100 &gt; low는 0이고 high는 99이므로 mid는 49임 . 2. arr[mid(49)] = 50는 target(88)보다 작으므로 arr[mid(49)+1] ~ arr[high(99)] 를 탐색하면 target(88)이 존재할 것임 . 3. 51 52 53 $ cdots$ 98 99 100 &gt; low는 50이고 high는 99이므로 mid는 74임 . 4. arr[mid(74)]는 target(88)보다 작으므로 arr[mid(74)+1] ~ arr[high(99)] 를 탐색하면 target(88)이 존재할 것임 . 5. 76 77 78 $ cdots$ 98 99 100 &gt; low는 75이고 high는 99이므로 mid는 87임 . 6. arr[mid(87)]는 target(88)과 동일하므로 mid(87)를 return한다 . &#51060;&#51652; &#53456;&#49353; &#49884;&#44036; &#48373;&#51105;&#46020; . - 시간 복잡도는 $O(logN)$이다 . - 위에서 1~100사이에서 target을 찾는 과정을 살펴봤음 . - 탐색 범위를 $N$이라고 한다면 처음에는 $N$만큼 탐색함 . - 그 다음에는 $ frac{N}{2}$만큼 탐색함 . - 또 그 다음에는 $ frac{N}{4}$만큼 탐색함 . - 이를 살펴보면 탐색 범위는 $N, frac{N}{2}, frac{N}{4}, cdots , 1$ . - 시간 복잡도는 알고리즘의 의해 수행되는 기본 연산의 개수를 보면 알 수 있음 . - 연산 횟수(탐색 반복 횟수)를 $k$라고 하면 처음 탐색($k=1$)때의 탐색 범위는 $N$, 두번째 탐색($k=2$)때의 탐색 범위는 $ frac{N}{2}$이며 이를 계속하면 탐색 범위는 $1$이 됨 . - 위의 관계식을 통해 $N times( frac{1}{2})^{k} = 1$임을 알 수 있고 이를 정리하면 $k=log_{2}N$임 . - Big O 표기법에서 로그의 밑은 영향이 없으므로 이진 탐색의 시간 복잡도는 $O(logN)$이라고 할 수 있음 &gt; 이해 안되면 통계수학 big O 표기법 다시 보기 .",
            "url": "https://jaesu26.github.io/green/python/algorithm/2021/08/31/%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89.html",
            "relUrl": "/python/algorithm/2021/08/31/%EC%9D%B4%EC%A7%84%ED%83%90%EC%83%89.html",
            "date": " • Aug 31, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "자료구조 스택(stack)",
            "content": "&#49828;&#53469;(stack) . - 스택(stack)은 기본적인 자료 구조 . - 스택은 자료를 넣고(push) 자료를 빼는(pop) 입구가 같은 선형 구조(LIFO - Last In First Out)으로 되어 있음 . - 참고: 자료구조 스택 . &#49828;&#53469;(stack) &#49324;&#50857; . - 파이썬에서 stack은 list를 통해 구현할 수 있다 . - stack.append(x)를 통해 스택에 x를 오른쪽(뒤)에 push한다 . - stack.pop()을 통해 스택의 마지막 원소를 pop한다 . &#50696;&#51228; - &#51228;&#47196; . 문제 출처: 백준 10773번 | . - 스택(stack)의 기본적인 push와 pop을 이요하면 된다 . - 0이 입력되면 pop하고 그 외에 수가 입력되면 push한다 . K = int(input()) stack = list() ## stack = []와 동일 for _ in range(K): num = int(input()) if num == 0: stack.pop() else: stack.append(num) print(sum(stack)) . 0 .",
            "url": "https://jaesu26.github.io/green/python/data%20structure/2021/08/30/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EC%8A%A4%ED%83%9D.html",
            "relUrl": "/python/data%20structure/2021/08/30/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%EC%8A%A4%ED%83%9D.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "자료구조 힙(heap)",
            "content": "&#55193;(heap) . - 최댓값 및 최솟값을 찾아내는 연산을 빠르게 하기 위해 고안된 완전이진트리 자료구조 . - 힙 속성 &gt; A가 B의 부모노드(parent node) 이면 A의 키(key)값과 B의 키값 사이에는 대소관계가 성립 . - 최대 힙: 부모노드의 키값이 자식노드의 키값보다 항상 큰 힙 . - 최소 힙: 부모노드의 키값이 자식노드의 키값보다 항상 작은 힙 . - 키(key)값의 대소관계는 오로지 부모노드와 자식노드 간에만 성립하며 특히 형제 사이에는 대소관계가 정해지지 않음 . - 대개 자식노드 개수가 최대 2개인 이진 힙(binary heap)을 사용함 . - 데이터의 최대값(최대 힙) or 최소값(최소 힙)을 찾는데 $O(1)$이 소요됨 &gt; 루트노드에 저장되어 있으므로 . - 데이터의 삽입과 삭제는 $O(logN)$이 소요됨 . - 참고: 자료구조 힙 . &#55193;(heap) &#49324;&#50857; . - 파이썬의 heapq 모듈은 최소 힙이다 . - 힙(Heap) 구조 그림으로 보기 &gt; 힙 구조 &gt; 이거 보면 무조건 이해 가능 . - 힙을 코드로 구현하기 전에 필요한 함수를 공부하자 . - heapq.heappush(heap, item) &gt; item을 heap에 추가함 . - heapq.heappop(heap) &gt; heap에서 가장 작은 원소(루트 노드)를 pop(추출)하고 비어 있으면 IndexError . - heapq.heapify(x) &gt; 리스트 x를 heap 자료 구조로 변환함 . - 참고: heapq . &#50696;&#51228;: &#52852;&#46300; &#54633;&#52404; &#45440;&#51060; . 문제 출처: 백준 15903번 | . - 카드 더미의 최소값 2개를 뽑은다음 두 숫자를 두 수의 합으로 바꿔주는 것을 반복하면 됨 . - 최소값 2개를 뽑으면 되니 Heap을 사용하자 . - Heap에서 최소값 추출은 $O(1)$ 삽입과 삭제는 $O(logN)$이므로 다른 구조보다 효율적으로 문제를 해결할 수 있음 . import heapq n, m = map(int, input().split()) cards = list(map(int, input().split())) heapq.heapify(cards) ## list인 cards를 Heap구조로 변홤함 for _ in range(m): two_card_sum = heapq.heappop(cards) + heapq.heappop(cards) ## 최소값 2개(제일 작은 값과 두 번째로 작은 값)를 뽑음 heapq.heappush(cards, two_card_sum) ## 두 수를 두 수의 합으로 바꿔줌 heapq.heappush(cards, two_card_sum) ## 그리고 cards 에 push한다 print(sum(cards)) . 19 .",
            "url": "https://jaesu26.github.io/green/python/data%20structure/2021/08/26/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%9E%99.html",
            "relUrl": "/python/data%20structure/2021/08/26/%EC%9E%90%EB%A3%8C%EA%B5%AC%EC%A1%B0-%ED%9E%99.html",
            "date": " • Aug 26, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "R 프로그래밍",
            "content": "참고: R 프로그래밍 - 허명회 지음 . - R 프로그래밍에 대해 복습할 겸 간단히 정리 . &#48289;&#53552;(vector) . - 데이터 컨테이너의 기본형 . &#48289;&#53552; . x &lt;- 1 is.vector(x) . TRUE - x는 길이가 1인 벡터 = 스칼라 . print(pi) print(pi, 16) . [1] 3.141593 [1] 3.141592653589793 . - π는 숫자가 예약되어 있는 스칼라 . M &lt;- matrix(1:12, nrow = 4, ncol = 3, byrow = T) M . A matrix: 4 × 3 of type int 1 | 2 | 3 | . 4 | 5 | 6 | . 7 | 8 | 9 | . 10 | 11 | 12 | . - M은 행렬 &gt; 벡터의 2차원 배열 . &#51064;&#45937;&#49905; . f &lt;- c(1, 1, 2, 3, 5, 8, 13, 21) f[5] . 5 f[1:5] . &lt;ol class=list-inline&gt;1 | 1 | 2 | 3 | 5 | &lt;/ol&gt; f[-c(1,4)] ## -기호는 제외한다는 의미를 가짐 . &lt;ol class=list-inline&gt;1 | 2 | 5 | 8 | 13 | 21 | &lt;/ol&gt; f[c(1,2,4)] . &lt;ol class=list-inline&gt;1 | 1 | 3 | &lt;/ol&gt; seq&#50752; rep &#54632;&#49688; . - seq(a, b, by = c)는 a부터 b까지 c간격으로 등차수열 생성 . seq(0, 10, 2.5) . &lt;ol class=list-inline&gt;0 | 2.5 | 5 | 7.5 | 10 | &lt;/ol&gt; - seq(a, b, length = n)는 a부터 b까지 길이가 n인 일정 간격 수열을 생성 . seq(0, 10, length = 11) . &lt;ol class=list-inline&gt;0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | &lt;/ol&gt; - rep(x, times = k)는 x의 각 요소가 k의 각 요소씩 반복된 벡터 . rep(NA, 5) . &lt;ol class=list-inline&gt;&lt;NA&gt; | &lt;NA&gt; | &lt;NA&gt; | &lt;NA&gt; | &lt;NA&gt; | &lt;/ol&gt; rep(c(1, 2), 3) . &lt;ol class=list-inline&gt;1 | 2 | 1 | 2 | 1 | 2 | &lt;/ol&gt; rep(c(1, 2, 3), c(3, 2, 1)) . &lt;ol class=list-inline&gt;1 | 1 | 1 | 2 | 2 | 3 | &lt;/ol&gt; - rep(x, each = k)는 x의 각 요소가 각각 k번 반복된 벡터 . rep(c(1, 2), each = 3) . &lt;ol class=list-inline&gt;1 | 1 | 1 | 2 | 2 | 2 | &lt;/ol&gt; &#54596;&#53552;&#47553; . - 조건에 부합하는 데이터 값만 추출 . x &lt;- 1:10 x[x %% 2 == 1] . &lt;ol class=list-inline&gt;1 | 3 | 5 | 7 | 9 | &lt;/ol&gt; subset(x, x %% 2 == 0) . &lt;ol class=list-inline&gt;2 | 4 | 6 | 8 | 10 | &lt;/ol&gt; ifelse &#54632;&#49688; . - ifelse(x, yes, no)는 x가 TRUE이면 yes를 값으로 하고 FALSE이면 no를 값으로 배출 . x &lt;- 1:10 x1 &lt;- ifelse(x %% 2 == 0, x, 2*x) cbind(x, x1) . A matrix: 10 × 2 of type dbl xx1 . 1 | 2 | . 2 | 2 | . 3 | 6 | . 4 | 4 | . 5 | 10 | . 6 | 6 | . 7 | 14 | . 8 | 8 | . 9 | 18 | . 10 | 10 | . names &#54632;&#49688; . - names(x)는 벡터x의 개별 요소에 이름을 부여함 . era &lt;- c(5, 4 ,3, 4 ,5, 6) era . &lt;ol class=list-inline&gt;5 | 4 | 3 | 4 | 5 | 6 | &lt;/ol&gt; - paste()함수는 2개의 문자열 벡터를 sep인수로 붙인다 . names(era) &lt;- paste(&quot;y&quot;, 2001:2006, sep = &quot;-&quot;) era . &lt;dl class=dl-inline&gt;y-20015y-20024y-20033y-20044y-20055y-20066&lt;/dl&gt; &#54665;&#47148;(matrix) . - $p$개의 길이 $n$인 벡터를 열에 배치함 . &#54665;&#47148; . n &lt;- 100 p &lt;- 3 x &lt;- rnorm(n*p) A &lt;- matrix(x, nrow = n, ncol = p) A[1:6, ] . A matrix: 6 × 3 of type dbl 0.3985257 | 0.28159071 | 2.3264862 | . 1.4299784 | -0.60442200 | -1.1111043 | . 0.2929706 | -0.04351824 | 1.0262398 | . 0.9128263 | 0.37584395 | 1.2865189 | . -0.2134398 | 0.99927429 | 0.1097158 | . 0.3423550 | -1.62561727 | 0.8711550 | . - [행, 열] 순으로 인덱싱 . A[1:6, 1:2] . A matrix: 6 × 2 of type dbl 0.3985257 | 0.28159071 | . 1.4299784 | -0.60442200 | . 0.2929706 | -0.04351824 | . 0.9128263 | 0.37584395 | . -0.2134398 | 0.99927429 | . 0.3423550 | -1.62561727 | . - 필터링을 통해 인덱싱도 가능 . A[A[,3] &gt; 0 &amp; A[,2] &gt; 0, ] . A matrix: 31 × 3 of type dbl 0.39852571 | 0.281590708 | 2.32648623 | . 0.91282635 | 0.375843947 | 1.28651890 | . -0.21343980 | 0.999274285 | 0.10971580 | . -0.09365101 | 1.645532123 | 1.65681557 | . 0.59683032 | 1.068823401 | 1.14622308 | . -0.07694040 | 2.143518568 | 0.82898136 | . -0.25295561 | 0.525762383 | 0.48493351 | . 0.69014327 | 0.370450911 | 1.43002803 | . 0.34475001 | 2.278569946 | 0.89774452 | . -0.27996206 | 0.840513317 | 0.44426639 | . -0.80394697 | 2.537376463 | 0.28302193 | . -0.82417672 | 1.777319058 | 0.01703245 | . 0.53338332 | 1.184873169 | 0.38581004 | . -0.18553193 | 0.820022012 | 0.94885563 | . -0.18877772 | 0.128753150 | 0.27520006 | . 1.35820343 | 0.792055902 | 0.28782618 | . 1.61265986 | 0.264419791 | 0.64471494 | . 1.04088992 | 1.584494787 | 0.19616481 | . 0.11426669 | 0.790059186 | 0.94831713 | . -0.16103555 | 0.112897158 | 0.19660418 | . -0.46409134 | 0.397766551 | 1.14864829 | . -0.17503821 | 2.345658962 | 0.80798855 | . 1.14206336 | 0.064781351 | 1.88838626 | . 1.29824117 | 0.308617314 | 1.84653339 | . 0.39353885 | 0.176955322 | 1.06523621 | . -1.26937649 | 0.353061974 | 1.91192497 | . 1.02235605 | 0.936847473 | 1.47997280 | . -1.43203461 | 1.910996122 | 0.36251213 | . 0.17007790 | 1.109508033 | 0.91300794 | . 0.26444960 | 0.009549556 | 0.03743093 | . 1.70585632 | 0.595840494 | 0.27405431 | . - t(A) 함수는 행렬 $ bf A$의 전치행렬을 구해줌 . B &lt;- matrix(1:9, 3, 3) B . A matrix: 3 × 3 of type int 1 | 4 | 7 | . 2 | 5 | 8 | . 3 | 6 | 9 | . t(B) . A matrix: 3 × 3 of type int 1 | 2 | 3 | . 4 | 5 | 6 | . 7 | 8 | 9 | . - solve()함수는 역행렬을 구해줌 . C &lt;- matrix(c(16 ,4, 1, 4, 4, 1, 1, 1, 1), 3, 3) C . A matrix: 3 × 3 of type dbl 16 | 4 | 1 | . 4 | 4 | 1 | . 1 | 1 | 1 | . solve(C) . A matrix: 3 × 3 of type dbl 0.08333333 | -0.08333333 | 0.0000000 | . -0.08333333 | 0.41666667 | -0.3333333 | . 0.00000000 | -0.33333333 | 1.3333333 | . - %*%는 행렬곱 &gt; 잘 알아두자 . solve(C) %*% C . A matrix: 3 × 3 of type dbl 1.000000e+00 | -5.551115e-17 | -1.387779e-17 | . 1.665335e-16 | 1.000000e+00 | 5.551115e-17 | . 0.000000e+00 | 0.000000e+00 | 1.000000e+00 | . - 참고로 $AA^{-1} = I$ . - $I$는 단위행렬 . apply &#54632;&#49688; . - apply(A, 1 or 2, f) &gt; 행렬A의 행(1) or 열(2)에 함수 f를 적용 . - c(1, 2)는 행과 열에 적용 &gt; 각 원소 : 파이썬의 applymap 함수를 생각하자 . M &lt;- matrix(1:12, 3, 4) M . A matrix: 3 × 4 of type int 1 | 4 | 7 | 10 | . 2 | 5 | 8 | 11 | . 3 | 6 | 9 | 12 | . - apply에서 옵션을 1(행)로 하니 전치된 행렬을 반환함 . - 그래서 원래의 행렬 크기와 같게 하려면 t() 함수를 통해 전치시켜야 함 . max_ = apply(M, 2, max) apply(M, 1, &quot;-&quot;, max_) . A matrix: 4 × 3 of type int -2 | -1 | 0 | . -2 | -1 | 0 | . -2 | -1 | 0 | . -2 | -1 | 0 | . max_ = apply(M, 2, max) t(apply(M, 1, &quot;-&quot;, max_)) . A matrix: 3 × 4 of type int -2 | -2 | -2 | -2 | . -1 | -1 | -1 | -1 | . 0 | 0 | 0 | 0 | . - apply에서 옵션을 2(열)로 하니 문제 없어보임 . max_ = apply(M, 1, max) apply(M, 2, &quot;-&quot;, max_) . A matrix: 3 × 4 of type int -9 | -6 | -3 | 0 | . -9 | -6 | -3 | 0 | . -9 | -6 | -3 | 0 | . - 옵션을 c(1, 2)로 하니 각 원소에서 -1을 수행함 . apply(M, 1:2, &quot;-&quot;, 1) . A matrix: 3 × 4 of type dbl 0 | 3 | 6 | 9 | . 1 | 4 | 7 | 10 | . 2 | 5 | 8 | 11 | . - 행렬의 각 열에 대해 최소값 0과 최대값 1이 되도록 변환 . n &lt;- 5 p &lt;- 4 M &lt;- matrix(rnorm(n*p), n, p) M . A matrix: 5 × 4 of type dbl 0.03010344 | -0.7290295 | -0.93633376 | 0.8597820 | . -0.89649998 | -0.6734334 | 0.57546489 | -0.2280883 | . 0.14167091 | 0.6042198 | 0.12012976 | -1.3751352 | . 0.23300396 | -0.9783167 | 0.05895963 | -0.1561013 | . 0.97727567 | -2.1341398 | 1.52209622 | 1.1284436 | . min_ &lt;- apply(M, 2, min) max_ &lt;- apply(M, 2, max) M.1 &lt;- t(apply(M, 1, &quot;-&quot;, min_)) M.2 &lt;- t(apply(M.1, 1, &quot;/&quot;, max_-min_)) M.2 . A matrix: 5 × 4 of type dbl 0.4945114 | 0.5131212 | 0.0000000 | 0.8926890 | . 0.0000000 | 0.5334239 | 0.6149448 | 0.4581629 | . 0.5540529 | 1.0000000 | 0.4297310 | 0.0000000 | . 0.6027957 | 0.4220859 | 0.4048492 | 0.4869165 | . 1.0000000 | 0.0000000 | 1.0000000 | 1.0000000 | . rownames&#50752; colnames &#54632;&#49688; . - 행렬의 행과 열에 이름을 붙임 . n &lt;- 10 x &lt;- matrix(round(rnorm(n*4, 50, 10)), n, 4) ## 평균이 50, 표준편차가 10인 정규분포에서 난수 40개 추출 rownames(x) &lt;- paste(&quot;S&quot;, 1:n, sep = &quot;&quot;) colnames(x) &lt;- c(&quot;math&quot;, &quot;engl&quot;, &quot;science&quot;, &quot;arts&quot;) x . A matrix: 10 × 4 of type dbl mathenglsciencearts . S156 | 52 | 62 | 51 | . S243 | 50 | 35 | 45 | . S337 | 48 | 45 | 49 | . S451 | 35 | 29 | 46 | . S556 | 46 | 43 | 44 | . S656 | 56 | 46 | 51 | . S760 | 68 | 48 | 51 | . S842 | 58 | 54 | 52 | . S954 | 32 | 55 | 50 | . S1038 | 47 | 33 | 56 | . &#47532;&#49828;&#53944;(list) . - R에서 가장 일반적인 데이터 형태 . members &lt;- list(leaders = c(&quot;gang&quot;, &quot;iu&quot;), assisstants = &quot;kang&quot;) members . $leaders &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; $assisstants &#39;kang&#39; - class(X) 함수는 X의 type을 알려줌 . class(members) . &#39;list&#39; - names()함수로 요소의 라벨을 확인 + 변경 가능 . print(names(members)) names(members)[2] &lt;- &quot;workers&quot; print(names(members)) . [1] &#34;leaders&#34; &#34;assisstants&#34; [1] &#34;leaders&#34; &#34;workers&#34; . &#47532;&#49828;&#53944;&#50640; &#51217;&#44540;&#54616;&#44592; . - [[ ]] 사용 . members[[1]] . &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - [ ]은 sublist . - [[ ]]은 벡터이고 [ ]은 리스트임 . members[1] . $leaders = &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - 요소 이름 사용 . members[[&quot;leaders&quot;]] . &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - $ 기호 사용 &gt; 개인적으로 제일 편함 . members$leaders . &lt;ol class=list-inline&gt;&#39;gang&#39; | &#39;iu&#39; | &lt;/ol&gt; - 리스트 내 자료 값 변경도 가능 . members$leaders[1] &lt;- &quot;park&quot; members . $leaders &lt;ol class=list-inline&gt;&#39;park&#39; | &#39;iu&#39; | &lt;/ol&gt; $workers &#39;kang&#39; lapply&#50752; sapply &#54632;&#49688; . - matrix에서 apply() 함수를 사용하듯이 list에선 lapply()와 sapply() 함수를 사용 . - lapply(list, fun)는 list 내 요소들에 함수 fun을 적용하여 결과를 리스트로 출력 &gt; sapply() 는 벡터로 출력 . salaries &lt;- list(leaders = c(250, 200), assistant = 100, members = c(300, 200, 180, 120 ,100)) salaries . $leaders &lt;ol class=list-inline&gt;250 | 200 | &lt;/ol&gt; $assistant 100 $members &lt;ol class=list-inline&gt;300 | 200 | 180 | 120 | 100 | &lt;/ol&gt; - lapply() 사용 . lapply(salaries, mean) . $leaders 225 $assistant 100 $members 180 - sapply() 사용 . - 벡터로 출력이 불가능할 때는 lapply() 처럼 list로 출력함 . sapply(salaries, mean) . &lt;dl class=dl-inline&gt;leaders225assistant100members180&lt;/dl&gt; unlist &#54632;&#49688; . - 함수 이름 그대로 list를 unlist로 만들어준다 . unlist(salaries) ## list에서 vector로 변환되었다 . &lt;dl class=dl-inline&gt;leaders1250leaders2200assistant100members1300members2200members3180members4120members5100&lt;/dl&gt; &#45936;&#51060;&#53552; &#54532;&#47112;&#51076;(data frame) . - matrix는 요소가 숫자만 가능했다면 data frame은 문자열과 같은 다른 type도 가능함 . - 데이터 프레임은 리스트의 일종 . - 리스트는 각 변수마다 길이가 달라도 되지만 데이터 프레임은 각 변수마다 길이가 같아야 함(열의 길이가 동일) . course.id &lt;- c(1, 2, 3, 4 ,5, 6 ,7, 8, 9 ,10) mid &lt;- c(8, 22, 25, 25 ,21, 12, 12, 29, 40, 25) final &lt;- c(11, 24, 31, 13 ,34 ,26, NA ,36, 34 ,38) exams &lt;- data.frame(course.id, mid, final) exams . A data.frame: 10 × 3 course.idmidfinal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | . 2 | 22 | 24 | . 3 | 25 | 31 | . 4 | 25 | 13 | . 5 | 21 | 34 | . 6 | 12 | 26 | . 7 | 12 | NA | . 8 | 29 | 36 | . 9 | 40 | 34 | . 10 | 25 | 38 | . is.list(exams) . TRUE colnames(exams) . &lt;ol class=list-inline&gt;&#39;course.id&#39; | &#39;mid&#39; | &#39;final&#39; | &lt;/ol&gt; names(exams) . &lt;ol class=list-inline&gt;&#39;course.id&#39; | &#39;mid&#39; | &#39;final&#39; | &lt;/ol&gt; length(exams) . 3 - [row, column]으로 인덱싱 . exams[exams$mid &gt; 20, ] . A data.frame: 7 × 3 course.idmidfinal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 2 2 | 22 | 24 | . 3 3 | 25 | 31 | . 4 4 | 25 | 13 | . 5 5 | 21 | 34 | . 8 8 | 29 | 36 | . 9 9 | 40 | 34 | . 1010 | 25 | 38 | . exams[exams$mid &gt; 20, &#39;final&#39;] ## exams[exams$mid &gt; 20, 3] 과 동일함 . &lt;ol class=list-inline&gt;24 | 31 | 13 | 34 | 36 | 34 | 38 | &lt;/ol&gt; - 데이터 프레임의 각 열은 수치 벡터이므로 연산 가능 . mean(exams[, &quot;mid&quot;]) . 21.9 mean(exams$final) . &lt;NA&gt; - 값이 NA로 나옴 &gt; 7번 학생이 기말시험을 결시함 . - 그럼 어떻게 평균을 구하지? &gt; na.rm = T 옵션을 통해 NA를 제외한 데이터만 사용할 수 있음 . mean(exams$final, na.rm = T) . 27.4444444444444 - 만약 시험을 결시한 경우 0점 처리 한다면? &gt; is.na() 함수를 통해 NA인 경우 TRUE를 아닌 경우 FALSE를 생성하여 처리 가능 . is.na(exams$final) . &lt;ol class=list-inline&gt;FALSE | FALSE | FALSE | FALSE | FALSE | FALSE | TRUE | FALSE | FALSE | FALSE | &lt;/ol&gt; exams$final[is.na(exams$final)] &lt;- 0 ## is.na가 True인 경우만 0으로 변경 exams . A data.frame: 10 × 3 course.idmidfinal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | . 2 | 22 | 24 | . 3 | 25 | 31 | . 4 | 25 | 13 | . 5 | 21 | 34 | . 6 | 12 | 26 | . 7 | 12 | 0 | . 8 | 29 | 36 | . 9 | 40 | 34 | . 10 | 25 | 38 | . mean(exams$final) . 24.7 &#46160; &#45936;&#51060;&#53552; &#54532;&#47112;&#51076;&#51032; &#48337;&#54633; . - exams 변수는 중간 기말 성적이 기록되어 있음 . - 새로운 변수 book은 과제와 프로젝트 점수가 student_name의 순서로 정렬되어 있음 . - 이 둘을 합쳐보자 . student_name &lt;- c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;) homework &lt;- c(22, 34, 31, 24, 37, 36, 37, 28, 37, 34) project &lt;- c(NA, 7, NA, NA, 17 ,10, 8, NA ,4, NA) course.id &lt;- c(8, 10, 5, 1, 4, 2, 3 ,9 ,7 ,6) book &lt;- data.frame(student_name, homework, project, course.id) book . A data.frame: 10 × 4 student_namehomeworkprojectcourse.id . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . a | 22 | NA | 8 | . b | 34 | 7 | 10 | . c | 31 | NA | 5 | . d | 24 | NA | 1 | . e | 37 | 17 | 4 | . f | 36 | 10 | 2 | . g | 37 | 8 | 3 | . h | 28 | NA | 9 | . i | 37 | 4 | 7 | . j | 34 | NA | 6 | . - NA는 자료의 수치 연산을 불가능하게 하므로 앞서 했던것처럼 is.na()를 통해 0점 처리하자 . book$project[is.na(book$project)] &lt;- 0 book . A data.frame: 10 × 4 student_namehomeworkprojectcourse.id . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . a | 22 | 0 | 8 | . b | 34 | 7 | 10 | . c | 31 | 0 | 5 | . d | 24 | 0 | 1 | . e | 37 | 17 | 4 | . f | 36 | 10 | 2 | . g | 37 | 8 | 3 | . h | 28 | 0 | 9 | . i | 37 | 4 | 7 | . j | 34 | 0 | 6 | . - 2개의 데이터 프레임을 통합하고자 할 때 확인할 것은 각 데이터 프레임에서 개체들의 정렬순서 . 1. 2개의 프레임에서 순서가 같은 경우 열 묶음(cbind)를 한다 &gt; cbind(exams, book) . - 하지만 course.id의 순서가 다르므로 불가능 . 2. 2개의 프레임에서 그 순서가 다른 경우 공통 개체 식별자(key)를 찾아 정의 &gt; merge() 함수가 key 변수를 찾아줌 . class_record &lt;- merge(exams, book, by = &#39;course.id&#39;) class_record . A data.frame: 10 × 6 course.idmidfinalstudent_namehomeworkproject . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | d | 24 | 0 | . 2 | 22 | 24 | f | 36 | 10 | . 3 | 25 | 31 | g | 37 | 8 | . 4 | 25 | 13 | e | 37 | 17 | . 5 | 21 | 34 | c | 31 | 0 | . 6 | 12 | 26 | j | 34 | 0 | . 7 | 12 | 0 | i | 37 | 4 | . 8 | 29 | 36 | a | 22 | 0 | . 9 | 40 | 34 | h | 28 | 0 | . 10 | 25 | 38 | b | 34 | 7 | . - 위와 같이 key 변수의 이름(위에서는 course.id)이 두 데이터 프레임에서 동일한 경우 by를 사용 &gt; 그렇지 않은 경우에는 by.x와 by.y를 사용 . - 학생들의 총 점수 합계를 구하여 데이터 프레임에 새 변수로 추가해보자 . class_record$total &lt;- apply(class_record[ ,c(2, 3, 5, 6)], 1, sum) class_record . A data.frame: 10 × 7 course.idmidfinalstudent_namehomeworkprojecttotal . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 1 | 8 | 11 | d | 24 | 0 | 43 | . 2 | 22 | 24 | f | 36 | 10 | 92 | . 3 | 25 | 31 | g | 37 | 8 | 101 | . 4 | 25 | 13 | e | 37 | 17 | 92 | . 5 | 21 | 34 | c | 31 | 0 | 86 | . 6 | 12 | 26 | j | 34 | 0 | 72 | . 7 | 12 | 0 | i | 37 | 4 | 53 | . 8 | 29 | 36 | a | 22 | 0 | 87 | . 9 | 40 | 34 | h | 28 | 0 | 102 | . 10 | 25 | 38 | b | 34 | 7 | 104 | . &#51064;&#51088;&#50752; &#45936;&#51060;&#53552; &#50836;&#50557;(factors and summaries) . - R에서 factor는 범주형 변수(벡터) 또는 비연속적 변수(벡터)를 지칭 . &#51064;&#51088;&#50752; &#53580;&#51060;&#48660; . set.seed(1) ## 시드 넘버 설정 alpha &lt;- sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), 25, replace = T) ## &#39;A&#39;, &#39;B&#39;, &#39;C&#39; 중에서 무작위로 25개를 중복을 허용하여 뽑는다 f &lt;- factor(alpha) ## alpha를 범주형 변수로 바꿈 . alpha . &lt;ol class=list-inline&gt;&#39;A&#39; | &#39;C&#39; | &#39;A&#39; | &#39;B&#39; | &#39;A&#39; | &#39;C&#39; | &#39;C&#39; | &#39;B&#39; | &#39;B&#39; | &#39;C&#39; | &#39;C&#39; | &#39;A&#39; | &#39;A&#39; | &#39;A&#39; | &#39;B&#39; | &#39;B&#39; | &#39;B&#39; | &#39;B&#39; | &#39;C&#39; | &#39;A&#39; | &#39;C&#39; | &#39;A&#39; | &#39;A&#39; | &#39;A&#39; | &#39;A&#39; | &lt;/ol&gt; f . &lt;ol class=list-inline&gt;A | C | A | B | A | C | C | B | B | C | C | A | A | A | B | B | B | B | C | A | C | A | A | A | A | &lt;/ol&gt; &lt;summary style=display:list-item;cursor:pointer&gt; Levels: &lt;/summary&gt; &lt;ol class=list-inline&gt;&#39;A&#39; | &#39;B&#39; | &#39;C&#39; | &lt;/ol&gt; - 문자열인 alpha와 인자 벡터인 f가 같아 보이지만 다름 . - factor는 Levels이 존재하여 데이터 분류에 용이함 . - str() 함수는 데이터를 요약하여 보여줌 . z &lt;- sample(1:5, 25, replace = T) g &lt;- factor(z) str(data.frame(f = f, g = g)) . &#39;data.frame&#39;: 25 obs. of 2 variables: $ f: Factor w/ 3 levels &#34;A&#34;,&#34;B&#34;,&#34;C&#34;: 1 3 1 2 1 3 3 2 2 3 ... $ g: Factor w/ 5 levels &#34;1&#34;,&#34;2&#34;,&#34;3&#34;,&#34;4&#34;,..: 5 5 2 2 1 4 1 4 3 2 ... . - table()은 빈도표를 만듦 . - addmargins()는 빈도표의 주변 합을 테이블에 추가함 . table(f) . f A B C 11 7 7 . table(f, g) ## f와 g의 인덱스를 보고 만듦 ex) f[x] = &#39;A&#39;이고 g[x] = 3이라면 (&#39;A&#39;, 3)위치의 값을 +1하는 식으로 만듦 . g f 1 2 3 4 5 A 2 3 1 3 2 B 2 2 1 2 0 C 1 3 0 2 1 . addmargins(table(f)) . f A B C Sum 11 7 7 25 . addmargins(table(f, g)) . A table: 4 × 6 of type dbl 12345Sum . A2 | 3 | 1 | 3 | 2 | 11 | . B2 | 2 | 1 | 2 | 0 | 7 | . C1 | 3 | 0 | 2 | 1 | 7 | . Sum5 | 8 | 2 | 7 | 3 | 25 | . tapply&#50752; aggregate&#47196; &#45936;&#51060;&#53552; &#50836;&#50557; . - tapply(x, f, fun)는 x를 f의 수준 별로 쪼개서 fun을 적용함 . - 파이썬에 존재하는 gruopby 함수와 agg 함수를 생각하면 쉽다 . set.seed(2) x &lt;- round(rnorm(25, 50, 10)) data.frame(x = x, f = f) . A data.frame: 25 × 2 xf . &lt;dbl&gt;&lt;fct&gt; . 41 | A | . 52 | C | . 66 | A | . 39 | B | . 49 | A | . 51 | C | . 57 | C | . 48 | B | . 70 | B | . 49 | C | . 54 | C | . 60 | A | . 46 | A | . 40 | A | . 68 | B | . 27 | B | . 59 | B | . 50 | B | . 60 | C | . 54 | A | . 71 | C | . 38 | A | . 66 | A | . 70 | A | . 50 | A | . tapply(x, f, mean) . &lt;dl class=dl-inline&gt;A52.7272727272727B51.5714285714286C56.2857142857143&lt;/dl&gt; tapply(x, f, function(t){max(t)-min(t)}) . &lt;dl class=dl-inline&gt;A32B43C22&lt;/dl&gt; - function()은 사용자 정의 함수임 . - 한 줄일 경우 { }생략 가능 . - 쪼갬의 대상이 벡터가 아니라 데이터 프레임인 경우에는 split()과 sapply()를 함께 이용 . split(data.frame(x = x, z = z), f) . $A A data.frame: 11 × 2 xz . &lt;dbl&gt;&lt;int&gt; . 141 | 5 | . 366 | 2 | . 549 | 1 | . 1260 | 4 | . 1346 | 4 | . 1440 | 4 | . 2054 | 1 | . 2238 | 3 | . 2366 | 2 | . 2470 | 2 | . 2550 | 5 | . $B A data.frame: 7 × 2 xz . &lt;dbl&gt;&lt;int&gt; . 439 | 2 | . 848 | 4 | . 970 | 3 | . 1568 | 2 | . 1627 | 4 | . 1759 | 1 | . 1850 | 1 | . $C A data.frame: 7 × 2 xz . &lt;dbl&gt;&lt;int&gt; . 252 | 5 | . 651 | 4 | . 757 | 1 | . 1049 | 2 | . 1154 | 2 | . 1960 | 4 | . 2171 | 2 | . s &lt;- split(data.frame(x = x, z = z), f) class(s) . &#39;list&#39; sapply(s, apply, 2, mean) . A matrix: 2 × 3 of type dbl ABC . x52.72727 | 51.571429 | 56.285714 | . z 3.00000 | 2.428571 | 2.857143 | . - aggregate(x, list(f, g), fun)은 x를 f와 g의 조합으로 쪼개서 fun을 적용함 . aggregate(data.frame(x = x, z = z)$x, list(f, g), sum) . A data.frame: 13 × 3 Group.1Group.2x . &lt;fct&gt;&lt;fct&gt;&lt;dbl&gt; . A | 1 | 103 | . B | 1 | 109 | . C | 1 | 57 | . A | 2 | 202 | . B | 2 | 107 | . C | 2 | 174 | . A | 3 | 38 | . B | 3 | 70 | . A | 4 | 146 | . B | 4 | 75 | . C | 4 | 111 | . A | 5 | 91 | . C | 5 | 52 | . - tapply()는 쪼갤 기준이 하나 . - aggregate()는 쪼갤 기준이 여러개(list) . cut &#54632;&#49688; . - cut(x, breaks)는 수치형 벡터 x를 breaks로 쪼개서 factor 변수로 만듦(구간화) . - 만약 기준 변수가 factor가 아니라면 factor로 만듦 . set.seed(21) x &lt;- runif(100, 0, 10) y &lt;- 5 + 0.5*(x-5) + rnorm(100) ## x와 y는 선형관계 chr_ &lt;- c(&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;10&#39;) x_cut &lt;- cut(x, chr_) class(x_cut) . &#39;factor&#39; chr_ . &lt;ol class=list-inline&gt;&#39;0&#39; | &#39;1&#39; | &#39;2&#39; | &#39;3&#39; | &#39;4&#39; | &#39;5&#39; | &#39;6&#39; | &#39;7&#39; | &#39;8&#39; | &#39;9&#39; | &#39;10&#39; | &lt;/ol&gt; cbind(x, x_cut, y) . A matrix: 100 × 3 of type dbl xx_cuty . 7.8611493 | 8 | 5.8484239 | . 2.5244560 | 3 | 5.5363467 | . 6.9925230 | 7 | 5.7855895 | . 1.8446075 | 2 | 3.0701969 | . 9.5961383 | 10 | 7.8832415 | . 9.1868340 | 10 | 8.1071017 | . 1.0180455 | 2 | 2.9864533 | . 1.7219168 | 2 | 2.4578035 | . 9.8600368 | 10 | 8.3377913 | . 8.4939610 | 9 | 7.9089234 | . 6.6754012 | 7 | 5.3797472 | . 9.3521022 | 10 | 8.1040078 | . 0.5818433 | 1 | 0.6879865 | . 6.1861583 | 7 | 3.9159120 | . 1.7491846 | 2 | 5.1402481 | . 0.3767539 | 1 | 3.4828244 | . 5.2531317 | 6 | 4.6426963 | . 2.8218425 | 3 | 5.8392804 | . 4.9904520 | 5 | 4.6111098 | . 6.3382510 | 7 | 4.0824480 | . 0.1139965 | 1 | 2.7712999 | . 6.0785656 | 7 | 4.4010011 | . 7.7559853 | 8 | 6.8674062 | . 9.2397118 | 10 | 5.3672191 | . 2.9170673 | 3 | 4.4595508 | . 7.8907624 | 8 | 6.5321374 | . 5.6849721 | 6 | 5.5335596 | . 7.7843508 | 8 | 7.2240144 | . 7.1323253 | 8 | 5.3871303 | . 6.6904867 | 7 | 6.1411056 | . ⋮ | ⋮ | ⋮ | . 5.2419521 | 6 | 4.802874 | . 5.3472914 | 6 | 4.589883 | . 9.6766790 | 10 | 7.405624 | . 5.2833101 | 6 | 5.497121 | . 5.3193106 | 6 | 5.138644 | . 6.2043358 | 7 | 6.850795 | . 9.2198573 | 10 | 6.225241 | . 2.2786153 | 3 | 2.754301 | . 9.2766458 | 10 | 6.687593 | . 9.2997805 | 10 | 8.441203 | . 5.2228023 | 6 | 5.490241 | . 9.9086911 | 10 | 8.955029 | . 0.6460298 | 1 | 2.554238 | . 8.6259344 | 9 | 8.088017 | . 4.8062732 | 5 | 5.224632 | . 5.3615727 | 6 | 6.835729 | . 4.1513448 | 5 | 3.384017 | . 2.2846328 | 3 | 3.595330 | . 9.8195084 | 10 | 5.809714 | . 6.5597644 | 7 | 4.664516 | . 5.8016786 | 6 | 6.295498 | . 1.4083867 | 2 | 2.498659 | . 6.9767447 | 7 | 5.034914 | . 7.4802064 | 8 | 7.236793 | . 9.5334043 | 10 | 6.601671 | . 1.3104292 | 2 | 1.524249 | . 6.4997197 | 7 | 6.496078 | . 7.0777577 | 8 | 5.070752 | . 0.9994111 | 1 | 2.695506 | . 0.6916488 | 1 | 3.510434 | . . - $(x, y)$의 산점도에 $x$의 구간별 평균을 막대로 넣어 구간별 평균의 이동을 산출해보자 . y_local &lt;- aggregate(y, list(x_cut), mean) ## x_cut은 1~10까지 존재 &gt; 1부터 10까지 x_cut별로 따로 모아 그에 해당하는 y 데이터의 평균을 구함 y_local . A data.frame: 10 × 2 Group.1x . &lt;fct&gt;&lt;dbl&gt; . (0,1] | 2.597557 | . (1,2] | 3.252382 | . (2,3] | 4.148030 | . (3,4] | 2.849470 | . (4,5] | 4.448115 | . (5,6] | 5.436146 | . (6,7] | 5.198160 | . (7,8] | 6.197139 | . (8,9] | 6.638144 | . (9,10] | 7.384560 | . plot(x, y, ylim = c(0, 10), main = &quot;x vs y&quot; ) segments(0:9, y_local$x, 1:10, y_local$x, lwd = 2) ## segments 함수는 x좌표와 y좌표를 입력받아 line을 그려줌 abline(v = 1:9, lty = &quot;dotted&quot;) ## abline 함수는 line을 그려줌, v는 수직선의 위치 . - 참고: abline 함수 . - 참고: segments 함수 . &#51077;&#52636;&#47141;(input and output) . - read.table read.csv(&#39;파일 위치&#39;) &gt; 텍스트 파일 or csv 파일을 읽어 내부 저장소에 dataframe으로 만듦 . - getwd() &gt; 현재의 작업 디렉토리를 알려줌 . - setwd(&#39;위치&#39;) &gt; 작업 디렉토리를 입력한 위치로 변경 . - dir() &gt; 현재 작업 디렉토리에 있는 파일들의 리스트를 보여줌 . - write.table write.csv()은 특정 데이터 프레임을 작업 디렉토리에 텍스트 파일 or csv 파일로 입력함 . - 파일을 읽을 때 stringAdFactors = F 옵션을 적용하면 문자열 변수가 자동으로 factor 형이 되는 것을 막아줌 . - sink()함수를 통해 결과값을 텍스트 파일로 저장할 수 있음 &gt; sink function . scan &#54632;&#49688; . - scan() &gt; 비정형의 문자열 데이터를 읽을 때 유용 . - what 은 읽어 들일 데이터 값 형식 numeric, logical, character . - 책 따라 하는데 scan함수가 제대로 작동되지 않아 찾아보니 quote = &quot;&quot; 로 하지 않아서라고 함 &gt; 참고: https://pythonq.com/so/r/29317 . - quote = &quot;&quot; 옵션을 적용하지 않으면 Read 1 item을 반환 &gt; 빈칸을 기준으로 문자열을 쪼개지 않았다는 뜻 &gt; 그런데 sep = &quot; n&quot; 으로 하면 Read 20 item임 . - 원인을 알았는데 내가 yesterday노래 가사 텍스트 파일을 만들 때 맨 앞에 &quot; 기호를 실수로 추가했었음 &gt; &quot; 기호를 없애니 잘 동작함 . lyrics &lt;- scan(&quot;yesterday.txt&quot;, what = &quot;character&quot;) ## quote = &quot;&quot; 옵션을 적용 안해도 잘 동작함 . str(lyrics) . chr [1:126] &#34;Yesterday,&#34; &#34;all&#34; &#34;my&#34; &#34;troubles&#34; &#34;seemed&#34; &#34;so&#34; &#34;far&#34; &#34;away.&#34; ... . head(lyrics, 10) . &lt;ol class=list-inline&gt;&#39;Yesterday,&#39; | &#39;all&#39; | &#39;my&#39; | &#39;troubles&#39; | &#39;seemed&#39; | &#39;so&#39; | &#39;far&#39; | &#39;away.&#39; | &#39;Now&#39; | &#39;it&#39; | &lt;/ol&gt; - 빈칸을 구분자로 인식하여 문자열을 쪼개어 읽어옴 + 줄 단위로 읽고 싶다면 sep = &quot; n&quot; . lyrics_2 &lt;- scan(&quot;yesterday.txt&quot;, what = &quot;character&quot;, sep = &quot; n&quot;) . str(lyrics_2) . chr [1:20] &#34;Yesterday, all my troubles seemed so far away.&#34; ... . head(lyrics_2, 5) . &lt;ol class=list-inline&gt;&#39;Yesterday, all my troubles seemed so far away.&#39; | &#39;Now it looks as though they &#39;re here to stay.&#39; | &#39;oh, I believe in yesterday.&#39; | &#39;Suddenly, I &#39;m not half the man I used to be.&#39; | &#39;There &#39;s a shadow hanging over me.&#39; | &lt;/ol&gt; cat &#54632;&#49688; . - print함수와 비슷하나 여러개의 출력이 가능하고 출력이 공백 없이 이어짐 . print(&quot;a&quot;) print(&quot;b&quot;) . [1] &#34;a&#34; [1] &#34;b&#34; . cat(&quot;a&quot;) cat(&quot;b&quot;) . ab . &#47928;&#51088;&#50676; &#51089;&#50629; . grep &#54632;&#49688; . - grep(pattern, x)는 x에서 pattern이 있는 곳을 알려줌 . grep(&quot;Yesterday&quot;, lyrics) . &lt;ol class=list-inline&gt;1 | 63 | 105 | &lt;/ol&gt; grep(&quot;yesterday&quot;, lyrics) . &lt;ol class=list-inline&gt;22 | 40 | 62 | 84 | 104 | 126 | &lt;/ol&gt; - &quot;Yesterday&quot;는 1 ,63 ,105번째 요소에 있고 &quot;yesterday&quot;는 22, 40 ,62, 84, 104, 126번째 요소에 있음을 알려줌 . - 이번에는 &quot;?&quot;를 찾아보자 . - grep(&quot;?&quot;, lyrics)를 하면 될 것 같지만 아님 . grep(&quot;?&quot;, lyrics) . &lt;ol class=list-inline&gt;1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 | 14 | 15 | 16 | 17 | 18 | 19 | 20 | 21 | 22 | 23 | 24 | 25 | 26 | 27 | 28 | 29 | 30 | 31 | 32 | 33 | 34 | 35 | 36 | 37 | 38 | 39 | 40 | 41 | 42 | 43 | 44 | 45 | 46 | 47 | 48 | 49 | 50 | 51 | 52 | 53 | 54 | 55 | 56 | 57 | 58 | 59 | 60 | 61 | 62 | 63 | 64 | 65 | 66 | 67 | 68 | 69 | 70 | 71 | 72 | 73 | 74 | 75 | 76 | 77 | 78 | 79 | 80 | 81 | 82 | 83 | 84 | 85 | 86 | 87 | 88 | 89 | 90 | 91 | 92 | 93 | 94 | 95 | 96 | 97 | 98 | 99 | 100 | 101 | 102 | 103 | 104 | 105 | 106 | 107 | 108 | 109 | 110 | 111 | 112 | 113 | 114 | 115 | 116 | 117 | 118 | 119 | 120 | 121 | 122 | 123 | 124 | 125 | 126 | &lt;/ol&gt; . - &quot;?&quot;는 정규표현식 기호로 사용되게 원래의 물음표 기호를 사용하고자 하면 &quot; &quot;을 앞에 넣어줘야함 &gt; 나중에 정규표현식 공부하자 . grep(&quot; ?&quot;, lyrics) . &lt;ol class=list-inline&gt;47 | 89 | &lt;/ol&gt; nchar &#54632;&#49688; . - nchar(x)는 문자열 x의 길이를 알려줌(빈칸 포함) . nchar(&quot;yesterday&quot;) . 9 - 참고 : length(x)의 결과는 아래와 같음 . length(&quot;yesterday&quot;) . 1 - 문자열 벡터에도 적용 가능함 . nchar(lyrics) . &lt;ol class=list-inline&gt;10 | 3 | 2 | 8 | 6 | 2 | 3 | 5 | 3 | 2 | 5 | 2 | 6 | 7 | 4 | 2 | 5 | 3 | 1 | 7 | 2 | 10 | 9 | 3 | 3 | 4 | 3 | 3 | 1 | 4 | 2 | 3 | 7 | 1 | 6 | 7 | 4 | 3 | 3 | 9 | 4 | 9 | 3 | 3 | 3 | 2 | 3 | 1 | 5 | 5 | 3 | 8 | 4 | 1 | 4 | 9 | 6 | 3 | 1 | 4 | 3 | 10 | 9 | 4 | 3 | 4 | 2 | 4 | 4 | 2 | 5 | 3 | 1 | 4 | 1 | 5 | 2 | 4 | 5 | 3 | 1 | 7 | 2 | 10 | 3 | 3 | 3 | 2 | 3 | 1 | 5 | 5 | 3 | 8 | 4 | 1 | 4 | 9 | 6 | 3 | 1 | 4 | 3 | 10 | 9 | 4 | 3 | 4 | 2 | 4 | 4 | 2 | 5 | 3 | 1 | 4 | 1 | 5 | 2 | 4 | 5 | 3 | 1 | 7 | 2 | 12 | &lt;/ol&gt; paste &#54632;&#49688; . - 다수의 문자열을 붙여 하나의 문자열을 만듦 . - 파이썬의 join 함수를 생각하면 된다 . paste(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) . &#39;a b c&#39; paste(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, sep = &quot;-&quot;) . &#39;a-b-c&#39; - paste 함수는 디폴트로 빈칸 하나를 기준으로 문자열을 붙인다 . - paste0 함수를 사용하면 빈칸 없음을 기준으로 문자열을 붙일 수 있다 . paste0(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) . &#39;abc&#39; substr &#54632;&#49688; . - substr(x, start, stop)은 x에서 start부터 stop까지의 문자열을 뽑아낸다 . substr(&quot;abcdefg&quot;, 2, 4) . &#39;bcd&#39; strsplit &#54632;&#49688; . - strsplit(x, split)은 x를 split을 기준으로 분리한다 . - 파이썬의 split 함수를 생각하면 쉽다 . strsplit(&quot;a-b-c-d-e&quot;, &quot;-&quot;) . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; | class(strsplit(&quot;a-b-c-d-e&quot;, &quot;-&quot;)) ## 쪼갠 문자열들의 타입은 list이다 . &#39;list&#39; unlist(strsplit(&quot;a-b-c-d-e&quot;, &quot;-&quot;)) . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; strsplit(c(&quot;a-b-c-d-e&quot;, &quot;qq-bb&quot;), &quot;-&quot;) ## 문자열 벡터도 가능 . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; | &lt;ol class=list-inline&gt;&#39;qq&#39; | &#39;bb&#39; | &lt;/ol&gt; | gregexpr &#54632;&#49688;(global regular expression) . - gregexpr(pattern, x)은 x에서 pattern이 발견되는 모든 위치를 알려준다 . - 파이썬의 index 함수를 생각하면 쉽다 . unlist(gregexpr(&quot;-&quot;, &quot;2021-12-22&quot;)) . &lt;ol class=list-inline&gt;5 | 8 | &lt;/ol&gt; - grep 함수와의 차이점은 아래와 같음 . unlist(grep(&quot;-&quot;, &quot;2021-12-22&quot;)) . 1 - grep 함수에서는 &quot;2021-12-22&quot;를 하나 취급한다 . - 마치 length(&quot;2021-12-22&quot;)는 $1$인것처럼 . - 포함여부만 확인 가능하고 문자열의 어느 위치에 존재하는지는 확인 불가능함 . unlist(gregexpr(&quot;-&quot;, c(&quot;2021-12-22&quot;, &quot;12-22&quot;))) ## 첫 번째 문자열에선 5, 8위치에 &quot;-&quot;이 존재하고 ## 두 번째 문자열에선 3 위치에 &quot;-&quot; 존재한다 . &lt;ol class=list-inline&gt;5 | 8 | 3 | &lt;/ol&gt; unlist(grep(&quot;-&quot;, c(&quot;2021-12-22&quot;, &quot;12-22&quot;))) ## 첫 번째 문자열에 &quot;-&quot;이 존재하고 ## 두 번째 문자열에 &quot;-&quot;이 존재한다 ## 문자열 어느 위치에 &quot;-&quot;이 존재하는지는 알 수 없다 . &lt;ol class=list-inline&gt;1 | 2 | &lt;/ol&gt; - regexpr 함수(regular expression)도 있는데 이 함수는 처음 위치만 알려준다 . unlist(regexpr(&quot;-&quot;, &quot;2021-12-22&quot;)) ## 8번째 인덱스에도 &quot;-&quot;이 존재하지만 처음 &quot;-&quot;이 등장한 위치만 알려준다 . 5 gsub &#54632;&#49688; (global substitude) . - gsub(pattern, replace, x)은 x에 있는 pattern을 replace로 바꾼다 . - 파이썬의 replace 함수를 떠올리면 쉽다 . gsub(&quot;-&quot;, &quot;.&quot;, &quot;2021-12-22&quot;) . &#39;2021.12.22&#39;",
            "url": "https://jaesu26.github.io/green/r/2021/08/20/R%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "relUrl": "/r/2021/08/20/R%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "date": " • Aug 20, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "파이썬 scipy.stats",
            "content": "- 확률분포를 scipy.stats를 통해 그리는데 익숙하지 않아 기본 사용에 대해 알아볼 거임 . - 참고: scipy.stats . - 참고: scipy 확률분포 . &#54869;&#47456;&#48516;&#54252; &#53364;&#47000;&#49828; . - scipy.stats를 통해 확률분포를 그려보자 . - 우선 확률분포에 대한 클래스 객체를 생성해야 함 . - 각 확률분포의 파라미터는 scipy.stats.이름을 통해 확인하자 . 종류 이름 확률분포 . 이산 | bernoulli | 베르누이 분포 | . 이산 | binom | 이항 분포 | . 이산 | poisson | 포아송 분포 | . 이산 | geom | 기하 분포 | . 이산 | nbinom | 음이항 분포 | . 이산 | hypergeom | 초기하 분포 | . 이산 | multinomial | 다항 분포 | . 연속 | norm | 정규 분포 | . 연속 | uniform | 균일 분포 | . 연속 | expon | 지수 분포 | . 연속 | gamma | 감마 분포 | . 연속 | t | t 분포 | . 연속 | chi2 | 카이제곱 분포 | . 연속 | f | f 분포 | . 연속 | beta | 베타 분포 | . &#47784;&#49688; &#51648;&#51221; . - 확률분포의 모수는 종류별로 다르므로 문서를 참고하자 . - 하지만 대부분 확률분포가 공통적으로 가지는 모수가 있음 . 모수 이름 의미 . loc | 기댓값 | . scale | 표준편차 | . &#54869;&#47456;&#48516;&#54252; methods . - 확률분포 클래스 객체가 가지는 method가 있음 . - 정규분포를 예로 들어 ppf에 대한 설명을 해보면 norm.ppf(0.5)는 정규분포에서 $50$분위수에 해당하는 $x$값으로 $0$이다 . 메서드 기능 . pmf | 확률질량함수 | . pdf | 확률밀도함수 | . cdf | 누적분포함수 | . ppf | 누적분포함수의 역함수(백분위 함수) | . sf | 생존함수 = 1 $-$ 누적분포함수 | . isf | 생존함수의 역함수 | . rvs | 무작위 표본 생성 | . &#54869;&#47456;&#48516;&#54252; plot . &#51221;&#44508; &#48516;&#54252; pdf . - 정규 분포 pdf를 그려보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm xx = np.linspace(-5, 5, 1000) for scale in (0.5, 1.0, 2.0): plt.plot(xx, norm(0, scale).pdf(xx), label = &#39;μ = 0, σ = &#39; + str(scale), lw = 2, alpha = 0.8) plt.plot(xx, norm(-2, 0.5).pdf(xx), label = &#39;μ = -2, σ = 0.5&#39;, lw = 2, alpha = 0.8) plt.xticks(np.arange(-5, 6)) plt.yticks(np.arange(0.0, 1.2, 0.2)) plt.title(&quot;normal distribution pdf&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() . &#51221;&#44508; &#48516;&#54252; cdf . - 정규 분포 cdf를 그려보자 . - cdf에 대한 내용 정리 예정 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm xx = np.linspace(-5, 5, 1000) for scale in (0.5, 1.0, 2.0): plt.plot(xx, norm(0, scale).cdf(xx), label = &#39;μ = 0, σ = &#39; + str(scale), lw = 2, alpha = 0.8) plt.plot(xx, norm(-2, 0.5).cdf(xx), label = &#39;μ = -2, σ = 0.5&#39;, lw = 2, alpha = 0.8) plt.xticks(np.arange(-5, 6)) plt.yticks(np.arange(0.0, 1.2, 0.2)) plt.title(&quot;normal distribution cdf&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() .",
            "url": "https://jaesu26.github.io/green/python/statistics/2021/08/10/scipy-stats.html",
            "relUrl": "/python/statistics/2021/08/10/scipy-stats.html",
            "date": " • Aug 10, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "가설검정",
            "content": "- 대표적인 확률분포에 대한 간단한 정리를 마친 후 작성할 예정임 &gt; 시작 . - 참고: Statistics: Unlocking the power of data, Robin Lock 외 4인 . &#51473;&#49900;&#44537;&#54620;&#51221;&#47532;(central limit theorem) . - 동일한 확률분포를 가진 독립확률변수 $n$개의 평균의 분포는 충분히 크다면($n geq 30$이면) 정규분포에 가까워짐 . - 앞으로 많은 가설검정에서 사용될 예정 . - 증명 링크 : https://en.wikipedia.org/wiki/Central_limit_theorem#Proof_of_classical_CLT . &#48531;&#49828;&#53944;&#47017;&#44284; p-&#44050; . - 뒤에서 설명할 내용들에 붓스트랩과 p-값의 개념이 쓰여서 알고가자 . - 이를 위해 간단한 예시를 들어보자 . - 전북대학교 학생들의 평균 맥박수가 모종의 이유로 궁금하다고 해보자(표본조사론 프로젝트? ㅋㅋ) . - 제일 먼저 떠오르는 생각은 전북대학교 학생들을 전부 불러모아 맥박을 측정하고 이를 평균내는 것이다 . - 확실한 방법이지만 일일이 맥박을 어느 세월에 측정할 것인가... . - 그래서 생각한 방법이 모든 학생의 맥박을 측정하는 대신에 일부 학생들의 맥박만 측정하여 평균을 내는 것이다 . - ??? : 일부 학생들의 맥박 평균과 전체 학생들의 맥박 평균이 같은지 어떻게 확신함?? . - 국이나 찌개등의 간을 볼 때 조금만 먹어보고 짠지 싱거운지 판단하는데 이는 음식에 간이 골고루 배도록 잘 섞어주었기 때문이다 . - 만약 간이 골고루 배어있지 않으면 위의 판단은 틀릴 수 있다 . - 마찬가지로 학생들을 골고루 잘 선택한다면(?) 일부 학생들의 맥박을 가지고 전체 학생들을 대표할 수 있을 것이다 . - 골고루 잘 선택하는 방법에는 학생들에게 1번부터 차례차례 번호를 부여하고 시스템을 통해 50개의 번호를 뽑는 것이 있다 . import numpy as np import matplotlib import matplotlib.pyplot as plt matplotlib.rcParams[&#39;font.family&#39;] = &#39;Malgun Gothic&#39; # 한글이 깨지지 않도록 설정 matplotlib.rcParams[&#39;axes.unicode_minus&#39;] = False # 한글이 깨지지 않도록 설정 np.random.seed(42) blood_pressure = np.random.normal(85, 15, 10000) ## 모집단 plt.hist(blood_pressure, bins=np.arange(int(np.min(blood_pressure)), int(np.max(blood_pressure)) + 1, 2)) plt.title(&#39;전북대학교 학생들의 맥박수 분포&#39;, fontsize=15) plt.show() . . - 전체 전북대학교 학생들의 맥박(모집단)을 일일이 측정하기 힘드니 임의의로 50명의 학생만 뽑아 맥박을 측정하고 평균을 내자 . - 모집단은 평균이 85, 표준편차가 15인 정규분포를 따른다고 가정하자 . sample = np.random.choice(blood_pressure, size=50, replace=False) print(f&#39;50명의 평균 맥박수는 {np.round(np.mean(sample), 1)}입니다&#39;) . 50명의 평균 맥박수는 85.9입니다 . - 50명을 무작위로 뽑아 맥박을 재고 이를 평균내보니 85.9가 나왔다 . - 그러면 이제 전북대학교 전체 학생들의 평균 맥박수가 85.9라고 할 수 있을까? . - 안타깝게도 그럴 수 없는데 무작위로 50명을 다시 뽑으면 당연하게도 다른 결과가 나오기 때문이다 . sample = np.random.choice(blood_pressure, size=50, replace=False) print(f&#39;50명의 평균 맥박수는 {np.round(np.mean(sample), 1)}입니다&#39;) . 50명의 평균 맥박수는 83.9입니다 . - 이번에는 평균이 83.9이다 . - 위의 결과로부터 2가지 문제점이 생겼다 . - 첫 번째는 평균 맥박수를 85.9로 해야될지 83.9로 해야될지 모르겠다는 것이고 . - 두 번째는 매번 50명씩 학생들의 맥박을 재는것도 쉬운일은 아니라는 것이다 . - 일단 첫 번째 문제는 전체 전북대학교 학생들의 평균 맥박수(모평균=모집단의 평균)를 점추정이 아닌 구간추정을 하면 된다 . - 즉, 모평균을 85.9, 83.9와 같이 하나의 값으로 나타내지 말고 정확히 몇인지는 모르지만 아마도 83에서 87사이인 것 같다와 같은 방식으로 나타내는 것이다 . - 그러면 구간은 어떻게 정할 것인지? &gt; 50명씩 학생들을 무작위로 뽑아 맥박을 재고 이를 평균낸다 &gt; 이를 엄청 많이 반복하자 &gt; 표본평균의 분포(표집분포) . - 그리고 최소값과 최대값을 기준으로 삼자! . - 1000번 정도 반복해보자 . np.random.seed(42) samples = [np.mean(np.random.choice(blood_pressure, size=50, replace=False)) for i in range(1000)] plt.hist(samples, bins=np.arange(int(np.min(samples)), int(np.max(samples)) + 0.5, 1)) plt.title(&#39;50명의 맥박수 평균의 분포&#39;, fontsize=15) plt.show() . . print(f&#39;구간의 최소값은 {np.round(np.min(samples), 1)}이고 최대값은 {np.round(np.max(samples), 1)}입니다&#39;) . 구간의 최소값은 78.6이고 최대값은 92.3입니다 . - 아마도 전북대학교 학생들의 평균 맥박수는 78.6에서 92.3사이인 것 같다 . - 그런데 사실 구간의 경계를 최소값과 최대값으로 할 필요는 없다 . - 예컨대 83과 87사이로 해도 된다 . - 구간의 폭이 좁으면 정확도는 떨어지지만 그만큼 쓸모가 있고 구간의 넓으면 정확도는 높아지지만 쓸모가 없다 . - 평균 맥박수가 0에서 200사이라고 한다면 정확하지만 쓸모가 없다... . - 한편, 정규분포인 경우 중심(평균)에서 표준편차의 2배 거리안에 95%의 데이터가 존재한다 . - 중심극한정리에 의해 표본크기가 30보다 큰 50이므로 표본평균의 분포(표집분포)는 정규분포를 따른다 . - 구간을 정한다는 것은 위에서 언급한 &quot;아마도(= 믿음의 크기)&quot;를 정한다는 것과 다름이 없다(구간이 넓으면 믿음의 크기가 커지고 좁으면 반대니까) . - 구간을 표집분포의 평균에서 표집분포의 표준편차(표준오차)의 2배 거리 내부로 정하면 어떨까?(95%의 데이터가 존재) . - 위에서 구한 1000개의 표본평균 중에서 95%나 구간안에 속한다!(정확도 높고 쓸모 있음) . - 그리고 이러한 구간을 신뢰구간이라고 표현한다 . - 여기서는 95% 신뢰구간! . samples_mean = np.mean(samples) samples_std = np.std(samples, ddof=1) print(f&#39;표집분포의 평균은 {np.round(samples_mean, 1)}이고 표준오차는 {np.round(samples_std, 1)}입니다&#39;) . 표집분포의 평균은 85.0이고 표준오차는 2.1입니다 . - 95% 신뢰구간은 표집분포의 평균에서 표준오차의 2배 거리 내부이므로 다음과 같다 . print(f&#39;전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 ({np.round(samples_mean - 2*samples_std, 1)}, {np.round(samples_mean + 2*samples_std, 1)}) 입니다&#39;) . 전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 (80.9, 89.2) 입니다 . - 전북대학교 학생들의 평균 맥박수의 95% 신뢰구간을 구했다! . - 누군가가 전북대학교 학생들의 평균 맥박수에 몇인지 물어본다면 답변할 수 있다! . - 전북대학교 학생들의 평균 맥박수가 몇이죠?? &gt; 정확히는 모르지만 80.9에서 89.2사이에 존재함을 95% 신뢰합니다! . - 신뢰한다는 표현이 현재로는 애매하게 느껴지지만 일단은 넘어가자 . - 드디어 전북대학교 학생들의 평균 맥박수가 어느정도인지 말할 수 있게 되었다 . - 그런데 심각한 문제점이 하나 있다 . - 위에서 말한 두 번째 문제점이다 . - 두 번째 문제점 : 매번 50명씩 학생들의 맥박을 재는것도 쉬운일은 아니다 . - 위에서 신뢰구간을 구하기 위해 50명의 맥박수를 재는 일을 1000번이나 반복했다 . - 총 50000명의 맥박수를 측정함... . - 우리가 처음에 전북대학교 학생들의 평균 맥박수를 구하기 위해 접근한 방식을 사용하면 . - 50000명씩 맥박수를 재지 않고 50명의 맥박수만 재는 것으로 신뢰구간을 구할 수 있다 . - 처음 접근한 방식 : 학생들을 골고루 잘 선택한다면(?) 일부 학생들의 맥박을 가지고 전체 학생들을 대표할 수 있을 것이다 . - 우리는 무작위로 50명의 학생들을 골랐다 &gt; 정말 무작위로 학생들을 골랐다면 이들이 전체를 대표할 수 있을것이다 . - 다르게 생각해보면 전체 학생들은 무작위로 고른 50명의 학생들을 복제한 것으로 판단할 수 있다! . - 즉 50명의 학생들을 무작위로 뽑고 이후부터는 50명의 학생들을 복원추출하면 된다 . - 그러면 50000명씩 맥박수를 재지 않고 단지 50명의 맥박수만 재는 것으로 위에서 구한 95% 신뢰구간을 계산할 수 있다 . np.random.seed(42) random_sample = np.random.choice(blood_pressure, size=50, replace=False) ## 학생 50명을 무작위로 뽑는다 bootstrap = [np.mean(np.random.choice(random_sample, size=50, replace=True)) for i in range(1000)] ## 무작위로 뽑은 50명의 학생들을 50명씩 복원추출한다(1000번 반복하자) plt.hist(bootstrap, bins=np.arange(int(np.min(bootstrap)), int(np.max(bootstrap)) + 0.5, 1)) plt.title(&#39;50명의 맥박수 평균의 붓스트랩 분포&#39;, fontsize=15) plt.show() . . - 95% 신뢰구간은 표집분포에서 구한것과 같은 방법으로 구한다 . - 붓스트랩 분포의 평균과 표준편차를 알면 구할 수 있음 . bootstrap_mean = np.mean(bootstrap) bootstrap_std = np.std(bootstrap, ddof=1) print(f&#39;붓스트랩 분포의 평균은 {np.round(bootstrap_mean, 1)}이고 표준오차는 {np.round(bootstrap_std, 1)}입니다&#39;) . 붓스트랩 분포의 평균은 87.1이고 표준오차는 2.1입니다 . print(f&#39;붓스트랩을 사용하여 계산한 전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 ({np.round(bootstrap_mean - 2*bootstrap_std, 1)}, {np.round(bootstrap_mean + 2*bootstrap_std, 1)}) 입니다&#39;) . 붓스트랩을 사용하여 계산한 전북대학교 학생들의 평균 맥박수에 대한 95% 신뢰구간은 (83.0, 91.2) 입니다 . - 위의 붓스트랩에 기반한 95% 신뢰구간은 모평균($ mu=85$)를 포함한다 . - 표본평균의 분포를 사용했을 때와 표본평균의 붓스트랩 분포를 사용했을 때의 결과를 비교하면 한가지 차이점이 존재한다 . - 분포의 중심(평균)이 다르다 . - 그런데 표준편차는 동일하다 . - 표본평균의 분포의 중심은 모평균에 수렴하지만 표본평균의 붓스트랩 분포의 중심은 표본평균(50명 학생들의 맥박수 평균)에 수렴한다 . - 붓스트랩은 처음에 뽑은 50명 표본 하나를 가지고 확장하여 사용하기 때문에 중심은 모평균이 아닌 50명 학생들의 맥박수에 수렴할 수 밖에 없다 . - 만약 처음에 뽑은 50명이 운이 없게도 전부 극단값에 치우쳐져 있다면 이를 가지고 만든 신뢰구간은 모평균을 포함하지 못할 것이다 . - 하지만 처음에 뽑은 50명이 극단값에 치우쳐져 있는지 아니면 중심 부근에 위치한지 어떻게 알 수 있지?? . - 추가 중 . - 표본평균의 분포의 표준편차는 모평균의 변동성을 설명하는 것 . &#54217;&#44512;&#50640; &#45824;&#54620; &#52628;&#47200; . - 양적 자료에서 관심 있는 모수는 종종 모집단 평균 $ mu$이다 . - ex) 우리나라 사람들의 평균 맥박수가 어느정도 되는지 궁금함 &gt; 평균에 대한 가설검증 . &#54364;&#48376; &#54217;&#44512;&#50640; &#45824;&#54620; &#51473;&#49900;&#44537;&#54620;&#51221;&#47532; . - 평균이 $ mu$이고 표준편차가 $ alpha$인 모집단에서 표본 크기 $n$이 충분히 클 때 표본 평균의 분포는 근사적으로 평균이 $ mu$이고 표준편차는 $ cfrac{ alpha}{ sqrt{n}}$인 정규분포를 따름 . - 하지만 위의 내용을 그대로 사용할 수 없음 . 1. 모집단의 표준편차 $ alpha$를 모른다 &gt; 표본의 표준편차 $s$를 $ alpha$대신 사용 . 2. 추정된 표준오차 $ cfrac{s}{ sqrt{n}}$에 기반하여 표준화한 통계량의 분포는 표준정규분포를 따르지 않음 &gt; t 분포를 따름(t 분포 참고) . &#54364;&#48376;&#51032; &#54364;&#51456;&#54200;&#52264;&#47484; &#49324;&#50857;&#54624; &#46412; &#54364;&#48376; &#54217;&#44512;&#51032; &#48516;&#54252; . - 평균이 $ mu$인 모집단에서 표본 크기 $n$인 무작위 표본을 뽑을 때 표본 평균의 분포는 중심이 $ mu$이고 표준오차는 $ cfrac{s}{ sqrt{n}}$으로 추정 . - 표본 평균을 표준화하면 자유도 $n-1$인 t 분포를 근사적으로 따름 . - 표본 크기 $n$이 커질수록 t분포는 표준정규분포와 가까워짐 . import numpy as np import scipy as sp import scipy.stats import matplotlib.pyplot as plt x = np.linspace(-5, 5, 100) rv_norm = sp.stats.norm(loc=0, scale=1) rv_t10 = sp.stats.t(df=10) rv_t5 = sp.stats.t(df=5) rv_t1 = sp.stats.t(df=1) norm_pdf = rv_norm.pdf(x) t10_pdf = rv_t10.pdf(x) t5_pdf = rv_t5.pdf(x) t1_pdf = rv_t1.pdf(x) legend = [&#39;z-dist&#39;, &#39;t(df=1)&#39;, &#39;t(df=5)&#39;, &#39;t(df=10)&#39;] plt.figure(figsize = (10, 6)) plt.plot(x, norm_pdf) plt.plot(x, t1_pdf) plt.plot(x, t5_pdf) plt.plot(x, t10_pdf) plt.title(&quot;z-dist, t-dist(df=1, 5, 10)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$p(x)$&quot;) plt.grid() plt.legend(legend) plt.show() . . - 위의 plot을 보면 자유도가 커질수록 t분포가 표준정규분포에 가까워짐을 알 수 있음 . - 나중에 plot그리는데 사용되는 lib와 사용법 추가 예정 . t &#48516;&#54252; &#49324;&#50857; &#51312;&#44148; . - 표본 크기 $n geq 30$이면 문제 없음 . - 만약 표본 크기 $n$이 작다면? &gt; 모집단이 정규분포를 따라야 함 . - 근데 모집단이 정규분포 따르는지 모른다 &gt; 대신에 표본이 정규분포를 따르는지 확인하자 &gt; shapiro.test 실시 . - 표본에 이상점이 있거나 비대칭이면 t 분포 사용$ times$ . - 표본이 정규분포를 따르는 것 같다 &gt; $ bar{x}$의 분포는 정규분포를 따른다 &gt; t-test 실시해도 괜찮다 . &#54217;&#44512;&#50640; &#45824;&#54620; t&#44160;&#51221; . - 영가설 $H_0: mu= mu_0$를 검정하는 t-통계량은 다음과 같음 . - $t= cfrac{ bar{x}- mu_0}{ frac{s}{ sqrt{n}}}$ . - $ bar{x}$는 표본 평균, $s$는 표본에서 계산한 표준편차 . - p-값을 통해 영가설을 기각할지 기각하지 못하는지를 결정 &gt; 가설검정 용어(영가설, p-값 등등)에 대해 나중에 정리 예정 . - 검증의 p-값은 자유도가 $n-1$인 t분포에서 대안가설에 적절한 꼬리쪽의 비율을 계산 . &#54217;&#44512;&#50640; &#45824;&#54620; t&#44160;&#51221; &#50696;&#51228; . 문제 | . - 사람의 평균 체온이 $36.5^{°} mathrm{C}$인지 검정하기 위해 건강한 사람 50명의 체온을 재었다 . - 임의로 데이터를 설정하여 평균 체온 데이터는 평균이 36.3, 표준편차는 0.5인 정규분포에서 추출했음 . - 임의로 뽑은 표본을 살펴보니 $ bar{x} = 36.35, ;s=0.5$이다 . - 위의 데이터는 사람의 평균 체온이 $36.5^{°} mathrm{C}$와는 다르다는 증거인지 유의수준 $ alpha=0.05$ 에서 검정하자 . 해결 과정 | . - $H_0: mu=36.5, ;H_a: mu neq36.5$ . - 표본 크기가 충분하고 표본에 대한 히스토그램을 보면 정규분포를 따르는 것으로 보인다 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . The rpy2.ipython extension is already loaded. To reload it, use: %reload_ext rpy2.ipython . import matplotlib.pyplot as plt import numpy as np ## 예시 샘플 np.random.seed(2021) sample = np.random.normal(loc = 36.3, scale = 0.5, size = 50) plt.hist(sample) plt.title(&#39;body heat data&#39;) plt.show() %R -i sample . - 샤피로 윌크 검정을 통해 정규성을 정확히 확인하자 . %%R shapiro.test(sample) . Shapiro-Wilk normality test data: sample W = 0.98456, p-value = 0.7524 . - p-값이 크므로 영가설(표본은 정규분포를 따름)을 기각할 수 없으므로 표본의 정규성을 가정 . - t통계량을 직접 구해도 됨 &gt; $t= cfrac{ bar{x}- mu_0}{ frac{s}{ sqrt{n}}} = cfrac{36.35-36.5}{ frac{0.5}{ sqrt{50}}}=-2.12$ . - 하지만 매번 직접 구하기 귀찮으므로 R을 통해 구해보도록 하자 + p-값도 구해줌 . - 사실 파이썬으로도 가능하지만 내가 모르는 관계로 R로 하고 나중에 따로 공부하자 . %%R print(mean(sample)) ## 평균 print(sd(sample)) ## 분산 . [1] 36.35498 [1] 0.5006206 . %%R t.test(sample, mu = 36.5, alternative = &#39;two.sided&#39;, conf.level = 0.95) . One Sample t-test data: sample t = -2.0483, df = 49, p-value = 0.04591 alternative hypothesis: true mean is not equal to 36.5 95 percent confidence interval: 36.21271 36.49726 sample estimates: mean of x 36.35498 . - p-값을 보면 0.04591로 유의수준인 0.05보다 작음 &gt; 영가설을 기각한다 . - 따라서 표본에 따르면 사람의 평균 체온은 $36.5^{°} mathrm{C}$와 다르다고 할 수 있다 . - 임의로 만든 표본은 평균이 36.3인 정규분포에서 추출한 것이므로 올바르게 추론한 것을 알 수 있음 . &#54217;&#44512; &#52264;&#51060; &#48516;&#54252; . - 단일 평균에 대한 t검정과 차이점은 표본이 하나인가 둘인가이다 . - 평균 차이에 대한 t검정에서 관심있는 모수는 $ mu_1 - mu_2$이다 . - 평균이 $ mu_1$과 $ mu_2$인 모집단에서 표본크기가 $n_1$과 $n_2$인 무작위 표본을 얻었을 때 표본 평균 차이 $ bar{x_1}- bar{x_2}$의 분포는 중심이 모집단 평균 차이$ mu_1- mu_2$이고 표준오차는 $ sqrt{ frac{{s_1}^{2}}{n_1}+ frac{{s_2}^2}{n_2}}$이다 . - 표본 평균 차이를 표준화한 값은 t분포를 따르며 자유도는 근사적으로 $n_1+n_2-2$ . - $n_1 &lt;30$ or $n_2&lt;30$인 경우 표본 크기가 작으며 이 경우에는 모집단이 정규분포를 따라야 함 . - 평균 차이를 검정할 땐 두 집단이 서로 독립인지 아닌지가 중요함 &gt; 독립여부에 따라 검정 방법이 달라짐 . - 여기서는 독립표본에 대해 얘기할 것 임 . - 두 집단의 분산의 동질성이 중요함 &gt; 평균 차이 검정을 하기 전에 분산의 동질성 검정을 수행함 . - 분산이 같은 경우 student&#39;s t-test를 사용하고 분산이 다른 경우 Welch&#39;s t test사용함 . &#54217;&#44512; &#52264;&#51060;&#50640; &#45824;&#54620; t&#44160;&#51221; . - 영가설 $H_0: mu_1- mu_2=0$를 검정하는 t-통계량은 다음과 같음 . - $t= cfrac{( bar{x_1}- bar{x_2})-0}{ sqrt{ frac{{s_1}^2}{n_1}+ frac{{s_2}^2}{n_2}}}$ . - $ bar{x_1}$과 $ bar{x_2}$는 표본 평균, $s_1$과 $s_2$는 표본의 표준편차 . &#54217;&#44512; &#52264;&#51060;&#50640; &#45824;&#54620; t&#44160;&#51221; &#50696;&#51228; . 문제 | . - 남자의 평균 체온$( bar{x}_{_1})$과 여자의 평균 체온$( bar{x}_{_2})$이 다른지 검정하기 위해 각각 건강한 사람 50명의 체온을 재었다 . - 임의로 데이터를 설정하여 남자의 평균 체온 데이터는 평균이 36.5, 표준편차는 0.4인 정규분포에서 추출했음 . - 임의로 데이터를 설정하여 여자의 평균 체온 데이터는 평균이 36.45, 표준편차는 0.5인 정규분포에서 추출했음 . - 임의로 뽑은 표본을 보니 $ bar{x}_{_1} = 36.54, ; bar{x}_{_2} = 36.5, ; s_{_1}=0.4, ;s_{_2}=0.53$이다 . - 위의 데이터는 남자와 여자의 평균 체온이 서로 다르다는 증거인지 유의수준 $ alpha=0.05$ 에서 검정하자 . 해결 과정 | . - $H_0: mu_1- mu_2 = 0, ;H_a: mu_1 neq mu_2$ . - 표본 크기가 충분하고 표본에 대한 히스토그램을 보면 정규분포를 따르는 것으로 보인다 . - 남자 모집단과 여자 모집단에서 표본을 추출했으므로 두 표본은 서로 독립이다 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . import matplotlib.pyplot as plt import numpy as np ## 예시 샘플 np.random.seed(2021) man_heat = np.random.normal(loc = 36.5, scale = 0.4, size = 50) woman_heat = np.random.normal(loc = 36.45, scale = 0.5, size = 50) fig, ax = plt.subplots(1, 2, figsize = (10, 4)) ax[0].hist(man_heat) ax[1].hist(woman_heat) ax[0].set_title(&#39;man body heat data&#39;) ax[1].set_title(&#39;woman body heat data&#39;) plt.show() %R -i man_heat,woman_heat . - 두 표본이 정규성을 따르는지 정확히 확인하자 . %%R shapiro.test(man_heat) . Shapiro-Wilk normality test data: man_heat W = 0.98456, p-value = 0.7524 . %%R shapiro.test(woman_heat) . Shapiro-Wilk normality test data: woman_heat W = 0.96223, p-value = 0.1102 . - 둘다 p-값이 크므로 정규성을 가정하자 . - 평균 차이 검정을 하기전에 우선 두 표본의 분산이 동일한지 검정하자 . - var.test는 두 집단의 분산이 동일한지 비교함 ratio(두 집단 분산의 비율)이 1이 아니라면 두 집단의 분산이 다르다는 증거임 . %%R print(mean(man_heat)) print(sd(man_heat)) print(mean(woman_heat)) print(sd(woman_heat)) . [1] 36.54399 [1] 0.4004965 [1] 36.52622 [1] 0.5260057 . %%R var.test(man_heat, woman_heat, ratio = 1, alternative = &quot;two.sided&quot;, conf.level = 0.95) . F test to compare two variances data: man_heat and woman_heat F = 0.57972, num df = 49, denom df = 49, p-value = 0.05916 alternative hypothesis: true ratio of variances is not equal to 1 95 percent confidence interval: 0.3289758 1.0215715 sample estimates: ratio of variances 0.5797175 . - 두 집단의 분산이 같은지 검정하니 p-값이 0.05보다 크기 때문에 다르다고 할만한 충분한 증거가 없으므로 동일하다 가정함 . - 분산이 각각 0.4와 0.5인 집단에서 표본을 추출하여 원래는 분산이 다르지만 표본크기가 작기 때문에 0.1의 차이를 판단하지 못하였음 . - 아무튼 var.test 결과는 분산이 동일하다 나왔으므로 두 집단의 분산이 동일하다 생각하고 평균 차이를 검정하자 . %%R t.test(man_heat, woman_heat, alternative = &#39;two.sided&#39;, var.equal = T, conf.level = 0.95) . Two Sample t-test data: man_heat and woman_heat t = 0.19001, df = 98, p-value = 0.8497 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: -0.1677758 0.2033056 sample estimates: mean of x mean of y 36.54399 36.52622 . - 검정결과를 보면 p-값이 0.05보다 크므로 영가설을 기각하지 못함 &gt; 남자와 여자의 평균체온을 다르다고 할 수 없음 . - 실제 데이터는 평균이 36.5와 36.45로 다르지만 표본의 크기가 충분하지 않아 이를 잡아내지 못함 . - 표본 크기가 50이 아니라 더욱 커진다면 위의 차이를 알아낼 수 있음 . &#45824;&#51025;&#54364;&#48376;&#50640; &#45824;&#54620; &#54217;&#44512; &#52264;&#51060; t&#44160;&#51221; . - 위에서 두 개의 개별 표본일 때 평균 차이 검정을 했음 . - 하지만 자료가 짝으로 주어졌다면 위와 동일한 방법으로 검정을 수행하면 안됨 . - 짝 자료 &gt; 동일한 피실험체를 두 가지 다른 조건에서 측정한 데이터 ex) 개별 사람의 왼손과 오른손 악력, 약을 복용하기 전과 후의 혈압 . - 조건이 동일하다면 동일한 피실험체가 아니어도 가능함 &gt; ex) 일란성 쌍둥이의 IQ . - 짝 자료에 대한 평균 차이 검정은 우선 각 짝 자료의 차이를 계산한 후 차이에 대한 평균 $ bar{x}_{_d}$, 표준편차 $s_{_d}$, 표본 크기 $n_{_d}$를 계산 . - $t = cfrac{ bar{x}_{_d} - 0}{ frac{s_{_d}}{ sqrt{n_{_d}}}}$를 자유도가 $n_{_d}-1$인 t분포에서 검정함 . &#45824;&#51025; &#54364;&#48376;&#50640; &#45824;&#54620; &#54217;&#44512; &#52264;&#51060; t&#44160;&#51221; &#50696;&#51228; . 문제 | . - 소설을 읽을 때 스토리 스포일러를 포함한 경우와 그렇지 않은 경우에 대해 즐거움의 등급(점수)차이가 있는지 유의수준 $ alpha=0.05$ 에서 검정하자 . - 등급이 높을 수록 스토리가 더 재밌었다는 것을 의미함 . - 12개 스토리의 각 버전은 최소 30명이 읽고 1~10등급으로 등급을 매겼음 . - 스포일러 유 &gt; 4.7, 5.1, 7.9, 7.0, 7.1, 7.2, 7.1, 7.2, 4.8, 5.2, 4.6, 6.7 . - 스포일러 무 &gt; 3.8, 4.9, 7.4, 7.1, 6.2, 6.1, 6.7, 7.0, 4.3, 5.0, 4.1, 6.1 . 해결 과정 | . - 12개의 스토리를 동일한 조건(무작위 샘플링)을 지닌 사람이 두 가지 처리(스포일러 유무)를 받아 읽고 등급을 평가함 &gt; 대응 표본 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . %%R install.packages(&#39;ggplot2&#39;) library(ggplot2) . Please select a CRAN mirror for use in this session . R[write to console]: trying URL &#39;https://cran.seoul.go.kr/bin/windows/contrib/4.0/ggplot2_3.3.5.zip&#39; R[write to console]: Content type &#39;application/zip&#39; R[write to console]: length 4129414 bytes (3.9 MB) R[write to console]: downloaded 3.9 MB . package &#39;ggplot2&#39; successfully unpacked and MD5 sums checked The downloaded binary packages are in C: tmp Rtmp0OKRvu downloaded_packages . %%R with_spoiler &lt;- c(4.7, 5.1, 7.9, 7.0, 7.1, 7.2, 7.1, 7.2, 4.8, 5.2, 4.6, 6.7) original &lt;- c(3.8, 4.9, 7.4, 7.1, 6.2, 6.1, 6.7, 7.0, 4.3, 5.0, 4.1, 6.1) diff &lt;- with_spoiler - original diff_df &lt;- as.data.frame(diff) ggplot(diff_df, aes(x = diff)) + xlab(&#39;Difference&#39;) + geom_dotplot(binwidth = 0.1) . - 짝 자료 차이에 대한 점도표를 보면 정규분포를 부정할 만한 비대칭이나 이상점은 없어보임 . %%R shapiro.test(diff) . Shapiro-Wilk normality test data: diff W = 0.95506, p-value = 0.7116 . - 샤피로 윌크 검정도 해보니 정규분포임을 가정해도 괜찮아 보임 . %%R t.test(with_spoiler, original, paired = T, alternative = &#39;two.sided&#39;, conf.level = 0.95) . Paired t-test data: with_spoiler and original t = 4.8997, df = 11, p-value = 0.0004719 alternative hypothesis: true difference in means is not equal to 0 95 percent confidence interval: 0.2708052 0.7125281 sample estimates: mean of the differences 0.4916667 . - R에서 대응 표본에 대한 검정을 하려면 paried = T 옵션을 적용한다 . - p-값이 0.0004719로 매우 작으므로 영가설을 기각하자 &gt; 스포일러 유무에 따른 재미의 등급은 차이가 있다! . &#47784;&#48516;&#49328;&#50640; &#45824;&#54620; &#52628;&#47200; . - 모집단이 얼마나 퍼져있는지에 대해 궁금할 수 있음 . - ex) 공장에서 생산하는 과자의 무게 . - 과자의 무게 변동이 큰지 작은지에 대한 검정이 모분산에 대한 검정이다 . &#45800;&#51068; &#47784;&#48516;&#49328;&#50640; &#45824;&#54620; &#44160;&#51221; . - 우선 단일 모분산에 대한 검정에는 $ chi^2$분포가 사용됨 &gt; 왜? . - 카이제곱분포를 떠올려보면 다음과 같음 . - $n$개의 서로 독립인 확률표본이 평균 $ mu$ 분산 $ sigma^2$인 정규분포에서 추출되었다고 하자 . - 모평균이 알려져 있지 않은 상황에서는 $ mu$ 대신 $ overline{X}$를 사용함 . $$ begin{aligned} sum Z_{i}^{2}&amp;= left( cfrac{X_1- overline{X}_n}{ sigma} right)^2 + left( cfrac{X_2- overline{X}_n}{ sigma} right)^2+ cdots+ left( cfrac{X_n- overline{X}_n}{ sigma} right)^2 &amp;= cfrac{1}{ sigma^2} sum(X_i- overline{X}_n)^2 [10pt] &amp;= chi^2_{n-1} end{aligned}$$ - 그런데 $s^2= cfrac{1}{n-1} sum(X_i- overline{X}_n)^2$ 이므로 $ chi^2_{n-1}= cfrac{(n-1)s^2}{ sigma^2}$ 이다 . - 따라서 $ cfrac{(n-1)s^2}{ sigma^2}$의 표본분포는 자유도가 $n-1$인 $ chi^2_{n-1}$분포를 하고 있다 . - $ chi^2$분포가 어떻게 생겼는지 그래프를 그려서 확인해보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import chi2 fig, ax = plt.subplots(figsize = (14, 7)) x = np.linspace(0, 8, 1000) for df in np.arange(1, 6): ax.plot(x, chi2(df).pdf(x), label = &#39;k = &#39; + str(df)) major_xticks = np.arange(0.0, 9.0, 2.0) minor_xticks = np.arange(0.5, 8.0, 0.5) major_yticks = np.arange(0, 1.2, 0.2) minor_yticks = np.arange(0.05, 1.0, 0.05) ax.set_title(&quot;$ chi^2$ distribution(df = 1, 2, 3, 4, 5)&quot;, fontsize = 20) ax.set_ylim(0, 1) ax.set_xlim(0, 8) ax.set_xticks(major_xticks) ax.set_xticks(minor_xticks, minor = True) ax.set_yticks(major_yticks) ax.set_yticks(minor_yticks, minor = True) ax.set_xlabel(&quot;$x$&quot;, fontsize = 14) ax.set_ylabel(&quot;$f(x)$&quot;, fontsize = 14, rotation = 0, labelpad = 20) ax.tick_params(axis = &#39;both&#39;, labelsize = 15, length = 10, direction = &#39;in&#39;) ax.tick_params(axis = &#39;both&#39;, which = &#39;minor&#39;, length = 5, direction = &#39;in&#39;) ax.grid() ax.legend() plt.show() . . - 정규분포와 t분포와 다르게 오른쪽으로 꼬리가 긴 분포이다 . - $ cfrac{(n-1)s^2}{ sigma^2}$의 표본분포는 위의 그래프처럼 자유도에 따라 달라짐 . - 단일모분산을 검정하는 검정통계량은 다음과 같음 . $$ chi^2_{n-1}= cfrac{(n-1)s^2}{ sigma^2}$$ . - 가설 $H_0 : sigma^2 = sigma_0^2$ 에 대한 검정은 대안가설 부호에 따라 다름 . $$ begin{aligned}H_a &amp;: sigma^2&gt; sigma_0^2 longrightarrow chi^2&lt; chi^{2}_{ alpha} H_a &amp;: sigma^2&lt; sigma_0^2 longrightarrow chi^2&gt; chi^2_{1- alpha} H_a &amp;: sigma^2 neq sigma_0^2 longrightarrow chi^2&lt; chi^2_{1- frac{ alpha}{2}} ; or ; chi^2&gt; chi^2_{ frac{ alpha}{2}} end{aligned}$$ - 이때 $ chi^2_{ alpha}$은 분포의 오른쪽 확률이 $ alpha$임을 나타낸다 . - 위가 성립하면 귀무가설 $H_0$를 기각한다 . &#45800;&#51068; &#47784;&#48516;&#49328;&#50640; &#45824;&#54620; &#44160;&#51221; &#50696;&#51228; . - 임의로 샘플을 만들고 모분산에 대해 검정해보자 . import numpy as np np.random.seed(2021) data = np.random.normal(0, 2, 10) . - 평균이 0이고 분산이 4인 정규분포에서 10개의 샘플을 뽑았다 . - 샘플을 가지고 $ alpha = 0.05$에서 모분산이 3를 넘는지 검정해보자 . $$H_0 : sigma^2 = 3 H_a : sigma^2 &gt; 3$$ . var_0 = 3 n = len(data) df = n - 1 s = np.std(data, ddof = 1) chi_square = (n-1) * (s**2) / var_0 ## 검정통계량 . s ## 표분편차는 1.52 . 1.5249196358322268 . - 검정통계량(chi2)이 $ chi^2_{0.05}$ 보다 크면 영가설을 기각할 수 있다 . from scipy.stats import chi2 X_square = chi2.ppf(0.95, df) ## 카이제곱분포의 오른쪽 영역이 0.05(왼쪽 영어은 0.95)가 되게하는 x 값 ## 누적분포의 역함수(ppf)를 통해 구한다 . X_square . 16.918977604620448 . chi_square . 6.9761396872400745 . X_square &lt; chi_square . False . - 검정통계량이 기각역보다 크지 않으므로 영가설을 기각할 수 없다 . - 따라서 모분산은 3보다 크다고 말할 수 없다 . - 분산이 4인 정규분포에서 샘플을 뽑았지만 영가설을 기각하지 못했음 . - 표본크기가 10으로 작아 변동성이 커 샘플의 분산이 2.32 이기 때문임 . - 표본크기가 더 크다면 영가설을 기각할 수 있을 것이다 . &#46160; &#47784;&#51665;&#45800;&#48516;&#49328; &#52264;&#51060;&#50640; &#45824;&#54620; &#44160;&#51221; . - 두 모집단의 분산을 비교하는데에는 F분포를 사용함 &gt; 왜? .",
            "url": "https://jaesu26.github.io/green/python/r/statistics/2021/07/27/%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%95.html",
            "relUrl": "/python/r/statistics/2021/07/27/%EA%B0%80%EC%84%A4%EA%B2%80%EC%A0%95.html",
            "date": " • Jul 27, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "파이썬에서 R실행",
            "content": "&#54028;&#51060;&#50028;&#50640;&#49436; R&#49892;&#54665;&#54616;&#44592; . 1. 아나콘다에 접속한 후 Anaconda Installers에서 64-Bit Graphical Installer(477MB)설치 . 2. Anaconda Prompt (anaconda3) 실행 . 3. 아래와 같이 입력 . (base) C: Users 한재수&gt; conda create -n py38r40 python=3.8 . (base) C: Users 한재수&gt; conda activate py38r40 . (py38r40) C: Users 한재수&gt; conda install jupyter lab . (py38r40) C: Users 한재수&gt; pip install rpy2 . (py38r40) C: Users 한재수&gt; R . 4. R에서 아래와 같이 입력 . &gt; install.packages(&quot;IRcernel&quot;) . &gt; IRcernel::installspec() . &gt; R.home() ## 나오는 경로 복사 . &gt; q() ## R 종료 . 5. 다시 프롬프트로 돌아와서 주피터랩 실행 . (py38r40) C: Users 한재수&gt; jupyter lab . 6. R세팅은 끝났고 파이썬에서 R을 사용하려면 아래와 같이 입력(주피터랩 킬 때마다 한 번씩만 입력) . import os . os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; ## R.HOME 에서 복사한 경로 . import rpy2 . %load_ext rpy2.ipython . 7. R사용 . 셀 마다 %R or %%R 입력하여 사용 . import os . os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; ## R.HOME 에서 복사한 경로 . import rpy2 . %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . %R q &lt;- c(1, 2, 3) %R print(q) Q = [1, 2, 3] print(Q) . [1] 1 2 3 [1, 2, 3] . %%R x &lt;- c(1, 2, 3, 4, 5, 8, 9, 11) y &lt;- c(5, 1, 7, 12, 11, 5, 7, 21) model &lt;- lm(y ~ x) summary(model) . Call: lm(formula = y ~ x) Residuals: Min 1Q Median 3Q Max -6.3741 -4.4232 0.9096 3.2796 6.4840 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.9958 3.4644 0.865 0.420 x 1.0473 0.5469 1.915 0.104 Residual standard error: 5.185 on 6 degrees of freedom Multiple R-squared: 0.3793, Adjusted R-squared: 0.2759 F-statistic: 3.667 on 1 and 6 DF, p-value: 0.104 . - %R -i 을 통해 파이썬에서 정의한 변수를 R에서 사용할 수 있음 . import numpy as np data = np.random.rand(50) %R -i data . %%R hist(data) .",
            "url": "https://jaesu26.github.io/green/python/r/2021/07/26/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%97%90%EC%84%9C-R%EC%8B%A4%ED%96%89.html",
            "relUrl": "/python/r/2021/07/26/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%97%90%EC%84%9C-R%EC%8B%A4%ED%96%89.html",
            "date": " • Jul 26, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "변수 이름",
            "content": "&#48320;&#49688; &#51460;&#51076;&#47568; . - 변수를 줄임말로 쓸 때가 있는데 뭐인지 헷갈리는 변수를 정리할 거임 . - 나중에 변수 줄임말 말고도 변수명을 어떻게 정할지에 대한 내용도 정리할 수 도 있음 . - rtn &gt; return . - tmp &gt; temporary variable . - num &gt; number . - lib &gt; library . - lin &gt; linear . - rv &gt; random variable . - aes &gt; aesthetic . - axes &gt; axis(축)의 복수형 . - param(s) &gt; parameter(s) . - loc &gt; location . - pch &gt; point character . - fig &gt; figure . - ax &gt; axes . - alg &gt; algebra(대수학) . - cnt &gt; count . - ec &gt; edgecolor . - fc &gt; facecolor . - h &gt; horizontal . - v &gt; vertical . - cpy &gt; copy . - tb &gt; table . - autopct &gt; autopercentage . - ptr &gt; pointer . &#48320;&#49688; &#51460;&#51076;&#47568;&#51008; &#50500;&#45768;&#51648;&#47564; &#50500;&#47924;&#53948; &#51460;&#51076;&#47568;&#51076; . - WLLN &gt; Weak Law of Large Numbers(큰 수의 약한 법칙) . - MLE &gt; maximum likelihood estimate(최대우도추정량) . &#48320;&#49688; &#51060;&#47492; &#51667;&#44592; . - 모음을 생략하여 짓기 count &gt; cnt, return &gt; rtn . - 임시 변수는 _ 붙이기 &gt; tmp_ .",
            "url": "https://jaesu26.github.io/green/variable%20name/2021/07/26/%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84.html",
            "relUrl": "/variable%20name/2021/07/26/%EB%B3%80%EC%88%98-%EC%9D%B4%EB%A6%84.html",
            "date": " • Jul 26, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "적률생성함수",
            "content": "&#51201;&#47456;&#51060;&#46976; . - 확률변수의 특징을 설명 . - 확률변수 $X$의 $k$차 중심적률(central moment)을 $ mu_{k}$라 하면 $ mu_{k} = E[(X- mu)^{k}]$ . - $ mu_{1} = E(X) - mu = 0$ &gt; 확률변수 $X$의 $1$차 중심적률은 $0$ . - $ mu_{2} = E[(X- mu)^{2}]$ &gt; 확률변수 $X$의 $2$차 중심적률은 분산 . - $ mu_{3} = E[(X- mu)^{3}]$ &gt; 확률변수 $X$의 $3$차 중심적률은 왜도 . - $ mu_{4} = E[(X- mu)^{4}]$ &gt; 확률변수 $X$의 $4$차 중심적률은 첨도 . - 일반적인 확률 변수 $X$의 적률(moment)은 비중심(non-central)적률을 나타냄 $ longrightarrow$ $ mu&#39;_{k} = E[X^k]$ . - $ mu&#39;_{k} = E[X^k] = begin{cases} text{이산확률변수 : } sum limits_{x}x^{k}f(x) text{연속확률변수 : } int_{- infty}^{ infty}x^{k}f(x)dx end{cases}$ . - $ mu&#39;_{1} = mu$ . - $ sigma^{2} = mu_{2} = mu&#39;_{2} - ( mu&#39;_{1})^{2}$ . - 모평균$ mu$는 확률변수 $X$의 1차 비중심적률 . - 모분산$ sigma^{2}$은 확률변수 $X$의 2차 비중심적률에서 1차 비중심적률의 제곱을 뺀 값 . - 참고 자료: 통계수학 강의 . &#51201;&#47456;&#49373;&#49457;&#54632;&#49688;(moment generating function, mgf) . - 특정 확률 분포의 적률을 생성하는 함수 . - 적률을 계산하려면 연속확률변수의 경우 적분을 하게 되는데 어렵거나 불가능한 경우도 있음 &gt; 적률생성함수를 통해 계산 가능 . - 임의의 확률변수 $X$의 기댓값이 존재한다면 $X$의 적률생성함수 $M_{X}(t) = E(e^{tX}), ; t in mathbb{R}$ . - $M_{X}(t) = E(e^{tX}) = begin{cases} text{이산확률변수 : } sum limits_{x}e^{tx}f(x) text{연속확률변수 : } int_{- infty}^{ infty}e^{tx}f(x)dx end{cases}$ . - 확률변수 $X$의 기댓값을 구하는데 $X$가 아니라 $x$가 사용되네?? . - $X$의 기댓값은 $X$가 가질 수 있는 값인 $x$들을 통해 구한다 . - 사실 $x$말고 $k$라고 하든지 $a$라고 하든지 다른 변수를 사용해도 됨 &gt; 마치 적분할 때 $ int x ,dx = int t , dt = int a ,da$ 인 것 처럼 . - 중요한건 확률변수가 가질 수 있는 값들을 가지고 기댓값을 구한다는 것 &gt; 당연한 소리 . - 확률변수 $X$가 가질 수 있는 모든값들을 구하고 이것들의 평균을 구하면 그게 확률변수의 기댓값(당연함) . - 참고: $X$는 확률변수, $x$는 확률변수 $X$가 가지는 값 &gt; 이산확률변수는 $P(X=x)$, 연속확률변수는 $P(A leq X leq B)$ . - 적률생성함수는 항상 존재하는 것이 아님 . $e^{tX}$가 $t=0$근방에서 적분이 가능해야 함 $ ; ;$ . | $ forall , t in mathbb{R}, ; ;E(e^{tX}) &lt; infty $ . | &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; &#53945;&#51669; . - 두 확률변수의 mgf가 일치하면 두 확률변수는 같은 분포를 가짐 . - 적률생성함수를 $k$번 미분하고 $t=0$을 대입하면 확률변수 $X$의 $k$차 비중심 적률이다 &gt; 왜??? . &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; k&#48264; &#48120;&#48516; $ longrightarrow$ k&#52264; &#48708;&#51473;&#49900; &#51201;&#47456; . - $M_{X}(t) = E(e^{tX})$ . - $ cfrac{d^{k}M_{X}(0)}{dt^{k}} = E(X^{k})$ . - 매클로린 급수를 사용하자 . - $e^{tX} = sum limits_{k = 0}^{ infty} cfrac{X^k}{k!}(e^{tX})^{(k)}(0) = cfrac{t^{0}}{0!}X^{0}+ cfrac{t^1}{1!}X^1+ cfrac{t^2}{2!}X^2+ cfrac{t^3}{3!}X^3+ dots$ . - 양변에 기댓값을 취하면... . - $M_X(t)=E(e^{tX}) = 1 + tE(X) + cfrac{t^2}{2!}E(X^2) + cfrac{t^3}{3!}E(X^3)+ dots$ . - 이제 양변을 t에 대해 미분하자 . - $ cfrac{dM_X(t)}{dt} = 0 + E(X) + tE(X^2) + cfrac{t^2}{2}E(X^3)+ dots$ . - 이제 $t=0$을 대입하면... . - $ cfrac{dM_X(0)}{dt} = E(X)$ &gt; 1번 미분하니 1차 적률이 구해짐 . - 그럼 한 번 더 미분하면 2차 적률? &gt; ㅇㅇ . - $ cfrac{d^2M_X(t)}{dt^2} = 0 + 0 + E(X^2) + tE(X^3)+ dots$ . - 참고: $E(X)$는 $t$에 대하여 상수임 . - 이제 $t=0$을 대입하면 . - $ cfrac{d^2M_X(0)}{dt^2} = E(X^2)$ . - 정말로 2번 미분하니 2차 적률이 구해졌다.. . - 확률 분포에 대해 정리할 때 기댓값과 분산을 과정없이 결과만 적었었음 . - 적률생성함수를 통해 여러가지 확률 분포의 기댓값과 분산을 구해보자 . &#44512;&#51068; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 균일 분포의 확률 밀도 함수: $f(x) = cfrac{1}{b-a}$ . - 균일 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{a}^{b}e^{tx} frac{1}{b-a}dx longrightarrow text{확률변수$X$가 $a$부터 $b$까지의 값을 가진다는 뜻} [10pt] &amp;= frac{1}{b-a} left[ frac{1}{t}e^{tx} right]_{a}^{b} [10pt] &amp;= frac{e^{t}(e^{b}-e^{a})}{t(b-a)} end{aligned}$ . - 균일 분포의 기댓값 &gt; 적률생성함수를 통해 구하는 것보다 1차 적률의 정의를 통해 구하는 것이 더 쉬움 . $ begin{aligned}E(X) &amp;= int_{a}^{b} frac{1}{b-a}x ;dx [10pt] &amp;= frac{1}{b-a} left[ frac{x^2}{2} right]_{a}^{b} [10pt] &amp;= frac{b^{2}-a^{2}}{2(b-a)} [10pt] &amp;= frac{a+b}{2} end{aligned}$ . - 균일 분포의 분산 &gt; 적률의 정의를 통해 구하자 &gt; 우선 2차 비중심 적률을 구하자 . $ begin{aligned}E(X^2) &amp;= int_{a}^{b} frac{1}{b-a}x^2 ;dx [10pt] &amp;= frac{1}{b-a} left[ frac{x^3}{3} right]_{a}^{b} [10pt] &amp;= frac{b^{3}-a^{3}}{3(b-a)} [10pt] &amp;= frac{a^2+ab+b^2}{3} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= cfrac{a^2+ab+b^2}{3} - bigg( cfrac{a+b}{2} bigg)^2 [10pt] &amp;= cfrac{4(a^2+ab+b^2) ,- 3(a^2+2ab+b^2)}{12} [10pt] &amp;= frac{(b-a)^2}{12} end{aligned}$ . &#44592;&#54616; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 기하 분포의 확률 질량 함수: $f(x) = q^{x-1}p, ; q=1-p, ; x = 1, 2, 3, dots$ . - 첫째항이 $a$, 공비가 $r$인 무한등비수열의 합: $ frac{a}{1-r}, ; |r|&lt;1$ . - 기하 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= sum limits_{x=1}^{ infty}e^{tx}q^{x-1}p [10pt] &amp;= frac{p}{q} sum limits_{x=1}^{ infty}(qe^{t})^{x}, quad -1 &lt; qe^t &lt; 1 [10pt] &amp;= frac{pqe^t}{q(1-qe^t)} [10pt] &amp;= frac{pe^t}{1-qe^t}, quad t&lt;-ln(1-p) end{aligned}$ . - 기하 분포의 기댓값 . - 몫의 미분: $ bigg { cfrac{f(x)}{g(x)} bigg }&#39; = cfrac{f&#39;(x)g(x)-f(x)g&#39;(x)}{(g(x))^2}$ . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= frac{pe^{t}(1-qe^t)-pe^{t}(-qe^t)}{(1-qe^t)^2} [10pt] &amp;= frac{pe^t}{(1-qe^t)^2} , quad text{$t=0$ 대입} [10pt] &amp;= frac{p}{(1-q)^2} [10pt] &amp;= frac{1}{p} end{aligned}$ . - 기하 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= frac{pe^{t}(1-qe^t)^2- 2pe^{t}(1-qe^{t})(-qe^t)}{(1-qe^t)^4} [10pt] &amp;= frac{pe^{t}(1-qe^t)((1-qe^t)+2qe^t)}{(1-qe^t)^4} [10pt] &amp;= frac{pe^{t}(1+qe^t)}{(1-qe^t)^3}, quad text{$t=0$ 대입} [10pt] &amp;= frac{p(1+q)}{(1-q)^3} [10pt] &amp;= frac{1+q}{p^2} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= frac{1+q}{p^2} - big( frac{1}{p} big)^2 [10pt] &amp;= frac{q}{p^2} end{aligned}$ . &#51060;&#54637; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 이항 분포의 확률 질량 함수: $f(x) ,= , _{n} rm C_{x} ,p^{x} ,(1-p)^{n-x}$ . - 이항 분포는 서로 독립이고 동일한 베르누이 분포를 따르는 확률변수들을 n개 합한 것임 . - 베르누이 분포의 확률 질량 함수 $f(x) = p^{x}(1-p)^{1-x}, ; x = 0, 1$ . - 베르누이 분포의 기댓값 . $ begin{aligned}E(X) &amp;= sum limits_{x=0}^{1}xp^{x}(1-p)^{1-x} [10pt] &amp;= 0 cdot (1-p) + 1 cdot p [10pt] &amp;= p end{aligned}$ . - 베르누이 분포의 분산 . $ begin{aligned}E(X^2) &amp;= sum limits_{x=0}^{1}x^2p^x(1-p)^{1-x} [10pt] &amp;= 0 cdot (1-p) + 1 cdot p [10pt] &amp;= p end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2)-[E(X)]^2 [10pt] &amp;= p - p^2 [10pt] &amp;= p(1-p) end{aligned}$ . - 확률변수 $X, Y$에 대해 $E(X + Y)= E(X) + E(Y)$ . - 확률변수 $X, Y$가 독립이면 $Var(X + Y) = Var(X) + Var(Y)$ . - 참고: 확률변수의 합 특징 . - 이항 분포의 기댓값 &gt; 이항 분포의 정의를 통해 구함: 베르누이 분포를 따르는 확률변수들의 합 . $ begin{aligned}E(X) &amp;= E bigg( sum limits_{i=1}^{n}X_i bigg) = sum limits_{i=1}^{n}E(X_i) [10pt] &amp;= E(X_1) + E(X_2) + dots+E(X_{n-1})+E(X_n) [10pt] &amp;= overbrace{p + dots + p}^{n rm times} = np end{aligned}$ . - 이항 분포의 분산 --&gt; 기댓값과 마찬가지 . $ begin{aligned}Var(X) &amp;= Var bigg( sum limits_{i=1}^{n}X_i bigg) = sum limits_{i=1}^{n}Var(X_i) [10pt] &amp;= Var(X_1)+Var(X_2)+ dots+Var(X_{n-1})+Var(X_n) [10pt] &amp;= overbrace{p(1-p)+ dots+p(1-p)}^{n rm times} = np(1-p) end{aligned}$ . - 이항 정리 . - $(x+y)^n = sum limits_{k=0}^{n} binom{n}{k}x^{n-k}y^{k}$ . - 이항 분포의 적률생성함수 . $ begin{aligned}M_{X}(t) &amp;= E(e^{tX}) [10pt] &amp;= sum limits_{x=0}^{n} binom{n}{x}e^{tx}p^{x} ,(1-p)^{n-x} [10pt] &amp;= sum limits_{x=0}^{n} binom{n}{x}(pe^{t})^{x} ,(1-p)^{n-x} [10pt] &amp;= (1-p+pe^{t})^n end{aligned}$ . - 이항 분포의 기댓값 &gt; 적률생성함수 미분해서 구하기 . - 합성함수의 미분 . - $ big {f(g(x)) big }&#39; = g&#39;(x)f&#39;(g(x))$ . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= npe^t(1-p+pe^t)^{n-1}, quad text{$t=0$ 대입} [10pt] &amp;= np end{aligned}$ . - 곱의 미분 . - $ big {f(x)g(x) big }&#39;=f&#39;(x)g(x)+f(x)g&#39;(x)$ . - 이항 분포의 분산 &gt; 적률생성함수 미분해서 구하기 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= npe^{t} cdot(1-p+pe^t)^{n-1}+npe^{t} cdot (n-1)pe^{t}(1-p+pe^{t})^{n-2}, quad text{$t=0$ 대입} [10pt] &amp;=np+np^{2}(n-1) [10pt] &amp;= np-np^2+n^2p^2 end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2)-[E(X)]^2 [10pt] &amp;= np-np^2+n^2p^2-(np)^2 [10pt] &amp;= np-np^2 [10pt] &amp;=np(1-p) end{aligned}$ . &#54252;&#50500;&#49569; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 테일러 급수 공부해라 구더기야 + 극좌표계도(희망) 하기 싫어.......... . - 테일러 급수: 초월함수를 특정 값의 근방에서 멱함수로 근사시킴 &gt; 개사기임 . - $a$에서 $f$의 테일러 급수 . $ begin{aligned}f(x) &amp;= sum limits_{n=0}^{ infty} frac{f^{(n)}(a)}{n!}(x-a)^{n} [10pt] &amp;= f(a) + frac{f&#39;(a)}{1!}(x-a)+ frac{f&#39;&#39;(a)}{2!}(x-a)^2+ frac{f&#39;&#39;&#39;(a)}{3!}(x-a)^3+ cdots end{aligned}$ . - $a=0$인 특별한 경우 매클로린 급수라고 함 . $ begin{aligned}f(x) &amp;= sum limits_{n=0}^{ infty} frac{f^{(n)}(0)}{n!}x^n [10pt] &amp;= f(0) + frac{f&#39;(0)}{1!}x+ frac{f&#39;&#39;(0)}{2!}x^2+ frac{f&#39;&#39;&#39;(0)}{3!}x^3+ cdots end{aligned}$ . - $e^x$의 매클로린 급수 . - $e^x = sum limits^{ infty}_{n=0} cfrac{x^n}{n!}$ . - 포아송 분포의 확률 질량 함수: $f(x) = cfrac{e^{- lambda} lambda^{x}}{x!}$ . - 포아송 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= sum limits_{x=0}^{ infty}e^{tx} frac{e^{- lambda} lambda^{x}}{x!} [10pt] &amp;=e^{- lambda} sum limits_{x=0}^{ infty} frac{( lambda e^{t})^{x}}{x!} quad text{$ therefore lambda e^t to x, quad x to n$ 으로 바꾸면 $e^x$의 매클로린 급수이다} [10pt] &amp;= e^{- lambda} cdot e^{ lambda e^{t}} [10pt] &amp;= e^{ lambda(e^{t}-1)} end{aligned}$ . - 포아송 분포의 기댓값 . - $e^{- lambda}$ 는 변수가 아니므로 $e^{ lambda e^{t}}$ 에 대해서만 미분하면 된다 . - $y =e^{t}, ; frac{d}{dy}(y) = e^{t}$ . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;=e^{- lambda} cdot(e^{ lambda y})&#39; [10pt] &amp;= e^{- lambda} cdot lambda e^{ lambda y} cdot frac{d}{dy}(y) [10pt] &amp;= e^{- lambda} cdot lambda e^{ lambda e^{t}} cdot e^{t}, quad text{$t=0$ 대입} [10pt] &amp;= lambda cdot e^{- lambda} cdot e^{ lambda} [10pt] &amp;= lambda end{aligned}$ . - 포아송 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= lambda e^{- lambda} cdot big([ lambda e^{ lambda e^{t}} cdot e^{t}] cdot [e^{t}] + [e^{ lambda e^{t}}] cdot[e^{t}] big), quad text{$t=0$ 대입} [10pt] &amp;= lambda e^{- lambda}( lambda e^{ lambda}+e^{ lambda}) [10pt] &amp;= lambda^{2}+ lambda end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2)-[E(X)]^{2} [10pt] &amp;= lambda^{2}+ lambda - lambda^{2} [10pt] &amp;= lambda end{aligned}$ . &#51648;&#49688; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 지수 분포의 확률 밀도 함수: $f(x) = lambda e^{- lambda x}, ; x&gt;0$ . - $ lambda$는 포아송 분포의 모수로 단위 시간당 사건의 평균 발생 횟수 . - 지수 분포의 적률생성함수 . $ begin{aligned}M_{X}(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{0}^{ infty}e^{tx} cdot lambda e^{- lambda x} ,dx [10pt] &amp;= lambda int_{0}^{ infty}e^{tx} cdot e^{- lambda x} ,dx [10pt] &amp;= lambda int_{0}^{ infty}e^{(t- lambda)x} ,dx [10pt] &amp;= frac{ lambda}{t- lambda} cdot left[e^{(t- lambda) x} right]_{0}^{ infty}, ; ; ;(t&lt; lambda) [10pt] &amp;= frac{ lambda}{ lambda - t} end{aligned}$ . - 지수 분포의 기댓값 . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= frac{ lambda}{( lambda - t)^2}, quad text{$t=0$ 대입} [10pt] &amp;= frac{1}{ lambda} end{aligned}$ . - 지수 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= - frac{-2 lambda( lambda-t) }{( lambda-t)^4} [10pt] &amp;= frac{2 lambda}{( lambda - t)^3}, quad text{$t=0$ 대입} [10pt] &amp;= frac{2}{ lambda^2} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= frac{2}{ lambda^2} - bigg( frac{1}{ lambda} bigg)^2 [10pt] &amp;= frac{1}{ lambda^2} end{aligned}$ . &#48288;&#53440; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 베타 분포의 확률 밀도 함수: $f(x)= cfrac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1}, quad 0 leq x leq1, ;( alpha , beta&gt;0)$ . - 베타 분포의 적률생성함수 . $ begin{aligned}M_t(x)&amp;=E(e^{tX}) [10pt] &amp;= int_{0}^{1} frac{1}{B( alpha, beta)}e^{tx}x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= int_{0}^{1} frac{1}{B( alpha, beta)} left( sum limits_{k=0}^{ infty} frac{t^k x^{k-1}}{k!} right)x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= sum limits_{k=0}^{ infty} int_{0}^{1} frac{1}{B( alpha, beta)} frac{t^k}{k!}x^{ alpha+k-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= sum limits_{k=0}^{ infty} left[ int_{0}^{1} frac{B( alpha +k, beta)}{B( alpha, beta)} frac{1}{B( alpha+k, beta)} frac{t^k}{k!}x^{ alpha+k-1}(1-x)^{ beta-1} ;dx right] [10pt] &amp;=1+ sum limits_{k=1}^{ infty} left[ frac{B( alpha +k, beta)}{B( alpha, beta)} frac{t^k}{k!} int_{0}^{1} frac{1}{B( alpha+k, beta)}x^{ alpha+k-1}(1-x)^{ beta-1} ;dx right] [10pt] &amp;=1+ sum limits_{k=1}^{ infty} left[ frac{ Gamma( alpha +k)}{ Gamma( alpha+ beta+k)} frac{ Gamma( alpha + beta)}{ Gamma( alpha)} frac{t^k}{k!} right] [10pt] &amp;=1+ sum limits_{k=1}^{ infty} left[ prod limits_{i=0}^{k-1} frac{ Gamma( alpha +i)}{ Gamma( alpha+ beta+i)} frac{t^k}{k!} right] end{aligned}$ . - 베타 분포의 기댓값 &gt; 적률생성함수를 통해 구하는 것보다 1차 적률의 정의를 통해 구하는 것이 더 쉬움 . - 베타 분포의 $f(x)$를 적분하면 $1$이다 . - 그런데 $f(x)$가 아닌 $xf(x)$를 적분함 &gt; $x^{ alpha-1} to x^{ alpha}$ . - 원래는 성공횟수가 ${ alpha-1}$, 실패횟수가${ beta-1}$인 베타분포인데 성공횟수가 ${ alpha}$, 실패횟수가${ beta-1}$로 바뀌었음 . - 그런데 어차피 베타분포는 확률 밀도 함수이므로 정의역구간을 적분하면 $1$이므로 상관없다 &gt; 하지만 바뀐 베타분포의 상수(베타 함수)가 아닌 기존 베타분포의 상수가 곱해져있는데??? . - 어차피 상수는 적분에 영향을 주지 못하니까 상수항은 임의로 맞춰주면 된다 . $ begin{aligned}E(X) &amp;= int_{0}^{1}x frac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{1}{B( alpha, beta)} int_{0}^{1}x^{ alpha}(1-x)^{ beta-1} ;dx quad text{$ therefore frac{1}{B( alpha+1, beta)}$을 곱해주어 베타 분포를 만들자} [10pt] &amp;= frac{B( alpha+1, beta)}{B( alpha, beta)} int_{0}^{1} frac{1}{B( alpha+1, beta)}x^{ alpha}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{B( alpha+1, beta)}{B( alpha, beta)} cdot 1 &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ Gamma( alpha+1) Gamma( beta)}{ Gamma( alpha + beta+1)} quad text{$ therefore$ 감마함수의 성질: $ Gamma( alpha+1) = alpha Gamma( alpha)$} [10pt] &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ alpha Gamma( alpha) Gamma( beta)}{( alpha+ beta) Gamma( alpha + beta)} [10pt] &amp;= frac{ alpha}{ alpha+ beta} end{aligned}$ . - 베타 분포의 분산 &gt; 적률의 정의를 통해 구하자 &gt; 우선 2차 비중심 적률을 구하자 . - 베타 분포의 기댓값을 구할 때와 같은 방법을 사용하자 . $ begin{aligned}E(X^2) &amp;= int_{0}^{1}x^{2} frac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{1}{B( alpha, beta)} int_{0}^{1}x^{ alpha+1}(1-x)^{ beta-1} ;dx quad text{$ therefore frac{1}{B( alpha+2, beta)}$을 곱해주어 베타 분포를 만들자} [10pt] &amp;= frac{B( alpha+2, beta)}{B( alpha, beta)} int_{0}^{1} frac{1}{B( alpha+2, beta)}x^{ alpha+1}(1-x)^{ beta-1} ;dx [10pt] &amp;= frac{B( alpha+2, beta)}{B( alpha, beta)} cdot 1 [10pt] &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ Gamma( alpha+2) Gamma( beta)}{ Gamma( alpha + beta+2)} quad text{$ therefore Gamma( alpha+1) = alpha Gamma( alpha)$} [10pt] &amp;= frac{ Gamma( alpha + beta)}{ Gamma( alpha) Gamma( beta)} cdot frac{ alpha( alpha+1) Gamma( alpha) Gamma( beta)}{( alpha+ beta+1)( alpha+ beta) Gamma( alpha + beta)} [10pt] &amp;= frac{ alpha( alpha+1)}{( alpha+ beta)( alpha+ beta+1)} end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= frac{ alpha( alpha+1)}{( alpha+ beta)( alpha+ beta+1)} - bigg( frac{ alpha}{ alpha+ beta} bigg)^{2} [10pt] &amp;= frac{ alpha}{ alpha+ beta} bigg( frac{ alpha+1}{ alpha+ beta+1}- frac{ alpha}{ alpha+ beta} bigg) [10pt] &amp;= frac{ alpha}{ alpha+ beta} bigg( frac{( alpha+1)( alpha+ beta)}{( alpha+ beta)( alpha+ beta+1)}- frac{ alpha( alpha+ beta+1)}{( alpha+ beta)( alpha+ beta+1)} bigg) [10pt] &amp;= frac{ alpha}{ alpha+ beta} cdot frac{ beta}{( alpha+ beta)( alpha+ beta+1)} [10pt] &amp;= frac{ alpha beta}{( alpha+ beta)^{2}( alpha+ beta+1)} end{aligned}$ . &#44048;&#47560; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 감마 분포의 확률 밀도 함수: $f(x) = cfrac{1}{ beta^{ alpha} Gamma( alpha)}x^{ alpha - 1}e^{- frac{x}{ beta}},(x, alpha, beta geq 0)$ . - 감마 함수: $ Gamma( alpha) = int_{0}^{ infty}x^{ alpha-1}e^{-x}dx, , alpha geq 0$ . - 감마 함수를 살짝 변형하면 $ int_{0}^{ infty} cfrac{1}{ Gamma( alpha)}x^{ alpha-1}e^{-x}dx = 1$ . - 위의 식을 감마 분포의 적률생성함수를 구하는데 사용할 것임 . - 감마 분포의 적률생성함수 &gt; $t=0$ 근방임을 잊지말자 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{0}^{ infty} frac{1}{ beta^{ alpha} Gamma( alpha)}x^{ alpha - 1}e^{- frac{x}{ beta}}e^{tx} ;dx quad text{$ therefore$ 감마함수의 적분을 이용하기 위해 치환} [10pt] &amp;= frac{1}{ beta^ alpha} int_{0}^{ infty} frac{1}{ Gamma( alpha)}x^{ alpha - 1}e^{ Big(t- frac{1}{ beta} Big)x} ;dx quad text{$ therefore bigg(t- frac{1}{ beta} bigg)x=-y, quad dx= frac{ beta}{1- beta t}dy$} [10pt] &amp;= frac{1}{ beta^ alpha} int_{0}^{ infty} frac{1}{ Gamma( alpha)} bigg( frac{ beta}{1- beta t}y bigg)^{ alpha - 1}e^{-y} frac{ beta}{1- beta t} ;dy quad text{$ therefore x= frac{ beta}{1- beta t}y, ;x=0 to y=0, ;x= infty to y= infty, ; bigg(t&lt; frac{1}{ beta} bigg)$} [10pt] &amp;= frac{1}{ beta^ alpha} bigg( frac{ beta}{1- beta t} bigg)^{ alpha} int_{0}^{ infty} frac{1}{ Gamma( alpha)}y^{ alpha - 1}e^{-y} ;dy quad text{$ therefore int_{0}^{ infty} frac{1}{ Gamma( alpha)}y^{ alpha-1}e^{-y}dy = 1$, 위에 참고} [10pt] &amp;= bigg( frac{1}{1- beta t} bigg)^{ alpha}, quad t&lt; frac{1}{ beta} end{aligned}$ . - 감마 분포의 기댓값 . $ begin{aligned}E(X) =&amp; frac{dM_X(t)}{dt} [10pt] &amp;= alpha bigg( frac{1}{1- beta t} bigg)^{ alpha-1} cdot frac{d}{dt} bigg( frac{1}{1- beta t} bigg) [10pt] &amp;= alpha bigg( frac{1}{1- beta t} bigg)^{ alpha-1} cdot frac{ beta}{(1- beta t)^2} [10pt] &amp;= frac{ alpha beta}{(1- beta t)^{ alpha+1}}, quad text{$t=0$ 대입} [10pt] &amp;= alpha beta end{aligned}$ . . - 감마 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= alpha beta frac{ beta( alpha+1)(1- beta t)^{ alpha}}{(1- beta t)^{2 alpha+2}} [10pt] &amp;= frac{ alpha beta^{2}( alpha+1)}{(1- beta t)^{ alpha+2}}, quad text{$t=0$ 대입} [10pt] &amp;= alpha beta^{2}( alpha+1) end{aligned}$ . $ begin{aligned}Var(X) &amp;= E(X^2) - [E(X)]^2 [10pt] &amp;= alpha beta^{2}( alpha+1) - ( alpha beta)^{2} [10pt] &amp;= alpha beta^{2}( alpha+1)- alpha^2 beta^2 [10pt] &amp;= alpha beta^2 end{aligned}$ . . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 카이제곱 분포의 확률 밀도 함수: $f(x) = dfrac{1}{2^ frac{k}{2} Gamma big( frac{k}{2} big)}x^{ frac{k}{2}-1}e^{- frac{x}{2}}$ . - $k$는 자유도 . - 감마 분포에서 $ alpha= frac{k}{2}, beta = 2$인 경우 카이제곱 분포라고 했음 . - 그렇기에 감마분포의 평균, 분산, 적률생성함수에 $ alpha= frac{k}{2}, beta = 2$를 대입하여 카이제곱 분포의 평균, 분산, 적률생섬함수를 구할 수 있음(내 생각) . - 카이제곱 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= bigg( frac{1}{1- beta t} bigg)^{ alpha}, quad t&lt; frac{1}{ beta}, quad text{$ alpha= frac{k}{2}, ; beta = 2$ 대입} [10pt] &amp;= bigg( frac{1}{1-2t} bigg)^ frac{k}{2} end{aligned}$ . - 카이제곱 분포의 기댓값 . - $E(X) = alpha beta= k, quad text{$ alpha= frac{k}{2}, ; beta = 2$ 대입}$ . - 카이제곱 분포의 분산 . - $Var(X) = alpha beta^2=2k, quad text{$ alpha= frac{k}{2}, ; beta = 2$ 대입}$ . &#51221;&#44508; &#48516;&#54252;&#51032; &#51201;&#47456;&#49373;&#49457;&#54632;&#49688; . - 정규 분포의 확률 밀도 함수: $f(x) = cfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . - 완전제곱식 생성: $x^2-ax= big(x- frac{a}{2} big)^2- frac{a^2}{4}$ . - 정규 분포의 적률생성함수 . $ begin{aligned}M_X(t) &amp;= E(e^{tX}) [10pt] &amp;= int_{- infty}^{ infty}e^{tx} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}} ;dx [10pt] &amp;= int_{- infty}^{ infty} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{x^2-2( mu+ sigma^{2}t)x+ mu^2}{2 sigma^{2}}} ;dx [10pt] &amp;= int_{- infty}^{ infty} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu- sigma^{2}t)^2-( mu+ sigma^2t)^2+ mu^2}{2 sigma^{2}}} ;dx [10pt] &amp;=e^{ mu t+ frac{ sigma^2 t^2}{2}} cdot int_{- infty}^{ infty} frac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu- sigma^{2}t)^2}{2 sigma^2}} ;dx [10pt] &amp;=e^{ mu t+ frac{ sigma^2 t^2}{2}} quad text{$ therefore$ 평균이 $ mu+ sigma^{2}t$이고 표준편차가 $ sigma$인 정규분포이므로 적분값은 $1$} end{aligned}$ . . - 정규 분포의 기댓값 . $ begin{aligned}E(X) &amp;= frac{dM_X(t)}{dt} [10pt] &amp;= ( mu + sigma^2 t)e^{ mu t+ frac{ sigma^2 t^2}{2}}, quad text{$t=0$ 대입} [10pt] &amp;= mu end{aligned}$ . . - 정규 분포의 분산 . $ begin{aligned}E(X^2) &amp;= frac{d^2M_X(t)}{dt^2} [10pt] &amp;= sigma^{2}e^{ mu t+ frac{ sigma^2 t^2}{2}}+( mu+ sigma^2 t)^2e^{ mu t+ frac{ sigma^2 t^2}{2}}, quad text{$t=0$ 대입} [10pt] &amp;= sigma^2+ mu^2 end{aligned}$ . $ begin{aligned}Var(X)&amp;=E(X^2)-[E(X)]^2 [10pt] &amp;= sigma^2+ mu^2-( mu)^2 [10pt] &amp;= sigma^2 end{aligned}$ . .",
            "url": "https://jaesu26.github.io/green/statistics/2021/07/23/%EC%A0%81%EB%A5%A0%EC%83%9D%EC%84%B1%ED%95%A8%EC%88%98.html",
            "relUrl": "/statistics/2021/07/23/%EC%A0%81%EB%A5%A0%EC%83%9D%EC%84%B1%ED%95%A8%EC%88%98.html",
            "date": " • Jul 23, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "동적 계획법",
            "content": "&#46041;&#51201; &#44228;&#54925;&#48277; . - 다이나믹 프로그래밍 참고: 동적 계획법 . - 다이나믹 프로그래밍((Dynamic Programming)으로도 불림 . - 큰 문제를 작은 문제로 나눠서 푸는 방법 . - 분할 정복과 유사하지만.. . 동적 계획법 분할 정복 . 공통점 | 큰 문제를 작은 문제로 나눠서 해결 | 큰 문제를 작은 문제로 나눠서 해결 | . 차이점 | 작은 문제가 반복됨 | 작은 문제가 반복되지 않음 | . - 나중에 분할 정복에 대해서도 다뤄보자 . &#45796;&#51060;&#45208;&#48121; &#54532;&#47196;&#44536;&#47000;&#48141; &#51312;&#44148; . 작은 문제들의 반복 . | 같은 문제는 구할 때마다 정답이 같음 . | &#45796;&#51060;&#45208;&#48121; &#54532;&#47196;&#44536;&#47000;&#48141; &#44396;&#54788; . - 모든 작은 문제는 단 한번만 풀어야 함 . - 정답을 구한 작은 문제는 어딘가에 저장 . - 큰 문제를 해결할 때 미리 구한 작은 문제의 정답을 사용 . 피보나치 수열을 다이나믹 프로그래밍으로 구현해보자 | . Top-down . - 큰 문제를 해결할 때 작은 문제가 해결되지 않았으면 작은 문제를 해결하여 큰 문제를 해결 . - 재귀 함수로 구현하는 경우가 대부분 Top-down 방법 . - 메모이제이션 기법 사용 &gt; 미리 구한 작은 문제의 정답을 어딘가에 저장 . fibonacci = {0:0, 1:1} ## 메모이제이션을 위한 딕셔러니 선언 ## 리스트도 가능 def fibo_top_down(n): if n in fibonacci: return fibonacci[n] fibonacci[n] = fibo_top_down(n-1) + fibo_top_down(n-2) return fibonacci[n] . fibo_top_down(10) . 55 . Bottom-up . - 작은 문제부터 차근차근 해결하여 큰 문제를 해결 . - 반복문 사용 . def fibo_bottom_up1(n): if n &lt;= 1: return n fir_fibo = 0 sec_fibo = 1 for _ in range(n-1): next_fibo = fir_fibo + sec_fibo ## 2번째 피보나치 값 = 0번째 피보나치 값 + 1번째 피보나치 값(n번째 피보나치 값 = n-2번째 피보나치 값 + n-1번째 피보나치 값) fir_fibo = sec_fibo ## 0번째 피보나치 값을 1번째 피보나치 값으로 업데이트 sec_fibo = next_fibo ## 1번째 피보나치 값을 2번째 피보나치 값으로 업데이트 ## 다시 for문 시작으로 돌아가서 1번째 피보나치 값과 2번째 피보나치 값을 통해 3번째 피보나치 값을 구함(이를 n-1번 반복) ## for 문의 역할은 점화식을 통해 0번째와 1번째의 피보나치 값을 가지고 n번째의 피보나치 값을 구한다 return next_fibo . fibo_bottom_up1(10) . 55 . - 또 다른 방법 . - 미리 dp라는 list를 생성 . x = 100 ## 문제 조건에 맞춰서 dp = [-1] * x ## 리스트 초기화 def fibo_bottom_up2(n): ## 굳이 함수를 사용하지 않아도 상관 없음 dp[0] = 0 dp[1] = 1 for i in range(2, n+1): dp[i] = dp[i-1] + dp[i-2] return dp[n] . fibo_bottom_up2(10) . 55 . - bottom-up 방식으로 구현한 위의 두개 코드의 차이점은? . - fibo(9)와 fibo(10)을 구할 때 처음 코드는 fibo_bottom_up1(9)과 fibo_bottom_up1(10) 총 함수를 2번 사용 . - 사실 fibo_bottom_up1(10)을 구했다면 fibo_bottom_up1(9)도 당연히 알지만 각각을 따로 두 번 구했다 . - 첫 번째 코드의 경우 다이나믹 프로그래밍은 이미 구한 작은 문제 정답은 또 구하지 않기로 했지만 그렇지 않은 모습 . - 하지만 두 번째 코드는 fibo_bottom_up2(10)을 구했다면 $ text{dp[0] ~ dp[10]}$까지 값이 채워져 있기에 fibo_bottom_up2(9)를 하지 않고 $ text{dp[9]}$를 통해 fibo(9)를 구할 수 있음 . - 하지만 공간복잡도(메모리 사용) 측면으로 보면 첫 번째 코드가 두 번째 코드보다 메모리를 덜 잡아먹는다(두 번째 코드는 충분히 큰 배열이 필요함) . - 결론: 상황에 맞게 사용하자 .",
            "url": "https://jaesu26.github.io/green/python/algorithm/2021/07/19/%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "relUrl": "/python/algorithm/2021/07/19/%EB%8B%A4%EC%9D%B4%EB%82%98%EB%AF%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
            "date": " • Jul 19, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "파이썬 기본 연산 시간 복잡도(Big O)",
            "content": "&#49884;&#44036; &#48373;&#51105;&#46020; . - 컴퓨터 프로그램의 입력값과 연산 수행 시간의 함수 관계 . - 보통 Big O 표기법으로 나타냄 . Big O &#54364;&#44592;&#48277; . - 알고리즘의 시간 복잡도를 나타내는 척도 . - 두 함수 $f$와 $g ,(g&gt;0)$에 대해 상수 $k&lt; infty$가 존재해서 $x in A subset mathbb{R}$인 $x$에 대하여 $ left| frac{f(x)}{g(x)} right|&lt;K$이면 $f(x)=O(g(x))$임 . - 쉽게 말하면 $f$는 $g$로부터 일정수준 이상 벗어날 수 없다는 뜻($f$나 $g$나 비슷비슷하다) . - $f(x) = 2x, ,g(x) = x$이면 $ left| frac{f(x)}{g(x)} right| = 2&lt; infty$이므로 $f(x) = O(g(x))$임 &gt; $f$나 $g$나 비슷함 . - 만약 $h(x) = x^2$이면 $ left| frac{h(x)}{g(x)} right| = |x|$이고 $x to infty$이면 $ left| frac{h(x)}{g(x)} right| to infty$이므로 $h(x) neq O(g(x))$임 &gt; $h$와 $g$는 급이 다름 . &#50672;&#49328; &#49884;&#44036; &#48373;&#51105;&#46020; . - 자료형별 연산의 시간 복잡도를 나타내자 . &#47532;&#49828;&#53944;(list) . - l은 리스트(list) . - k는 상수 . - 참고: 파이썬 자료형별 연산 시간 복잡도 . Operation Example Complexity Class Notes . index | l[n] | $O(1)$ | | . store | l[n] = 0 | $O(1)$ | store는 변수 저장 | . length | len(l) | $O(1)$ | | . append | l.append(5) | $O(1)$ | | . pop | l.pop() | $O(1)$ | same as l.pop(-1) | . clear | l.clear() | $O(1)$ | similar to l = [] | . slice | l[a:b] | $O(b-a)$ | $l[1:5] to O(l)$, $l[ ; ; : ; ; ] to O(len(l)-0)=O(N)$ | . extend | l.extend(...) | $O(len( dots))$ | depends only on len of extension | . construction | list(...) | $O(len( dots))$ | depends on length of ... iterable | . check ==, != | l1 == l2 | $O(N)$ | | . insert | l[a:b] = ... | $O(N)$ | | . delete | del l[n] | $O(N)$ | depends on $n$; $O(N)$ in worst case | . containment | x in/not in l | $O(N)$ | linearly searches list | . copy | l.copy() | $O(N)$ | Same as $l[ ; ;: ; ;]$ which is $O(N)$ | . remove | l.remove(...) | $O(N)$ | | . pop | l.pop(n) | $O(N)$ | $O(N-i)$: l.pop(0): $O(N)$ (see above) | . extreme value | min(l)/max(l) | $O(N)$ | linearly searches list for value | . reverse | l.reverse() | $O(N)$ | | . iteration | for v in l: | $O(N)$ | Worst: no return/break in loop | . sort | l.sort() | $O(N Log N)$ | key/reverse mostly does not change | . multiply | $k times l$ | $O(kN)$ | $5 times l$ is $O(N)$: $len(l) times l$ is $O(N^2)$ | . &#51665;&#54633;(set) . - 리스트에 비해 시간 복잡도가 작음 . Operation Example Complexity Class Notes . Length | len(s) | $O(1)$ | | . Add | s.add(5) | $O(1)$ | | . Containment | x in/not in s | $O(1)$ | compare to list/tuple - $O(N)$ | . Remove | s.remove(..) | $O(1)$ | compare to list/tuple - $O(N)$ | . Discard | s.discard(..) | $O(1)$ | | . Pop | s.pop() | $O(1)$ | popped value &quot;randomly&quot; selected | . Clear | s.clear() | $O(1)$ | similar to s = set() | . Construction | set(...) | $O(len(...))$ | depends on length of ... iterable | . check ==, != | s != t | $O(len(s))$ | same as $len(t)$; False in $O(1)$ if the lengths are different | . &lt;=/&lt; | s &lt;= t | $O(len(s))$ | issubset | . &gt;=/&gt; | s &gt;= t | $O(len(t))$ | issuperset s &lt;= t == t &gt;= s | . Union | s | t | $O(len(s)$+$len(t))$ | | . Intersection | s &amp; t | $O(len(s)$+$len(t))$ | | . Difference | s - t | $O(len(s)$+$len(t))$ | | . Symmetric Diff | s ^ t | $O(len(s)$+$len(t))$ | | . Iteration | for v in s: | $O(N)$ | Worst: no return/break in loop | . Copy | s.copy() | $O(N)$ | | . &#54644;&#49884;(dictionary) . - 시간 복잡도가 대부분 $O(1)$이다 . - 같은 함수라면 리스트 대신 딕셔너리를 사용하는 것이 시간 복잡도 면에서 우월함 . Operation Example Complexity Class Notes . Index | d[k] | $O(1)$ | | . Store | d[k] = v | $O(1)$ | | . Length | len(d) | $O(1)$ | | . Delete | del d[k] | $O(1)$ | | . get/setdefault | d.get(k) | $O(1)$ | | . Pop | d.pop(k) | $O(1)$ | | . Pop item | d.popitem() | $O(1)$ | popped item &quot;randomly&quot; selected | . Clear | d.clear() | $O(1)$ | similar to s = {} or = dict() | . View | d.keys() | $O(1)$ | same for d.values() | . Construction | dict(...) | $O(len(...))$ | depends # (key,value) 2-tuples | . Iteration | for k in d: | $O(N)$ | all forms: keys, values, items, Worst: no return/break in loop | .",
            "url": "https://jaesu26.github.io/green/python/algorithm/2021/07/15/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B8%B0%EB%B3%B8%EC%97%B0%EC%82%B0-%EC%8B%9C%EA%B0%84%EB%B3%B5%EC%9E%A1%EB%8F%84.html",
            "relUrl": "/python/algorithm/2021/07/15/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B8%B0%EB%B3%B8%EC%97%B0%EC%82%B0-%EC%8B%9C%EA%B0%84%EB%B3%B5%EC%9E%A1%EB%8F%84.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "문자열 처리",
            "content": "format &#54632;&#49688; . - 문자열을 포매팅(formatting)하는데 사용 . - 포매팅: 문자열의 원하는 위치에 특정 변수를 삽입 . - 아래 예제를 보자 . &#39;이름:{},나이:{},성별:{}&#39;.format(&#39;홍길동&#39;,&#39;21&#39;,&#39;남&#39;) . &#39;이름:홍길동,나이:21,성별:남&#39; . - 순서대로 홍길동, 21, 남이 {}에 삽입됨 . - 구구단도 쉽게 출력할 수 있음 . i = 2 for j in range(1, 10): print(&#39;{} X {} = {}&#39;.format(i, j, i*j)) . 2 X 1 = 2 2 X 2 = 4 2 X 3 = 6 2 X 4 = 8 2 X 5 = 10 2 X 6 = 12 2 X 7 = 14 2 X 8 = 16 2 X 9 = 18 . [$ star$]&#49548;&#49688;&#51216; &#51088;&#47551;&#49688; &#54364;&#54788;[$ star$] . - 알고리즘 문제를 풀다보면 특정 소수점 자릿수까지 출력을 요구할 때가 있음 . - 계산 결과를 소수점 셋째 자리 까지 표현하려면? . a = 10 b = 3 a / b . 3.3333333333333335 . - 소수점 셋째 짜리 까지 표현하고 싶음 . - format 함수 사용! . a = 10 b = 3 print(&#39;{:.3f}&#39;.format(a / b)) . 3.333 . - round 함수도 되는데? . - round(x, a) --&gt; x를 소수점 a번째 까지 나타냄 . a = 10 b = 3 round(a / b, 3) . 3.333 . - 아래와 같은 경우는? . a = 10 b = 2 a / b . 5.0 . - format 함수 . a = 10 b = 2 print(&#39;{:.3f}&#39;.format(a / b)) . 5.000 . - round 함수 . a = 10 b = 2 round(a / b, 3) . 5.0 . - format 함수는 소수점 셋째 자리까지 나타낸 반면 round 함수는 첫째 자리까지 나타냄 . round 함수를 사용할 때 주의할 점 | . - 파이썬에서는 사사오입의 원칙을 따라 반올림할 자리가 5이면 반올림을 할 때 짝수면 내림, 홀수면 올림 한다 . round(2.5) . 2 . round(-1.5) . -2 . - 오사오입의 원칙으로 반올림 하려면? --&gt; 함수를 따로 만들자 . def round2(number): if number &gt;= 0: if number - int(number) &gt;= 0.5: a = 1 else: a = 0 return int(number) + a else: if int(number) - number &gt; 0.5: a = -1 else: a = 0 return int(number) + a . round2(2.5) . 3 . round2(-1.5) . -1 . - 사사오입의 원칙으로 반올림을 하는 이유는 데이터의 대부분이 .5로 끝나는 자료라면 이를 반올림하면 0.5만큼의 오차가 생기기 때문 . 결론: 원하는 자릿수 까지 나타내려면 round 함수 대신 format 함수를 쓰자 | . join &#54632;&#49688; . - 문자열로 이루어진 리스트를 기준 문자열로 합쳐 문자열로 만듦 . - &#39;구분자&#39;.join(list) . - 구분자에는 문자열, list에는 문자열을 원소로 가지는 리스트가 들어감 . a = [&#39;12&#39;, &#39;45&#39;, &#39;48&#39;] . &#39;-&#39;.join(a) . &#39;12-45-48&#39; . &#39;&#39;.join(a) . &#39;124548&#39; . replace &#54632;&#49688; . - 특정 문자를 다른 문자로 대체 . - &#39;문자열&#39;.replace(&#39;기존 문자&#39;, &#39;바꿀 문자&#39;) . a = &#39;hello world&#39; . a.replace(&#39;h&#39;, &#39;H&#39;) . &#39;Hello world&#39; . a.replace(&#39;&#39;, &#39;!&#39;) . &#39;!h!e!l!l!o! !w!o!r!l!d!&#39; . - 문자열에서는 빈칸도 하나의 문자로 취급 . split &#54632;&#49688; . - 문자열을 구분자를 기준으로 쪼갬 . - &#39;문자열&#39;.split(&#39;구분자&#39;) . a = &#39;!h!e!l!l!o! !w!o!r!l!d!&#39; . a.split(&#39;!&#39;) . [&#39;&#39;, &#39;h&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;, &#39;o&#39;, &#39; &#39;, &#39;w&#39;, &#39;o&#39;, &#39;r&#39;, &#39;l&#39;, &#39;d&#39;, &#39;&#39;] . upper &#54632;&#49688; . - 문자열에서 모든 소문자를 대문자로 바꿈 . - &#39;문자열&#39;.upper(&#39;구분자&#39;) . a = &#39;hello world&#39; . a.upper() . &#39;HELLO WORLD&#39; . str.isupper() . - str이 대문자로만 이루어져 있으면 True를 아니면 False를 반환 . string = &#39;ABC&#39; string2 = &#39;AbC&#39; . string.isupper() . True . string2.isupper() . False . lower &#54632;&#49688; . - 문자열에서 모든 대문자를 소문자로 바꿈 . - &#39;문자열&#39;.lower(&#39;구분자&#39;) . a = &#39;HELLO WORLD&#39; . a.lower() . &#39;hello world&#39; . str.islower() . - str이 소문자로만 이루어져 있으면 True를 아니면 False를 반환 . string = &#39;abc&#39; string2 = &#39;aBc&#39; . string.islower() . True . string2.islower() . False . count &#54632;&#49688; . - 문자열에서 특정 문자 or 문자열의 개수를 반환함 . - &#39;문자열&#39;.count(&#39;찾는 문자&#39;, 시작 인덱스, 끝 인덱스) . - 시작 인덱스 $ leq$ 문자열 $&lt;$ 끝 인덱스 . a = &#39;HELLO WORLD&#39; . a.count(&#39;L&#39;) . 3 . a.count(&#39;L&#39;, 0, 9) . 2 . a.count(&#39;L&#39;, 0, 10) . 3 . chr &#54632;&#49688; . - 아스키 코드를 문자로 변환함 . - chr(아스키코드) . - 아스키 코드 참고: https://ko.wikipedia.org/wiki/ASCII . chr(65) . &#39;A&#39; . ord &#54632;&#49688; . - 문자를 아스키 코드로 변환함 . - ord(&#39;문자&#39;) . ord(&#39;A&#39;) . 65 .",
            "url": "https://jaesu26.github.io/green/python/2021/07/09/%EB%AC%B8%EC%9E%90%EC%97%B4-%ED%95%A8%EC%88%98.html",
            "relUrl": "/python/2021/07/09/%EB%AC%B8%EC%9E%90%EC%97%B4-%ED%95%A8%EC%88%98.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "그리디 알고리즘",
            "content": "&#44536;&#47532;&#46356; &#50508;&#44256;&#47532;&#51608;(&#50837;&#49900;&#51137;&#51060; &#50508;&#44256;&#47532;&#51608;, Greedy Algorithm)&#51060;&#46976;? . - 다이나믹 프로그래밍이 모든 경우를 확인 한다는 점에서 고안된 알고리즘 . - 매 선택마다 가장 최적인 답을 선택하여 결론을 도출 --&gt; 알파고: 자신 차례마다 가장 승률이 높은 수를 선택 . - but, 매 선택마다 최적이지만 결과가 최적이라는 보장 없음 . - 마시멜로 실험: 당장은 1개, 기다리면 2개 --&gt; 최적해: 기다리고 2개 먹기 . - 하지만 그리디 알고리즘은 지금 최적의 선택인 1개를 선택 --&gt; 최적해 아님 . &#44536;&#47084;&#47732; &#50612;&#46500; &#44221;&#50864;&#50640; &#51096; &#46041;&#51089;&#54616;&#45716;&#44032;? . - 탐욕 선택 속성(greedy choice property): 한번의 선택이 다음 선택과는 무관 . - 최적 부분 구조(optimal substructure): 매 순간의 최적해 --&gt; 문제에 대한 최적해 . &#44536;&#47532;&#46356; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . - 백준 - 설탕 배달: https://www.acmicpc.net/problem/2839 . - 설탕 N kg을 3kg, 5kg봉지에 담아야 하는데 봉지의 수를 최소화 . 최적 부분 구조: 매 순간 봉지의 수를 최소화하려는 행위(3kg 봉지 보다 5kg 봉지 사용)는 문제에 대한 최적해(봉지의 수 최소화) . | 탐욕 선택 속성: 전에 5kg 봉지를 선택하든 3kg 봉지를 선택하든 상관없이 현재 남아있는 무게를 가지고만 판단하여 선택 . | - 그리디 알고리즘: 5kg 봉지로만 담는 것이 최선 . - 만약 5kg 봉지로만 담는 것이 불가능하면? . - 5kg 봉지를 하나 줄이고 3kg 봉지를 사용함 . - 이를 반복함 --&gt; 만약 담는 것이 불가능하면 -1 return . 설탕 배달(그리디 알고리즘) | . - 설탕의 무게는 N kg . 5kg 봉지 선택(최적 판단) . | 5kg 봉지 선택(최적 판단) . | 5kg 봉지만 계속 선택 --&gt; total: k 번 선택(최적 판단) . | 만약 남은 무게가 예컨데 4kg 이라 5kg 봉지에 담지 못한다면 3kg 선택(최적 판단) . | 3kg 에 담고나면 1kg 이 남음 --&gt; 어느 봉지에도 담지 못함 . | 5kg 봉지를 k - 1번 선택하고 3kg 봉지를 선택 . | 5kg 봉지를 0번 선택할 때 까지 반복 --&gt; 이 경우에도 답이 없다면 해가 존재하지 않음 . | N = int(input()) def sugar(n): k = n // 5 l = n % 5 for i in range(k+1): if l == 0: return k break elif l % 3 == 0: return k + l // 3 break else: l += 5 k -= 1 return -1 print(sugar(N)) . 21 . - 설탕 무게가 101kg 일시 5kg 19개, 3kg 2개를 선택 .",
            "url": "https://jaesu26.github.io/green/python/algorithm/2021/07/09/%EA%B7%B8%EB%A6%AC%EB%94%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "relUrl": "/python/algorithm/2021/07/09/%EA%B7%B8%EB%A6%AC%EB%94%94-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "DFS와 BFS 알고리즘",
            "content": "&#44618;&#51060; &#50864;&#49440; &#53456;&#49353;(Depth First Search, DFS) . - 모든 정점을 한번만 방문 . - 시작 노드에서 다음 분기로 넘어가기 전에 해당 분기를 완벽하게 탐색 . - 방문할 노드와 방문한 노드를 기준으로 탐색 . - 특정 노드가 방문할 노드 --&gt; 탐색, 방문한 노드 --&gt; 지나감 . - 그래프나 트리는 dictionary로 생성 . - stack 구조 와 재귀 함수로 구현 가능 . DFS &#51109;&#51216; . - 단지 현 경로상의 노드들만을 기억하면 되므로 저장공간의 수요가 비교적 적음 . - 목표노드가 깊은 단계에 있을 경우 해를 빨리 구함 . DFS &#45800;&#51216; . - 해가 없는 경로에 깊이 빠질 가능성 존재 . - 얻어진 해가 최단 경로가 된다는 보장이 없음 --&gt; 목표에 이르는 경로가 다수일 때 해에 다다르면 탐색을 끝내버림 --&gt; 이때 얻어진 해는 최적이 아닐 수 있음 . DFS 참고: 깊이 우선 탐색 | . DFS &#53076;&#46300; &#44396;&#54788; . - tree 구조 . - stack 자료 구조 활용: 후입선출(한쪽면이 막힌 원통) . - 노드: [A], [B], [C], [D], [E], [F], [G], [H], [I], [J] . - 분기: [A, B, E], [A, B, F, I], [A, C, G], [A, D, H, I] . tree = {&#39;A&#39;: [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;], ## A는 B, C, D와 연결됨 &#39;B&#39;: [&#39;A&#39;, &#39;E&#39;, &#39;F&#39;], ## B는 A, E, F와 연결됨 &#39;C&#39;: [&#39;A&#39;, &#39;G&#39;], ## C는 A, G와 연결됨 &#39;D&#39;: [&#39;A&#39;, &#39;H&#39;], ## D는 A, H와 연결됨 &#39;E&#39;: [&#39;B&#39;], ## E는 B와 연결됨 &#39;F&#39;: [&#39;B&#39;, &#39;I&#39;], ## F는 B, I와 연결됨 &#39;G&#39;: [&#39;C&#39;], ## G는 C와 연결됨 &#39;H&#39;: [&#39;D&#39;, &#39;J&#39;], ## H는 D, J와 연결됨 &#39;I&#39;: [&#39;F&#39;], ## I는 F와 연결됨 &#39;J&#39;: [&#39;H&#39;]} ## J는 H와 연결됨 . &#47532;&#49828;&#53944; &#54876;&#50857; . - 파이썬에서 리스트는 stack구조여서 DFS에 활용 가능 . - list.pop(i)은 성능이 떨어짐, i번째 이후 원소들을 한 칸씩 앞으로 땡겨야하기 때문 --&gt; $O(N)$ . - 비고: $O(N-i) to O(N)$ 최악의 경우(0번째 인덱스) . - list.pop()은 마지막 원소만 pop하므로 $O(1)$ . - list.pop()--&gt; 맨 마지막에 넣었던 노드를 가져옴: stack구조와 동일(후입선출) . def DFS_list(graph, start_node): visited = [] ## 방문한 노드 stack = [] ## 방문할 노드 stack.append(start_node) ## 방문할 노드에 시작 노드 추가 while stack: ## 방문할 노드가 있다면(리스트에 원소가 있으면 True) node = stack.pop() ## 마지막 노드 추가(스택 구조 사용) if node not in visited: ## 만약 아직 방문한 노드가 아니라면 visited.append(node) ## 이제 방문했으니까 방문한 노드에 추가 stack.extend(reversed(graph[node])) ## 방문한 노드에 연결된 노드를 탐색해보자 print(visited) print(stack) print(&#39;-&#39;) ## 방문과정 확인 return visited ## 방문한 노드를 반환 DFS_list(tree, &#39;A&#39;) ## 마지막은 return 값 . [&#39;A&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;B&#39;] - [&#39;A&#39;, &#39;B&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;, &#39;E&#39;, &#39;A&#39;] - [&#39;A&#39;, &#39;B&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;, &#39;E&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;, &#39;B&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;I&#39;, &#39;B&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;I&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;] [&#39;D&#39;, &#39;C&#39;, &#39;F&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;] [&#39;D&#39;, &#39;C&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;] [&#39;D&#39;, &#39;G&#39;, &#39;A&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;] [&#39;D&#39;, &#39;G&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;] [&#39;D&#39;, &#39;C&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;] [&#39;D&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;] [&#39;H&#39;, &#39;A&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;] [&#39;H&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;] [&#39;J&#39;, &#39;D&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;] [&#39;J&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] [&#39;H&#39;] - [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] [] - . [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] . - return 결과를 보면 DFS 방식임을 알 수 있다 . &#54644;&#49884; &#53580;&#51060;&#48660; &#54876;&#50857; . - if node not in visited: --&gt; visited가 list인 경우 $O(N)$의 시간복잡도를 가짐 . - visited도 해시 테이블(key: value 관계인 자료형: 파이썬의 dictionary)로 구현하면 $O(1)$로 효율$ uparrow$ . - 해시 테이블에 관한 좋은 영상 &gt; https://www.youtube.com/watch?v=HraOg7W3VAM . def DFS_Hash_Table(graph, start_node): visited = {} ## 방문한 노드 stack = [] ## 방문할 노드 stack.append(start_node) ## 방문할 노드에 시작 노드 추가 while stack: ## 방문할 노드가 있다면(리스트에 원소가 있으면 True) node = stack.pop() ## 마지막 노드 추가(스택 구조 사용) if node not in visited: ## 만약 아직 방문한 노드가 아니라면 visited[node] = True ## 이제 방문했으니까 방문한 노드에 추가 stack.extend(reversed(graph[node])) ## 방문한 노드에 연결된 노드를 탐색해보자 return list(visited.keys()) ## 방문한 노드를 반환 DFS_list(tree, &#39;A&#39;) ## 마지막은 return 값 . [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] . - list를 활용한 코드와 return 결과는 동일하다 . - 시간복잡도면에서 list를 활용한 것 보다 Hash Table을 사용한 것이 성능이 우월하다 . - return 결과를 보면 DFS 방식임을 알 수 있다 . &#51116;&#44480;&#54632;&#49688; &#54876;&#50857; . def DFS_recursive(graph, start_node, visited = {}): visited[start_node] = True for node in graph[start_node]: if node not in visited: DFS_recursive(graph, node, visited) ## 간단히 설명 -&gt; 처음 시작 노드는 &#39;A&#39; -&gt; &#39;A&#39;를 visited에 추가 &#39;A&#39;의 node는 [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;] ## -&gt; &#39;B&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;B&#39;를 start_node로 하여 visited에 추가 -&gt;&#39;B&#39;의 node는 [&#39;A&#39;, E&#39;, &#39;F&#39;] ## -&gt; &#39;A&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;E&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;E&#39;를 start_node로 하여 visited에 추가 -&gt; &#39;E&#39;의 node는 [&#39;B&#39;] ## -&gt; &#39;B&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;B&#39;의 node로 &#39;A&#39;, &#39;E&#39; 방문 했고 이제 &#39;F&#39;만 남았음 ## -&gt; &#39;F&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;F&#39;를 start_node로 하여 visited에 추가 -&gt; &#39;F&#39;의 node는 [&#39;B&#39;, &#39;I&#39;] ## -&gt; &#39;B&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;I&#39;는 아직 방문 안했음 -&gt; 재귀함수 실행 -&gt; &#39;I&#39;를 start_node로 하여 visited에 추가 -&gt; &#39;I&#39;의 node는 [F] ## -&gt; &#39;F&#39;는 이미 방문했음 -&gt; pass ## -&gt; &#39;A&#39;의 node인 [&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]중 &#39;B&#39;를 방문 끝냈으므로 &#39;B&#39;를 탐색했던 것처럼 나머지 &#39;C&#39;와 &#39;D&#39;도 탐색하면 끝임 return list(visited.keys()) DFS_recursive(tree, &#39;A&#39;) . [&#39;A&#39;, &#39;B&#39;, &#39;E&#39;, &#39;F&#39;, &#39;I&#39;, &#39;C&#39;, &#39;G&#39;, &#39;D&#39;, &#39;H&#39;, &#39;J&#39;] . - 재귀함수를 사용하여 방문한 노드를 visited에 추가한다 . - return 결과를 보면 DFS 방식임을 알 수 있다 . &#45320;&#48708; &#50864;&#49440; &#53456;&#49353;(Breadth First Search, BFS) . - 모든 정점을 한번만 방문 . - 시작 노드에서 인접한 다음 분기로 넘어가면서 탐색 . - 넘어갈 분기가 없으면 하위 노드를 탐색 . - 방문할 노드와 방문한 노드를 기준으로 탐색 . - 특정 노드가 방문할 노드 --&gt; 탐색, 방문한 노드 --&gt; 지나감 . - 그래프나 트리는 dictionary로 생성 . - queue 구조로 구현 가능 . BFS &#51109;&#51216; . - 출발노드에서 목표노드까지의 최단 길이 경로를 보장 . BFS &#45800;&#51216; . - 경로가 매우 길 경우에는 탐색 가지가 급격히 증가함에 따라 보다 많은 기억 공간을 필요 . - 해가 존재하지 않는다면 유한 그래프(finite graph)의 경우에는 모든 그래프를 탐색한 후에 실패로 끝남 . - 무한 그래프(infinite graph)의 경우에는 결코 해를 찾지도 못하고, 끝내지도 못함 . BFS 참고: 너비 우선 탐색 | . BFS &#53076;&#46300; &#44396;&#54788; . - tree 구조 . - queue 자료 구조 활용: 선입선출(양쪽 면이 뚫린 원통) . - 노드: [A], [B], [C], [D], [E], [F], [G], [H], [I], [J] . - 분기: [A, B, E], [A, B, F, I], [A, C, G], [A, D, H, I] . deque &#54876;&#50857; . - 성능이 좋음 --&gt; $O(1)$ . - 사용: from collections import deque . - 만약 queue = list()라면 queue.pop(0)을 해야함 --&gt; $O(N)$ . - deque를 사용하여 queue.pop(0)대신 queue.popleft( ) 사용 --&gt; $O(1)$ . - DFS와 마찬가지로 visited는 해시 테이블로 구현 . def BFS_queue(graph, start_node): from collections import deque ## deque패키지 import visited = {} ## 방문한 노드 queue = deque() ## 방문할 노드 queue.append(start_node) ## 방문할 노드에 시작 노드 추가 while queue: ## 방문할 노드가 있다면(리스트에 원소가 있으면 True) node = queue.popleft() ## 첫번째 노드 추가(큐 구조 사용) if node not in visited: ## 만약 아직 방문한 노드가 아니라면 visited[node] = True ## 이제 방문했으니까 방문한 노드에 추가 queue.extend(graph[node]) ## 방문한 노드에 연결된 노드를 탐색해보자 print(list(visited.keys())) print(queue) print(&#39;-&#39;) ## 방문과정 확인 return list(visited.keys()) ## 방문한 노드를 반환 BFS_queue(tree, &#39;A&#39;) . [&#39;A&#39;] deque([&#39;B&#39;, &#39;C&#39;, &#39;D&#39;]) - [&#39;A&#39;, &#39;B&#39;] deque([&#39;C&#39;, &#39;D&#39;, &#39;A&#39;, &#39;E&#39;, &#39;F&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] deque([&#39;D&#39;, &#39;A&#39;, &#39;E&#39;, &#39;F&#39;, &#39;A&#39;, &#39;G&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;] deque([&#39;A&#39;, &#39;E&#39;, &#39;F&#39;, &#39;A&#39;, &#39;G&#39;, &#39;A&#39;, &#39;H&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;] deque([&#39;E&#39;, &#39;F&#39;, &#39;A&#39;, &#39;G&#39;, &#39;A&#39;, &#39;H&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;] deque([&#39;F&#39;, &#39;A&#39;, &#39;G&#39;, &#39;A&#39;, &#39;H&#39;, &#39;B&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;] deque([&#39;A&#39;, &#39;G&#39;, &#39;A&#39;, &#39;H&#39;, &#39;B&#39;, &#39;B&#39;, &#39;I&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;] deque([&#39;G&#39;, &#39;A&#39;, &#39;H&#39;, &#39;B&#39;, &#39;B&#39;, &#39;I&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;] deque([&#39;A&#39;, &#39;H&#39;, &#39;B&#39;, &#39;B&#39;, &#39;I&#39;, &#39;C&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;] deque([&#39;H&#39;, &#39;B&#39;, &#39;B&#39;, &#39;I&#39;, &#39;C&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;] deque([&#39;B&#39;, &#39;B&#39;, &#39;I&#39;, &#39;C&#39;, &#39;D&#39;, &#39;J&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;] deque([&#39;B&#39;, &#39;I&#39;, &#39;C&#39;, &#39;D&#39;, &#39;J&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;] deque([&#39;I&#39;, &#39;C&#39;, &#39;D&#39;, &#39;J&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;] deque([&#39;C&#39;, &#39;D&#39;, &#39;J&#39;, &#39;F&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;] deque([&#39;D&#39;, &#39;J&#39;, &#39;F&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;] deque([&#39;J&#39;, &#39;F&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;] deque([&#39;F&#39;, &#39;H&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;] deque([&#39;H&#39;]) - [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;] deque([]) - . [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;] . - return 결과를 보면 BFS 방식임을 알 수 있다 .",
            "url": "https://jaesu26.github.io/green/python/algorithm/2021/07/09/DFS-BFS.html",
            "relUrl": "/python/algorithm/2021/07/09/DFS-BFS.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "정렬 알고리즘",
            "content": "- 데이터를 오름차순으로 정렬해보자! . $O(N^2)$ &#51221;&#47148; . &#49440;&#53469; &#51221;&#47148; . - 가장 작은 수를 첫 번째 인덱스로 선택 그 다음으로 작은 수를 두 번째 인덱스로 선택 . - 이런식으로 가장 큰 수까지 마지막 인덱스로 선택하면 정렬 끝 . &#49440;&#53469; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2] . 2 첫 번째 인덱스와 나머지 $n - 1$개의 수를 비교하여 가장 작은 수와 위치를 바꾼다 . 3 5와 비교하여 1이 가장 작으므로 5와 1의 위치를 바꾼다 . List = [1, 8, 7, 5, 2] . 4 이제 두 번째 인덱스와 나머지$n - 2$개의 수를 비교하여 남은 수 중 가장 작은 수와 위치를 바꾼다 . 5 8과 비교하여 2가 가장 작으므로 8과 2의 위치를 바꾼다 . List = [1, 2, 7, 5, 8] . 6 이런 식으로 $n-1$번째 인덱스와 나머지 1개의 수를 비교하여 오름차순 정렬을 마친다 . List = [1, 2, 5, 7, 8] . &#49440;&#53469; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 2] n = len(List) for i in range(n - 1): min_idx = i for j in range(i + 1, n): if List[j] &lt; List[min_idx]: min_idx = j List[i], List[min_idx] = List[min_idx], List[i] print(List) . [1, 8, 7, 5, 2] [1, 2, 7, 5, 8] [1, 2, 5, 7, 8] [1, 2, 5, 7, 8] . &#48260;&#48660; &#51221;&#47148; . - 연속된 인덱스를 비교하여 더 큰 값을 오른쪽으로 보냄 . - 한 사이클을 돌면 가장 큰 값이 맨 뒤에 위치 . - 사이클마다 남은 수 중 가장 큰 값이 뒤에 위치함 . &#48260;&#48660; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2] . 2 첫 번째 인덱스와 두 번째 인덱스를 비교하여 더 큰값을 오른쪽에 위치시킨다 . 3 5와 8을 비교하면 8이 더 크므로 8을 오른쪽을 보낸다 . List = [5, 8, 7, 1, 2] . 4 이제 두 번째 인덱스와 세 번째 인덱스를 비교한다 . 5 8과 7을 비교하면 8이 더 크므로 8을 오른쪽으로 보낸다 . List = [5, 7, 8, 1, 2] . 6 이런식으로 한 사이클을 돌면 8이 마지막에 위치한다 . List = [5, 7, 1, 2, 8] . 7 다시 사이클을 돌면 7이 8 왼쪽에 위치한다 . List = [5, 1, 2, 7, 8] . 8 이런식으로 $n - 1$ 번의 사이클을 돌면 자료가 오름차순으로 정렬된다 . List = [1, 2, 5, 7 ,8] . &#48260;&#48660; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 2] n = len(List) for i in range(n - 1, 0, -1): for j in range(i): if List[j + 1] &lt; List[j]: List[j + 1], List[j] = List[j], List[j + 1] print(List) . [5, 7, 1, 2, 8] [5, 1, 2, 7, 8] [1, 2, 5, 7, 8] [1, 2, 5, 7, 8] . &#49341;&#51077; &#51221;&#47148; . - 자료 배열의 모든 요소를 앞에서부터 차례대로 이미 정렬된 배열 부분과 비교함 . - 자신의 위치를 찾아 삽입함 . - 일반적으로 선택 정렬, 버블 정렬 보다 빠름 . &#49341;&#51077; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2] . 2 두 번째 원소를 부분 리스트에서 적절한 위치에 삽입 . List = [5, 8, 7, 1, 2] . 3 5와 8을 비교하면 8이 더 크므로 8을 오른쪽을 보낸다 . List = [5, 8, 7, 1, 2] . 4 세 번째 원소를 부분 리스트에서 적절한 위치에 삽입 . 5 7과 8을 비교하면 8이 더 크고 5와 7을 비교하면 7이 더 크므로 5와 8사이에 위치한다 . List = [5, 7, 8, 1, 2] . 6 네 번째 원소를 부분 리스트에서 적절한 위치에 삽입 . 7 1이 부분 리스트 중 가장 작으므로 맨 앞에 삽입 . List = [1, 5, 7, 8, 2] . 8 마지막 원소를 부분 리스트에서 적절한 위치에 삽입 . 9 2는 부분 리스트 중 1 다음으로 작으므로 1 오른쪽에 삽입 . List = [1, 2, 5, 7, 8] . &#49341;&#51077; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 2] n = len(List) for i in range(1, n): j = i - 1 key = List[i] while List[j] &gt; key and j &gt;= 0: List[j+1] = List[j] j = j - 1 List[j+1] = key print(List) . [5, 8, 7, 1, 2] [5, 7, 8, 1, 2] [1, 5, 7, 8, 2] [1, 2, 5, 7, 8] . $O(NlogN)$ &#51221;&#47148; . &#48337;&#54633; &#51221;&#47148; . - 리스트 안에 있는 요소들을 왼쪽, 오른쪽 두 그룹으로 나눔 . - 각 그룹을 또 왼쪽, 오른쪽 두 그룹으로 나눔, 이를 요소가 1개 남을 때까지 반복함 . - 나누어진 두 개의 리스트를 병합함 . - 이를 정렬될 때까지 반복함 . &#48337;&#54633; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 2, 3, 9, 4] . 2 그룹을 두 그룹으로 나눈다 . [5, 8, 7, 1], [2, 3, 9, 4] . 3 각 그룹을 두 그룹으로 나눈다 . [5, 8], [7, 1], [2, 3], [9, 4] . 4 이를 요소가 1개 남을 때까지 반복한다 . [5], [8], [7], [1], [2], [3], [9], [4] . 5 이제 나눈 순서의 역순으로 두 그룹씩 오름차순으로 병합한다 . [5, 8], [1, 7], [2, 3], [4, 9] . 6 이를 정렬이 끝날 때까지 반복한다 . [1, 5, 7, 8], [2, 3, 4, 9] . List = [1, 2, 3, 4, 5, 7, 8, 9] . &#48337;&#54633; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . - 위의 병합 정렬 알고리즘을 보면 두 그룹으로 나누고 병합하는 과정을 반복한다 . - 그렇기에 재귀 함수를 사용하여 구현했음 --&gt; 리스트의 길이가 클 경우 많은 재귀 함수 호출이 이루어지기에 시간이 매우 오래걸림(내 생각) . - 먼저 left, right로 나눈 후 나눠진 left를 가지고 또 left, right로 나눈다 . - left를 나누는 것이 끝나면 이제서야 right를 가지고 left, right로 나눈다 . 이 코드는 아래 코드보다 느림 | . - list타입.pop(0)은 $O(N)$임 . List = [5, 8, 7, 1, 2, 3, 9, 4] def mergeSort(x): if len(x) &lt;= 1: return x mid = len(x) // 2 left = x[:mid] right = x[mid:] next_left = mergeSort(left) next_right = mergeSort(right) return merge(next_left, next_right) def merge(left, right): sorted_list = [] while left and right: if left[0] &lt; right[0]: sorted_list.append(left.pop(0)) else: sorted_list.append(right.pop(0)) while left: sorted_list.append(left.pop(0)) while right: sorted_list.append(right.pop(0)) return sorted_list mergeSort(List) . - 그래서 pop(0)함수를 사용하지 않음 . - 아래의 코드가 이해가 잘 안될 수 있다 . - 그래서 어떻게 split하고 merge가 되는지 알아보기로 하자 . - 밑의 출력을 보니 처음으로 merge()에 대입된 left와 right는 [5]와 [8]임을 알 수 있다 . - 처음으로 넣은 값은 [5, 8, 7, 1, 2, 3, 9, 4]인데 신기하다 . - 자세히 살펴보자 . List = [5, 8, 7, 1, 2, 3, 9, 4] k = 0 def mergeSort(x): ## 나누기 n = len(x) if n &lt;= 1: return x mid = n // 2 left = x[:mid] ## mid를 기준으로 왼쪽 right = x[mid:] ## mid를 기준으로 오른쪽 next_left = mergeSort(left) ## 재귀적으로 나누기 next_right = mergeSort(right) ## 재귀적으로 나누기 global k k += 1 print(&#39;return 횟수 %s&#39; %k) return merge(next_left, next_right) def merge(left, right): ## 병합하기 i = 0 j = 0 sorted_list = list() print(left) print(right) while i &lt; len(left) and j &lt; len(right): ## left와 right중 더 작은 값 넣기 if left[i] &lt; right[j]: sorted_list.append(left[i]) i += 1 else: sorted_list.append(right[j]) j += 1 ## left와 right 중 남은 값을 넣어주기 while i &lt; len(left): sorted_list.append(left[i]) i += 1 while j &lt; len(right): sorted_list.append(right[j]) j += 1 return sorted_list print(mergeSort(List)) . return 횟수 1 [5] [8] return 횟수 2 [7] [1] return 횟수 3 [5, 8] [1, 7] return 횟수 4 [2] [3] return 횟수 5 [9] [4] return 횟수 6 [2, 3] [4, 9] return 횟수 7 [1, 5, 7, 8] [2, 3, 4, 9] [1, 2, 3, 4, 5, 7, 8, 9] . - 우선 mergeSort 함수에서 return은 총 7번 일어남을 알 수 있다 . - 각 상황에서 어떤일이 일어나는지 알아보자 . 우리는 print(mergeSort(List))를 통해 mergeSort 함수에 List라는 input을 넣었다 . | mergeSort에는 [5, 8, 7, 1, 2, 3, 9, 4]이 대입됐다 . | left는 [5, 8, 7, 1], right는 [2, 3, 9, 4]이다 . | next_left는 mergeSort([5, 8, 7, 1]), next_right는 mergeSort([2, 3, 9, 4])이다 . | merge(next_left, next_right)값을 return한다 . | 근데 merge(next_left, next_right)를 return하려고 보니까 next_left, next_right 값을 알아야한다 . | 4번으로 돌아가서 보면 mergeSort([5, 8, 7, 1])와 mergeSort([2, 3, 9, 4])를 구해야 한다 --&gt; 그럼 구하면 되지 . | mergeSort()에 [5, 8, 7, 1]이 대입된다 . | 그러면 mergeSort()는 merge(mergeSort([5, 8]), mergeSort([7, 1]))를 return한다 . | 근데 mergeSort([5, 8]), mergeSort([7, 1])값은 뭐지?? --&gt; 이것도 구해야 한다 . | mergeSort([5, 8])을 구하면 next_left = [5], next_right = [8]이다 . | merge(next_left, next_right)는 merge([5], [8])이 되고 드디어 merge()함수에 left와 right가 대입된다 --&gt; 그래서 처음 left와 right로 출력된 값이 [5]와 [8]이었던 것: return1 . | merge([5], [8])은 [5,8]인 sorted_list를 return한다 --&gt; mergeSort([5, 8])은 [5,8]을 return한다 즉, mergeSort([5, 8])= [5, 8] . | 이제 mergeSort([5, 8])를 구했으니 mergeSort([7, 1])값을 구할 차례이다 . | mergeSort([7, 1])은 merge([7], [1])이고 [1, 7]을 return한다 --&gt; mergeSort([7, 1]) = [1, 7]: return2 . | 이제 8번을 보자. 8번은 merge([5, 8, 7, 1])이고 merge(mergeSort([5, 8]), mergeSort([7, 1]))를 return한다 . | 이때는 mergeSort([5, 8])와 mergeSort([7, 1])를 모르는 상태였지만 이제는 구해서 알고 있다 . | merge([5, 8], [1, 7])을 구해보면 sorted_list로 [1, 5, 7, 8]을 return한다: return3 . | 이제 mergeSort([2, 3, 9, 4])을 구할 차례이다. 이는 위에서 한 방식대로 따라하면 된다 . | 결과적으로 print(mergeSort(List))는 [1, 2, 3, 4, 5, 7, 8, 9]을 출력하게 된다 . | - 메모리 아끼는 병합 정렬 참고: https://www.daleseo.com/sort-merge/ . $O(N)$ &#51221;&#47148; . &#44228;&#49688; &#51221;&#47148; . - 카운팅 정렬이라고도 한다 . - 양수만 가능, 값의 범위가 크면 안됨(메모리 크기를 넘기면 안됨) . - 수의 범위가 작다면(입력으로 주어지는 값들의 개수: 0 ~ 1이라고 수의 범위가 작은 것이 아님... 0 ~ 1사이의 수는 무한개이다) 카운팅 정렬을 통해 빠르게 정렬할 수 있음 . - 비교 정렬이 아님 --&gt; 위의 코드들은 다른 요소값과 비교하는데 카운팅 정렬은 비교없이 데이터를 정렬함 . - 입력으로 주어지는 input의 개수는 큰데 주어지는 값의 개수가 적다면 메모리 관점에서 효율적이다 . - 예로 input이 최대1억개인데 값이 1 ~ 10까지라면 위에서 다룬 정렬은 1억크기의 배열이 필요하지만 카운팅 정렬에 경우는 크기가 10인 배열을 만들면 된다 . - 하지만, 최대 수를 기준으로 배열을 만든다(최대값이 100인 경우 크기가 100인 리스트 생성) . - 그렇기에 [0, 1, 1, 1, 100]인 리스트를 정렬한다고 보면 숫자는 3개 뿐이지만 최대값이 100이므로 크기가 100인 리스트를 만들어야 한다 --&gt; 심한 메모리 낭비 . &#44228;&#49688; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; . 1 최대 값이 k인 크기가 $n$인 정렬되지 않은 리스트가 있다 . List = [5, 8, 7, 1, 1, 3, 9] . 2 k = 10 이라고 가정하자. [0] * (k+1) 리스트를 만든다 --&gt; 파이썬에서 인덱스는 0부터 시작하기 때문 . count = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] . 3 List 요소의 값을 x라 하면 count[x]의 값을 +1 해준다 . count = [0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 0] . 4 count 리스트에서 자기(x) 앞에 몇개의 숫자가 있는지를 바탕으로 x의 위치를 결정하여 정렬한다. 예로 3의 경우 자기 앞에 숫자 2개가 있으므로 3번째이다 . List = [1, 1, 3, 5, 7, 8, 9] . &#44228;&#49688; &#51221;&#47148; &#50508;&#44256;&#47532;&#51608; &#53076;&#46300; &#44396;&#54788; . List = [5, 8, 7, 1, 1, 3, 9] def counting_sort(arr): count = [0] * (max(arr) + 1) sorted_list = [0] * len(arr) for i in arr: count[i] += 1 ## arr에 있는 수를 몇개인지 카운팅함 for j in range(1, max(arr) + 1): count[j] += count[j - 1] ## count[j] 앞에 몇 개의 숫자가 있는지 저장 ## count[5] = 10이라면 5가 x번 등장했다고 할 때 5앞에 10-x개의 숫자가 있다는 의미이므로 sorted_list[10-x : x]에 5가 위치한다. (x 번째 포함 no, x-1번째 까지) for k in range(len(arr)): sorted_list[count[arr[k]] - 1] = arr[k] ## 인덱스는 0부터 시작하므로 -1을 해줌 count[arr[k]] -= 1 return sorted_list print(counting_sort(List)) . [1, 1, 3, 5, 7, 8, 9] .",
            "url": "https://jaesu26.github.io/green/python/algorithm/2021/07/04/%EC%A0%95%EB%A0%AC-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "relUrl": "/python/algorithm/2021/07/04/%EC%A0%95%EB%A0%AC-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "확률 분포",
            "content": "- 2학기에 수리통계학 배움 . - 내용 추가 + 확률 밀도 함수 유도 과정 추가 + 증명 안하고 넘어갔던 부분 추가 예정 . - 만약 수리통계학에 없는 내용이라면? . . . . . . . &#54869;&#47456; &#48516;&#54252;&#46976;? . - 확률 분포(probability distribution)는 확률 변수가 특정한 값을 가질 확률을 나타내는 함수를 의미한다 &gt; 참고: 확률 분포 . &#54869;&#47456; &#48320;&#49688;&#46976;? . - 확률변수(Random Variable)란 무작위 실험을 했을 때 특정 확률로 발생하는 각각의 결과를 수치로 맵핑하는 함수 . - 무작위 실험 &gt; 동전 던지기 . - 특정 확률 &gt; 앞면이 나올 확률 $ dfrac{1}{2}$, 뒷면이 나올 확률 $ dfrac{1}{2}$ . - 각각의 결과 &gt; 앞면(H)과 뒷면(T) . - 수치로 맵핑 &gt; 앞면(H) : $1$, 뒷면(T) : $2$ . &#50672;&#49549; &#54869;&#47456; &#48516;&#54252; . - 연속 확률 변수가 가지는 확률 분포 . - 이산 확률 변수는 확률을 $[ star]P(X=x)[ star]$와 같이 표현 가능, 연속 확률 변수는 이런 표현이 무의미(어차피 $0$) . - 연속 확률 변수는 확률을 $[ star]P(A leq X leq B)[ star]$로 표현 가능 . &#51221;&#44508; &#48516;&#54252; . - 정규 분포는 수집된 자료의 분포를 근사하는 데에 자주 사용됨 . - 중심극한정리에 의하여 독립적인 확률변수들의 평균은 정규 분포에 가까워지는 성질이 있기 때문임 . - 신뢰구간이나 가설검정 등의 모델에서 사용 . - 기호로는 $N sim ( mu, sigma^{2})$ . - 정규 분포의 기댓값, 중앙값, 최빈값은 $ mu$, 분산은 $ sigma^{2}$ . - 표준정규분포는 평균이 0, 표준편차가 1인 경우임 &gt; $N sim (0, 1)$ . - 정규 분포에서 $ mu pm2 sigma$에 전체 데이터 중 $95 %$가 존재 . &#54364;&#51456;&#54868; . - 정규 분포 밀도 함수에서 $Z = cfrac{X - mu}{ sigma}$ 를 통해 $X$(원점수)를 $Z$($z$점수) 표준화하여 표준정규분포(z-분포)를 얻을 수 있다 . &#51221;&#44508; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688;(PDF) . $f(x) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . &#51221;&#44508; &#48516;&#54252; plot . import numpy as np np.random.normal(loc, scale, size) . - loc는 평균, scale은 표준편차, size는 표본의 수 . np.random.normal(loc = 0, scale = 1, size = 1000) . - np.random.normal(loc = 0, scale = 1, size = 1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.normal(loc = 0, scale = 1, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.normal(loc = 0, scale = 1, size = 1000)&#39;) plt.show() . &#44512;&#51068; &#48516;&#54252; . - 모든 확률 변수에 대하여 구간 내에서 균일한 확률을 가짐 . - 임의의 구간 내에서 균일한 확률을 가지기에 난수 생성기로 쓰임 . - 이산 확률 변수에서도 가능 . &#44512;&#51068; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x) = begin{cases} cfrac{1}{b-a} &amp; text{for $x in [a,b]$} 0 &amp; text{otherwise} end{cases} $ . - $f(x)$는 구간 $[a,b]$에서 균등한 확률을 가짐 . &#44512;&#51068; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{a+b}{2}$ . - $Var(X) = cfrac{(b-a)^{2}}{12}$ . &#44512;&#51068; &#48516;&#54252; plot . import numpy as np np.random.uniform(low, high, size) . - low는 출력값의 최소 경계, high은 출력값의 최대 경계, size는 표본의 수 . np.random.uniform(low = 0, high = 1, size = 1000) . - np.random.uniform(low = 0, high = 1, size = 1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.uniform(low = 0, high = 1, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.normal(loc = 0, scale = 1, size = 1000)&#39;) plt.show() . &#50672;&#49549;&#54805; &#54869;&#47456;&#48320;&#49688;&#51032; cdf&#45716; $U(0, 1)$&#51012; &#46384;&#47480;&#45796; . - 증명 . $U=F(x)=P(X leq x) F_{U}(u)=P(U leq u)=P(F(X) leq u)=P(X leq F^{-1}(u))=F(F^{-1}(u))=u f_{U}(u)=1, ;0&lt;u&lt;1 therefore F(X) sim U(0,1)$ . - 역함수가 없는 경우는... 몰라 . - 정규분포를 예로 들자 . - 정규분포에서 샘플을 뽑고 샘플을 누적분포함수에 input하자 . - 그러면 output이 나오고 이를 가지고 확률밀도함수를 그리면 $U(0, 1)$이 된다 . - 일단 연속형 확률변수의 cdf 값은 $0$과 $1$ 사이에 있다 . - 정규분포에서 $x$를 뽑았는데 $0$이 나왔다고 하자 . - 이에 대한 누적분포함수값은 $0.5$이다 . - 이를 반복하면 누적분포함수값이 많이 나올것이다 . - 이를 가지고 확률밀도함수를 그리면 $U(0, 1)$이라는 것이다 . - 즉 누적분포함수값이 $0$과 $1$사이인데 나올 가능성이 모두 같다는 것이다(?) . - 근데 하나의 누적분포함수값에는 하나의 $x$가 대응되는것 아닌가? . - 누적분포함수값이 $0.5$라면 그에 대한 $x$값은 $0$이다 . - $0$과 $1$ 사이의 값을 가지는 누적분포함수값이 나올 가능성이 모두 같다면 $x$도 뽑힐 가능성이 같다(?) . - 히스토그램을 그려보면 $x$값이 $0$근처에 몰려있고 $3$이 넘어가면 거의 없는데 뭐가 같지??? . - 하지만 이는 잘못됐는데 일단 실수는 무한히 많기에 정규분포에서 특정값이 나올 확률은 $0$이다 . - 그러니 특정값에 대한 확률은 같다 . - 그렇기에 범위로 비교하는것이 올바르다 . - 그러면 $x$값이 $0$과 $1$사이에서 나올 확률이랑 $1$과 $2$사이에서 나올 확률이 같음? . - no 다름 . - ??? 위에서 누적분포함수값이 나올 가능성이 모두 같다면 $x$도 뽑힐 가능성이 같다고 했잖음... . - 동일한 누적분포함수값의 범위에 대해서는 같다 . - 일단 하나의 실수를 뽑았다고 치자 &gt; $x$는 $0$이 나왔고 이에 대한 cdf값은 $0.5$임 . - cdf값은 $0$부터 $1$사이에 존재하고 $0$부터 $1$사이의 실수는 무한개이기에 cdf값이 $0.5$일 확률은 $0$이다 . - 또한 $x$가 $3$ 이 나왔다고 치고 이에대한 cdf값은 대충 $0.99$라 치자 &gt; 이 역시 확률은 $0$이다 . - 그럼 범위로 따지면? . - 누적분포함수값이 $0$부터 $0.5$사이일 확률과 $0.5$부터 $1$사이일 확률은 서로 동일하다 . - 바꿔말하자면 확률밀도함수 아래의 면적으로 따졌을 때 $- infty$부터 $0$사이 면적과 $0$부터 $ infty$사이 면적은 동일하다 . - 즉 정규분포에서 표본을 뽑았을 때 $x$값이 $- infty$부터 $0$사이일 확률과 $0$부터 $ infty$사이일 확률은 같다 . - 확률밀도함수에 확률은 $y$값이 아니라 면적이다 . - $x$값이 $0$과 $1$사이에서 나올 확률이랑 $1$과 $2$사이에서 나올 확률은 다른데 그래프 아래의 면적이 다르다 . - 그렇기에 당연히 누적분포함수값의 범위도 다르다 . - 정규분포에서 cdf값이 $0.1$과 $0.3$사이일 확률과 $0.5$와 $0.7$사이일 확률은 같음 . - 이는 정규분포에서 $x$값을 뽑았을 때 $-1.28 sim -0.52$일 확률과 $0 sim 0.52$일 확률이 같다는 의미 . - 즉 $X$를 정규분포에서 생성하고 $X$에 정규분포 cdf를 취하면 이것은 $U(0,1)$을 따른다는 소리 . - 직접 구현하여 맞는지 확인해보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import norm ## 연속형 확률변수는 정규분포로 하자 . np.random.seed(2021) x = np.random.normal(loc = 0, scale = 1, size = 10000) ## 표준정규분포 plt.hist(x, bins = 30) plt.show() . - $x$는 정규분포에서 뽑은 거니까 이를 가지고 히스토그램을 그리면 당연히 정규분포이다 . - $x$축은 정규확률변수가 가질 수 있는 값, $y$축은 빈도수 . - 히스토그램의 면적을 $1$로 만들면 $y$축은 $f(x)$(정규분포의 pdf)가 된다 . - $f(x) = dfrac{1}{ sqrt{2 pi sigma^{2}}}e^{- dfrac{(x- mu)^{2}}{2 sigma^{2}}}$ . - ex) $f(0) = 0.3989422804014327$ . - 정규확률변수가 가질 수 있는 값($x$)의 $99 %$는 $ mu pm 2 sigma$안에 있고 $ mu$에 가까울 수 록 뽑힐 가능성이 높다 . norm.pdf(0) . 0.3989422804014327 . F_x = norm.cdf(x) plt.hist(F_x) plt.show() . - $x$축은 $F(X)$, $y$축은 빈도수, $X$는 정규분포를 따름 . - 정말 $U(0, 1)$를 따른다 . - 즉 연속형 확률분포(예컨대 정규분포) $f(x)$에서 $x$를 뽑고 이를 연속형 확률분포의 cdf $F(x)$에 input하여 나온 값으로 히스토그램을 그리면 위와 같이 $U(0,1)$ 된다 . - 그럼 특정 연속형 확률분포에서 $x$를 뽑지 않고 그냥 균일분포에서 뽑으면? . X = np.linspace(-3, 3, 10000) ## -3부터 3까지 나올 가능성이 동등하다고 생각하자 fig, (ax1, ax2) = plt.subplots(1,2) ax1.plot(X, norm.pdf(X)) ax2.plot(X, norm.cdf(X)) plt.show() . - $x$축은 $U(-3, 3)$, $y$축은 각각 $f(x)$와 $F(x)$ . - 그런데 문득 궁금한점이 있다 . x = np.random.normal(loc = 0, scale = 1, size = 10000) . - 위의 코드를 사용하여 정규분포에서 랜덤표본을 뽑았다 . - 그런데 랜덤표본은 어떻게 뽑지? . - $x$의 pdf를 아는것과 $x$에 대한 샘플링이 가능한것은 다른 문제 . - 예컨대 정규분포에서 특정$x$가 뽑힐 확률은 $0$인데 어떻게 뽑을거? . - $U(0,1)$은 생성할 수 있다고 했을 때 랜덤표본을 추출하는 방법을 알아보자(균일분포를 어떻게 생성하는지는 모르니 넘어가자) . - 위에서 $F(x) = U$라고 했다 &gt; 연속형 확률변수의 cdf는 균일분포를 따른다 . - 그런데 이를 바꿔 말하자면 $x = F^{-1}(U)$ . - 즉 임의의 확률변수에서 $x$를 뽑는것은 $x$의 cdf의 역함수에 $U(0,1)$에서 뽑은 난수를 input하여 구하는것과 동일하다는 것 . - 즉 $x$의 cdf의 역함수를 알고 균일분포에서 랜덤표본을 뽑을 수 있으면 임의의 확률변수에서 $x$를 뽑는것과 같은 효과를 얻을 수 있다는 것 . - 이를 역변환기법(Inverse CDF Method)이라고 한다 . - 단점은 cdf의 역함수를 알아야 한다는 것.... . from scipy.stats import uniform n = 10000 U = uniform.rvs(size = n) X1 = norm.ppf(U) X2 = norm.rvs(size = n) fig, (ax1, ax2) = plt.subplots(1,2) ax1.hist(X1, bins = 30) ax2.hist(X2, bins = 30) plt.show() . - 정말 둘 다 표준정규분포이다! . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;($ chi^2$&#48516;&#54252;) . - $k$개의 서로 독립인 표준 정규 확률변수를 각각 제곱하여 합해 얻어진 분포 . - 이때 $k$는 자유도이며 카이제곱 분포의 매개변수 . - 분산의 퍼진 정도를 분포로 보여줌 . - 모분산을 구하거나 적합도 검정, 독립성/동질성 검정 등의 모델에서 사용 . - $k$개의 독립적이고 표준정규분포를 따르는 확률변수 $Z_1, dots,Z_k$가 있을 때 자유도 $k$의 카이제곱 분포는 . - 확률변수 $Q = sum limits^{k}_{i=1}Z{_i}{^2}$의 분포임 . - 따라서 $Q sim chi{^2}(k)$ . - 참고: 카이제곱 분포 . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x; k) = dfrac{1}{2^ frac{k}{2} Gamma big( frac{k}{2} big)}x^{ frac{k}{2}-1}e^{- frac{x}{2}}$ . - $ Gamma big( frac{k}{2} big)$는 감마함수이다 . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = k$ . - $Var(X) = 2k$ . &#52852;&#51060;&#51228;&#44273; &#48516;&#54252; plot . import numpy as np np.random.chisquare(df, size) . - df는 자유도, size는 표본의 수 . np.random.chisquare(df = 10, size = 1000) . - np.random.chisquare(df = 10, size = 1000)를 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.chisquare(df = 10, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.chisquare(df = 10, size = 1000)&#39;) plt.show() . - 자유도(df)를 바꿔볼까? . - df = 5 . np.random.seed(1) sample = np.random.chisquare(df = 5, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.chisquare(df = 5 , size = 1000)&#39;) plt.show() . - df = 1 . - 표준정규분포의 제곱은 자유도가 1인 카이제곱 분포를 따름 . - $V = bigg( dfrac{X- mu}{ sigma} bigg)^{2} sim chi^{2}(1)$ . - 표본을 10000개 뽑아 둘을 비교해보자! . np.random.seed(2) sample = np.random.chisquare(df = 1, size = 10000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.chisquare(df = 1 , size = 10000)&#39;) plt.show() . np.random.seed(2) sample = np.random.normal(loc = 0, scale = 1, size = 10000) sample = sample**2 plt.hist(sample, bins = 30) plt.title(&#39;square of a standard normal distribution&#39;) plt.show() . - 두 분포가 거의 동일하다 . - 표준정규분포의 제곱은 자유도가 1인 카이제곱 분포를 따른다는 것을 확인할 수 있다 . &#51648;&#49688; &#48516;&#54252; . - 사건이 서로 독립적일 때, 일정 시간동안 발생하는 사건의 횟수가 포아송 분포를 따른다면, 다음 사건이 일어날 때까지 대기 시간은 지수분포를 따른다(지수 분포) . - 기하 분포에서 베르누이 시행 횟수$n$이 많아지고 성공 확률 $p$가 작아지면 지수 분포로 수렴 . - 감마 분포에서 $ alpha = 1$일 때의 특수한 경우임(감마 분포 참고) . &#51648;&#49688; &#48516;&#54252;&#51032; &#47924;&#44592;&#50613;&#49457; . - 기하 분포의 무기억성과 같은 내용임 . - $P(A mid B)$ &gt; 사건 B가 발생한 상황에서 사건 A가 발생할 확률 . - $P(X&gt;s+t mid X&gt;t) = P(X&gt;s)$ . - 핸드폰의 고장률이 지수 분포를 따른다면 내가 핸드폰을 처음 구매하고 1년안에 고장날 확률 = 핸드폰을 5년 사용한 시점에서 1년 안에 고장날 확률 . - 물론 현실은 핸드폰을 5년 사용한 후에 고장날 확률이 더 크다 . &#51648;&#49688; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x; beta) = frac{1}{ beta}e^{- frac{x}{ beta}}, ; x &gt; 0$ . - 위의 확률 밀도 함수는 감마 분포의 확률 밀도 함수에서 $ alpha = 1$을 대입한 결과이다 . - 여기서 $ beta$는 사건 사이의 평균 시간인데 포아송 분포의 모수인 $ lambda$는 단위 시간당 사건의 평균 발생 횟수이다 . - 위의 지수 분포 설명에서 사건의 횟수가 포아송 분포를 따를 때를 전제로 대기 시간은 지수 분포를 따른다고 했다 . - 그렇기에 여기서는 위의 확률 밀도 함수 대신 포아송 분포의 모수인 $ lambda = frac{1}{ beta}$ 를 통해 지수 분포의 확률 밀도 함수를 나타내기로 함 . - 위아래 확률 밀도 함수 둘 다 맞는 표현임, 그런데 numpy.random.exponential이 위의 확률 밀도 함수를 사용하므로 위의 확률 밀도 함수를 기억하는 것이 좋을 것 같음 . $f(x; lambda) = lambda e^{- lambda x}, ; x&gt;0$ . &#51648;&#49688; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{1}{ lambda}$ . - $Var(X) = cfrac{1}{ lambda^{2}}$ . - 기댓값은 어찌보면 당연한데 단위 시간 동안 사건이 $ lambda$번 발생한다면 대기 시간은 $ cfrac{1}{ lambda}$여야 $ lambda times cfrac{1}{ lambda} = 1$(단위 시간)이 성립한다 . &#51648;&#49688; &#48516;&#54252; plot . - 사건이 발생하고 다음 사건이 발생하기 까지의 대기 시간에 대한 확률 분포 . - numpy.random.exponential의 확률 밀도 함수는 $f(x; beta) = frac{1}{ beta}e^{- frac{x}{ beta}}, ; x &gt; 0$임 (numpy 지수 함수) . import numpy as np np.random.exponential(scale, size) . - scale은 $ beta$ = 대기 시간, size는 표본의 수 . np.random.exponential(scale = 2, size = 1000) . - 우리 집 앞에서 1시간당 평균 0.5명이 넘어진다 &gt; $ lambda$(사건의 빈도) $= 0.5$ 이므로 대기 시간 $ beta$(대기 시간) $= 2$ . - 다시말하면 우리 집 앞에서 한 명이 넘어지고 다음 사람이 넘어지기 까지 2시간이 걸린다 . - 이때 한 사람이 넘어지고 다음 사람이 넘어지기 까지 걸리는 대기 시간에 대한 분포를 그려보자 . - np.random.exponential(scale = 2, size = 1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.exponential(scale = 2, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.exponential(scale = 2, size = 1000)&#39;) plt.show() . &#44048;&#47560; &#48516;&#54252; . - 감마 분포는 지수 분포나 푸아송 분포 등의 매개변수에 대한 켤레 사전 확률 분포 . - 이에 따라 베이즈 확률론에서 사전 확률 분포로 사용 . - $ alpha$개의 사건이 일어날 때까지 걸리는 대기 시간에 대한 분포 . - 지수 분포를 한 번의 사건이 아닌 여러 개의 사건으로 확장 . - 지수 분포의 모수가 $ beta$ &gt; $ beta$ = 사건 사이의 평균 시간 . - 모수가 $ beta$인 지수 분포를 따르는 확률 변수 X가 $ alpha$개가 있고 각 확률 변수 X는 i.i.d를 따름 &gt; 이 확률 변수의 합은 모수가 $ alpha, beta$인 감마 분포를 따름 . - 참고: 감마 분포 . &#44048;&#47560;&#54632;&#49688;(Gamma Function) . - 복소수 범위까지 일반화 된 팩토리얼(!) . $ Gamma( alpha) = int_{0}^{ infty}x^{ alpha-1}e^{-x}dx, , alpha geq 0$ . &#44048;&#47560;&#54632;&#49688; &#49457;&#51656; . - $ Gamma( alpha+1) = alpha Gamma( alpha)$ . - $ Gamma(n) = (n-1)!, , n in mathbb{N}$ . - $ Gamma big( frac{1}{2} big) = sqrt{ pi}$ . &#44048;&#47560; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x; alpha, beta) = cfrac{1}{ beta^{ alpha} Gamma( alpha)}x^{ alpha - 1}e^{- frac{x}{ beta}},(x, alpha, beta geq 0)$ . - 확률 변수 $X$가 감마 분포를 따른 다면 $X sim Gamma( alpha, beta)$ . - 발생하기 까지의 평균$ beta = cfrac{1}{ lambda}$의 시간이 소요되는 어떤 사건이 $ alpha$번 발생하는데 걸리는 시간 $X$에 대한 확률 분포 . - $ lambda$는 포아송 분포의 모수로 단위 시간당 사건의 평균 발생 횟수 . - $ alpha = 1$일 때 $ lambda = cfrac{1}{ beta}$인 지수 분포를 따름 . - $X sim Gamma(1, beta) Longleftrightarrow exp big( frac{1}{ beta} big)$ . &#44048;&#47560; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = alpha beta$ . - $Var(X) = alpha beta^{2}$ . &#44048;&#47560; &#48516;&#54252; plot . - $ alpha$는 형태 모수(shape parameter), $ beta$는 척도 모수(scale parameter) . - 사건이 발생하고 다음 사건이 발생하기 까지의 평균 대기 시간이 $ beta$일 때 $ alpha$번의 사건이 발생하는데 걸리는 시간에 대한 확률 분포 . import numpy as np np.random.gamma(shape, scale, size) . - shape는 $ alpha$, scale은$ beta$, size는 표본의 수 . np.random.gamma(shape = 2, scale = 2, size = 1000) . - 우리 집 앞에서 1시간당 평균 0.5명이 넘어진다 &gt; $ lambda = 0.5$이므로 $ beta = 2$ . - 다시말하면 우리 집 앞에서 한 명이 넘어지고 다음 사람이 넘어지기 까지 평균 2시간이 걸린다 . - 이때 2명의 사람이 넘어지기 까지 걸리는 시간에 대한 분포를 그려보자 . - np.random.gamma(shape = 2, scale = 2, size = 1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.gamma(shape = 2, scale = 2, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.gamma(shape = 2, scale = 2, size = 1000)&#39;) plt.show() . - 위에서 지수 분포는 감마 분포에서 $ alpha = 1$인 특수한 경우라고 했음 . - 진짜로 동일한지 $ beta = 4$인 지수 분포와 $ alpha = 1, beta = 4$인 감마 분포를 히스토그램을 그려 비교하자 . np.random.seed(1) sample1 = np.random.gamma(shape = 1, scale = 4, size = 1000) sample2 = np.random.exponential(scale = 4, size = 1000) fig, ax = plt.subplots(1, 2, figsize = (14, 4)) ax[0].hist(sample1, bins = 30) ax[1].hist(sample2, bins = 30) ax[0].set_title(&#39;np.random.gamma(shape = 2, scale = 4, size = 1000)&#39;) ax[1].set_title(&#39;np.random.exponential(scale = 4, size = 1000)&#39;) plt.show() . - 히스토그램을 통해 비교하니 $ alpha = 1$인 감마 분포는 지수 분포와 동일함을 알 수 있다 . $ alpha$&#50752;$ beta$&#50640; &#46384;&#47480; &#44048;&#47560; &#48516;&#54252; &#47784;&#50577; . - $ alpha$는 형태 모수로 $ alpha$가 커질수록 그래프의 모양이 종모양에 가까워짐 . - $ beta$는 척도 모수로 $ beta$가 커질수록 그래프가 퍼짐 . - shape는 $ alpha$, scale은 $ beta$, loc은 위치 매개변수 . - scipy.stats.gamma 참고 . $ alpha$ &#48320;&#54868; $ beta$ &#44256;&#51221; . - $ alpha$(사건 발생 횟수)가 커질수록 그래프가 종모양에 가까워짐 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import gamma loc = 0 scale = 0.5 x = np.linspace(0, 12, 1000) plt.figure(figsize = (14, 7)) for shape in np.arange(2, 11, 2): plt.plot(x, gamma(shape, loc, scale).pdf(x), label = &#39;α = &#39; + str(shape)) plt.title(&quot;Gamma distribution(α = 2, 4, 6, 8, 10, β = 0.5)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() . $ alpha$ &#44256;&#51221; $ beta$ &#48320;&#54868; . - $ beta$(대기 시간)가 커질수록 그래프가 넓게 퍼짐 . loc = 0 shape = 3 x = np.linspace(0, 16, 1000) plt.figure(figsize = (14, 7)) for scale in np.arange(0.4, 2.1, 0.4): plt.plot(x, gamma(shape, loc, scale).pdf(x), label = &#39;β = &#39; + str(round(scale, 1))) plt.title(&quot;Gamma distribution(α = 3, β = 0.4, 0.8, 1.2, 1.6, 2.0)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$f(x)$&quot;) plt.grid() plt.legend() plt.show() . t &#48516;&#54252; . - 표본평균$ bar{X}$을 이용해 정규분포의 평균을 해석 &gt; 모집단이 정규분포를 따를 때 . - 표준화한 표본평균의 분포: 모표준편차를 알고 있음$ bigg( frac{x- mu}{ sqrt{ frac{ sigma}{n}}} bigg)$ --&gt; 정규분포, 모표준편차를 모르고 표본표준편차를 알고 있음$ bigg( frac{x- bar{x}}{ sqrt{ frac{s}{n}}} bigg)$ &gt; t분포 . - 다음의 확률 분포로 정의 &gt; $ cfrac{Z}{ sqrt{ frac{V}{ nu}}}$ . - $Z$는 표준정규분포, $V$는 자유도$ nu$인 카이제곱 분포 . - 자유도가 커질수록 t분포는 표준정규분포에 가까워짐 (중심극한정리와 무관) &gt; 보통 표본 크기 $n geq30$이면 표준정규분포와 가깝다고 한다 . - [$ star$]표본크기가 커지면 표준정규분포에 가까워짐[$ star$] &gt; 표본 크기가 커진다는 것은 모집단에 가까워진다는 의미이므로 표본표준편차도 모표준편차에 가까워짐 . - t 분포의 적률생성함수는 정의되지 않음 . - 참고: t분포 . t &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x) = cfrac{ Gamma big( frac{ nu + 1}{2} big)}{ sqrt{ nu pi} Gamma big( frac{ nu}{2} big)} big(1+ frac{x^2}{ nu} big)^{- big( frac{ nu+1}{2} big)}$ . t &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = 0, ; nu &gt; 1$ . - $Var(X) = cfrac{ nu}{ nu-2} ,( nu&gt;2), ; infty ,(1&lt;v leq2)$ . t &#48516;&#54252; plot . import numpy as np np.random.standard_t(df, size) . - df는 자유도, size는 표본의 수 . np.random.standard_t(df = 5, size = 1000) . - np.random.standard_t(df = 5, size = 1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.standard_t(df = 5, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.standard_t(df = 5, size = 1000)&#39;) plt.show() . - $x = 0$을 기준으로 대칭임 . - 자유도가 5이므로 표본 크기는 6 . - 모표준편차 대신 표본표준편차를 알고 표본 크기가 6일 때 표준화한 표본 평균$ bigg( frac{x- bar{x}}{ sqrt{ frac{s}{n}}} bigg)$에 대한 분포 . - t분포는 표준정규분포보다 꼬리 부근에 밀도가 높음 &gt; 모표준편차 대신 표본표준편차를 사용하기 때문 &gt; 표본의 특성상 추출할 때마다 다르므로 변동성이 있음 . t&#48516;&#54252;&#50752; &#54364;&#51456;&#51221;&#44508;&#48516;&#54252; &#48708;&#44368; . import numpy as np import scipy as sp import scipy.stats import matplotlib.pyplot as plt . x = np.linspace(-5, 5, 100) rv_norm = sp.stats.norm(loc=0, scale=1) rv_t10 = sp.stats.t(df=10) rv_t5 = sp.stats.t(df=5) rv_t1 = sp.stats.t(df=1) norm_pdf = rv_norm.pdf(x) t10_pdf = rv_t10.pdf(x) t5_pdf = rv_t5.pdf(x) t1_pdf = rv_t1.pdf(x) legend = [&#39;z-dist&#39;, &#39;t(df=1)&#39;, &#39;t(df=5)&#39;, &#39;t(df=10)&#39;] plt.figure(figsize = (10, 6)) plt.plot(x, norm_pdf) plt.plot(x, t1_pdf) plt.plot(x, t5_pdf) plt.plot(x, t10_pdf) plt.title(&quot;z-dist, t-dist(df=1, 5, 10)&quot;) plt.xlabel(&quot;$x$&quot;) plt.ylabel(&quot;$p(x)$&quot;) plt.grid() plt.legend(legend) plt.show() . - 위에서 말한대로 t분포가 표준정규분포보다 꼬리가 두껍다 . - 하지만 자유도가 커지면 표준정규분포와 비슷해진다 . F &#48516;&#54252; . - F 검정과 분산분석(ANOVA)등에서 주로 사용됨 . - 카이제곱 분포가 한 집단의 분산에 대해 다뤘다면 F 분포는 두 집단의 분산에 대해 다룸 . - 두 확률변수 $V_1, V_2$가 각각 자유도가 $ nu_1, nu_2$이고 서로 독립인 카이제곱 분포를 따를 때 다음의 확률변수 F는 자유도가 ($ nu_1, nu_2$)인 F-분포를 따름 . - 적률생성함수가 존재하지 않음 . - $F = cfrac{ frac{V_1}{ nu_1}}{ frac{V_2}{ nu_2}} sim F( nu_1, nu_2)$ . - 참고: F 분포 . F &#48516;&#54252; &#49457;&#51656; . - 분자와 분모의 자유도가 뒤바뀐 F 분포 성질: $F_{ nu_1, nu_2, alpha} = cfrac{1}{F_{ nu_2, nu_1, alpha}}$ . - t 분포를 제곱하면 분자와 분모의 자유도가 각각 1, $ nu$인 F분포가 된다 . - $t = cfrac{Z}{ sqrt{ frac{U}{ nu}}} sim t_{ nu}$ . F &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x) = cfrac{ Gamma big( frac{ nu_1+ nu_2}{2} big) big( frac{ nu_1}{ nu_2} big)^{ frac{ nu_1}{2}}x^{ frac{ nu_1}{2}-1}}{ Gamma big( frac{ nu_1}{2} big) Gamma big( frac{ nu_2}{2} big) big(1+ frac{ nu_1}{ nu_2}x big)^{ frac{ nu_1+ nu_2}{2}}}$ . F &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X)= cfrac{ nu_2}{ nu_2-2}, ; nu_2&gt;2$ . - $Var(X)= cfrac{2{ nu_{2}}^{2}( nu_1+ nu_2-2)}{ nu_1( nu_2-2)^{2}( nu_2-4)}, ; nu_2&gt;4$ . F &#48516;&#54252; plot . import numpy as np np.random.f(dfnum, dfden, size) . - dfnum은 분자의 자유도, dfden은 분모의 자유도, size는 표본의 수 . np.random.f(dfnum = 1, dfden = 10, size = 1000) . - np.random.f(dfnum = 1, dfden = 5, size = 1000)를 히스토그램으로 나타내보면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.f(dfnum = 1, dfden = 10, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.f(dfnum = 1, dfden = 10, size = 1000)&#39;) plt.show() . &#48288;&#53440; &#48516;&#54252; . - 제한된 범위$[0, 1]$에서 확률적인 모델링에 적합함(ex: 비율) . - 두개의 매개변수 $ alpha, beta$에 따라 그래프의 모양이 다양함 . - 베타 분포는 확률에 대한 확률분포 &gt; 베이즈안 통계학에서 이항 분포의 켤레 사전 분포로 사용됨 . - 베이지안 방법 &gt; 모수를 확률변수로 생각하여 사전 정보를 활용해 모수를 추정함 . - 이항 분포에서는 성공 확률 $p$가 고정이고 성공 횟수($n-x=$ 실패횟수)가 확률변수인데 베타 분포에서는 성공 횟수($ alpha-1$)와 실패 횟수($ beta-1$)이 고정이고 성공 확률이 확률변수임 . - 베타 분포에서 $ alpha =1, beta=1$이면 균일분포와 동일함 &gt; $ alpha=1, beta=1$이면 성공 횟수와 실패 횟수 둘다$0$이므로 성공확률을 특정할 수 없어서 균일분포 모양을 띄움 . - 참고: 베타 분포 . &#48288;&#53440; &#54632;&#49688; . - 베타 분포의 확률 밀도 함수의 적분값을 1로 만드는 상수 . - 이항 계수를 실수범위까지 확장한 것 . $B( alpha, beta)= int_{0}^{1}x^{ alpha -1}(1-x)^{ beta - 1}dx = cfrac{ Gamma( alpha) Gamma( beta)}{ Gamma( alpha + beta)}$ . &#48288;&#53440; &#48516;&#54252;&#51032; &#54869;&#47456; &#48128;&#46020; &#54632;&#49688; . $f(x)= cfrac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1}, quad 0 leq x leq1, ;( alpha , beta&gt;0)$ . &#48288;&#53440; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X)= cfrac{ alpha}{ alpha + beta}$ . - $Var(X)= cfrac{ alpha beta}{( alpha+ beta)^{2}( alpha+ beta+1)}$ . - $ underset{x}{ mathrm{argmax}} , f(x)= cfrac{ alpha-1}{ alpha + beta - 2}, ; ( alpha, beta &gt; 1)$ . - 최빈값은 성공횟수($ alpha-1$)와 실패횟수($ beta-1$)에 대한 성공률(= 성공횟수($ alpha-1$) / 성공횟수($ alpha-1$) + 실패횟수($ beta-1$)) . &#48288;&#53440; &#48516;&#54252;&#50752; &#51060;&#54637; &#48516;&#54252; . - 베타 분포는 확률에 대한 확률분포라고 했음 . - 예시를 들어서 설명하자 . - 게임을 하는 중임 &gt; 동전이 있는데 앞면이 나오면 이김 &gt; 그런데 앞면과 뒷면이 나올 확률을 알지 못함 . - 연습으로 동전을 10번 던져봤더니 앞면이 3번 뒷면이 7번 나왔음 &gt; 앞면이 나와야 이기므로 앞면이 나올 확률이 뒷면이 나올 확률 보다 높으면 좋겠음 . - 위에 상황에서 앞면이 나올 확률이 0.5보다 클 확률은 얼마일까? &gt; 확률에 대한 확률분포 . $$ begin{aligned}P(X&gt;0.5) &amp;= 1-P(X&lt;0.5) [10pt] &amp;=1- int_{0}^{0.5} cfrac{ Gamma(12)}{ Gamma(4) Gamma(8)}x^{4-1}(1-x)^{8-1}dx [10pt] &amp;=1- int_{0}^{0.5} binom{12}{4}x^{4-1}(1-x)^{8-1}dx [12pt] &amp;= ,??? end{aligned}$$ - 적분하기가 힘들다 . - R의 pbeta() 함수로 구해보자 . import rpy2 import os os.environ[&#39;R_HOME&#39;]=&#39;C:/anaconda3/envs/py38r40/lib/R&#39; %load_ext rpy2.ipython . C: anaconda3 envs py38r40 lib site-packages rpy2 robjects packages.py:366: UserWarning: The symbol &#39;quartz&#39; is not in this R namespace/package. warnings.warn( . %%R 1 - pbeta(0.5, shape1 = 4, shape2 = 8) . [1] 0.1132812 . - 앞면이 3번 뒷면이 7번 나왔을 때 앞면이 나올 확률이 0.5보다 클 확률은 0.1132812이다 &gt; 약 11% . - 아무래도 게임에서 이기기는 힘들어 보인다 . - 그런데 위의 식에서 3번째 줄을 보면 이항 분포가 보인다 . - 성공확률의 거듭제곱과 실패확률의 거듭제곱은 이항분포의 확률 질량 함수에서도 존재함 . - 베타 분포에서는 확률변수 $X$가 성공 확률인 반면 이항 분포에서는 확률변수 $X$가 성공 횟수임 . - 베타 분포: $ cfrac{1}{B( alpha, beta)}x^{ alpha-1}(1-x)^{ beta-1}, ;$ $x$는 성공 확률 . - 이항 분포: $ binom{n}{x} ,p^{k} ,(1-p)^{n-x}, ;$ $x$는 성공 횟수 . - 이렇기에 이항 분포의 모수를 추정하는데 베타 분포가 사전 분포로 사용된다 . &#48288;&#53440; &#48516;&#54252; plot . - scipy.stats.beta()를 통해 다양한 베타 분포를 그려보자 . import numpy as np import matplotlib.pyplot as plt from scipy.stats import beta x = np.linspace(0, 1, 1000) beta_pdf1 = beta(a = 0.5, b = 0.5).pdf(x) beta_pdf2 = beta(a = 5, b = 1).pdf(x) beta_pdf3 = beta(a = 1, b = 3).pdf(x) beta_pdf4 = beta(a = 2, b = 2).pdf(x) beta_pdf5 = beta(a = 2, b = 5).pdf(x) plt.figure(figsize = (7, 5)) plt.plot(x, beta_pdf1, label = &#39;α = 0.5, β = 0.5&#39;) plt.plot(x, beta_pdf2, label = &#39;α = 5, β = 1&#39;) plt.plot(x, beta_pdf3, label = &#39;α = 1, β = 3&#39;) plt.plot(x, beta_pdf4, label = &#39;α = 2, β = 2&#39;) plt.plot(x, beta_pdf5, label = &#39;α = 2, β = 5&#39;) plt.xlabel(&#39;rate of success(x)&#39;) plt.ylabel(&#39;Beta pdf&#39;) plt.title(&#39;Beta distribution&#39;) plt.grid() plt.legend() plt.show() . - $x$축은 성공확률이어서 0과 1사이임 . - $y$축 자체가 확률이 아니라 $ int_{a}^{b}f(x)dx$가 확률이고 $y$축은 $f(x)$임 . - $ alpha = 1, beta geq 1$이면 성공횟수는 0인데 실패횟수는 존재하므로 성공확률 $x$가 낮을 수록 함수값이 큼 . - $ alpha geq 1, beta = 1$이면 성공횟수는 존재하는데 실패횟수는 0이므로 성공확률 $x$가 높을 수록 함수값이 큼 . - $ alpha &gt; 1, beta &gt; 1$이면 기댓값 부근에서 함수값이 크다 + $ alpha+ beta$가 커지고 $ alpha$와 $ beta$가 비슷하면 정규분포에 근사 가능 . - $ alpha &lt; 1, beta &lt; 1$이면 $x$가 0 과 1에 극단적으로 치우침 . &#51060;&#49328; &#54869;&#47456; &#48516;&#54252; . - 이산 확률 변수가 가지는 확률 분포 . &#48288;&#47476;&#45572;&#51060; &#48516;&#54252; . - 성공 확률이 $p$인 베르누이 시행 결과가 성공이면 $1$, 실패면 $0$의 값을 가지는 확률변수의 분포 . &#48288;&#47476;&#45572;&#51060; &#49884;&#54665; . - 임의의 결과가 성공 또는 실패와 같이 가능한 결과가 2 가지 . &#48288;&#47476;&#45572;&#51060; &#49884;&#54665; &#51312;&#44148; . - 각 시행의 결과는 상호 배타적인 두 사건(성공 or 실패)으로 구분 . - 성공 확률 $p$, 실패 확률 $q$일 때, $p+q=1$ . - 각 시행은 독립적 . &#48288;&#47476;&#45572;&#51060; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688;(PMF) . $f(x)=p^x(1-p)^{1-x}, quad x=0,1$ . &#48288;&#47476;&#45572;&#51060; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = p$ . - $Var(X) = p(1-p)$ . &#51060;&#54637; &#48516;&#54252; . - 서로 독립이고 동일한 베르누이 분포를 따르는 확률변수$X_1, dots,X_n$을 모두 합한 것 &gt; $X = sum limits_{i=1}^{n}X_i$ . - 성공 확률이 $p$인 베르누이 시행을 독립적으로 $n$번 반복했을 때 성공 횟수 $X$는 이항 분포를 따름 . - 기호로는 $X sim B(n,p)$ . - 독립적 시행 &gt; 각 시행은 서로 영향을 주지 않음 . &#51060;&#54637; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) ,= , _{n} rm C_{x} ,p^{x} ,(1-p)^{n-x} ,= , binom{n}{x} ,p^{k} ,(1-p)^{n-x}$ . - 성공 확률 $p$인 베르누이 시행을 $n$번 시행하여 그 중 $x$번을 성공할 확률 질량 함수 . - 베르누이 분포는 이항 분포에서 $n=1$일 때이다 . &#51060;&#54637;&#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = np$ . - $Var(X) = np(1-p)$ . &#51060;&#54637; &#48516;&#54252; plot . import numpy as np np.random.binomial(n, p, size) . - $n$은 표본 크기, $p$는 성공 확률, size는 표본의 수 . np.random.binomial(n = 50, p = 0.5, size = 1000) . - 성공 확률이 p = 0.5인 베르누이 시행을 n = 50번 반복하는 것을 표본 하나로 두고 표본을 size = 1000번 추출한다 . - 동전 던지기($p=0.5$)를 $n$ = $50$번 시행하여 앞면이 나온 횟수($X=0,1,2, dots,49,50$)를 하나의 표본이라 할 때 표본을 $size = 1000$번 추출한다 . - np.random.binomial(n = 10, p = 0.5, size = 1000)을 히스토그램으로 나타내면? . - $np geq 5$ 이면 이항분포를 정규분포로 근사할 수 있다 . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.binomial(n = 10, p = 0.5, size = 1000) plt.hist(sample) plt.title(&#39;np.random.binomial(n = 10, p = 0.5, size = 1000)&#39;) plt.show() . &#54252;&#50500;&#49569; &#48516;&#54252; . - 단위 시간, 단위 공간 안에 어떤 사건이 몇 번 발생할 것인지를 표현하는 이산 확률 분포 . - 이항 분포에서 시행횟수$n$이 매우 크고 성공 확률$p$가 매우 작은 경우 성공횟수는 포아송 분포로 근사 가능 &gt; 나중에 증명 . - 음이항 분포에서 성공횟수$x$가 매우 크고 실패 확률$p$가 매우 작은 경우 실패횟수는 포아송 분포로 근사 가능 &gt; 나중에 증명 . - 포아송 분포의 모수($ lambda$)는 단위 시간에서 사건의 평균 발생 횟수 . &#54252;&#50500;&#49569; &#48516;&#54252; &#51204;&#51228; &#51312;&#44148; . - 독립성: 1시간 동안 우리 집 앞에서 넘어진 사람 수와 친구 집앞에서 넘어진 사람 수는 독립이다 . - 일정성: 1시간 동안 평균 3명이 넘어졌다면 2시간 동안에는 평균 6명이 넘어진다 . - 비집락성: 우리 집 앞에서 같은 시간에 두 명 이상이 넘어질 확률은 0이다 . &#54252;&#50500;&#49569; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) = cfrac{e^{- lambda} lambda^{x}}{x!}$ . - $x$는 단위 시간에서 사건의 발생 횟수, $ lambda$는 단위 시간에서 사건의 평균 발생 횟수 . - $ lambda = 10$, $x = 7$ &gt; 단위 시간에서 사건의 평균 10번 발생할 때 7번 발생할 확률은? . - 우리 집 앞에서 1시간에 사람이 평균적으로 10명이 넘어진다고 한다. 이 때 1시간에 사람이 5명 넘어질 확률은? . - $ lambda = 10, , x = 5 longrightarrow f(5) = cfrac{e^{-10} ,10^5}{5!} = 0.03783327480207071$ . &#54252;&#50500;&#49569; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = lambda$ . - $Var(X) = lambda$ . - 평균과 분산이 같으므로 평균이 클수록 그래프가 더 넓게 퍼진다 . &#54252;&#50500;&#49569; &#48516;&#54252; plot . import numpy np.random.poisson(lam, size) . - $ lambda$는 모수, size는 표본의 수 . np.random.poisson(lam = 10, size = 1000) . - 단위 시간에서 사건이 평균 10번 발생할 때 (lam = 10) 단위 시간에서 사건이 몇 번 발생하는지를 하나의 표본이라 할 때 size = 1000번 표본을 추출한다 . - 우리 집 앞에서 1시간당 평균 10명이 넘어질 때($ lambda=10$) 1시간당 몇 명 넘어지는지($x = 0,1,2, dots,10,11, dots$)를 $size = 1000$번 기록한다 . - np.random.poisson(lam = 10, size = 1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.poisson(lam = 10, size = 1000) plt.hist(sample, bins = 24) plt.title(&#39;np.random.poisson(lam = 10, size = 1000)&#39;) plt.show() . - $ lambda$를 바꿔볼까? &gt; 우리 집 앞에서 1시간당 평균 4명이 넘어진다면?? . np.random.seed(1) sample = np.random.poisson(lam = 4, size = 1000) plt.hist(sample) plt.title(&#39;np.random.poisson(lam = 4, size = 1000)&#39;) plt.show() . &#44592;&#54616; &#48516;&#54252; . - 어떤 확률변수 $X$가 성공 확률이 $p$인 베르누이 시행에서 처음 성공까지 시도한 횟수라고 할 때 $X$는 성공 확률 $p$인 기하분포를 따른다 . - 처음 성공할 때까지 걸린 시도 횟수 X가 확률 변수이다 . &#44592;&#54616; &#48516;&#54252;&#51032; &#47924;&#44592;&#50613;&#49457; . - $P(X=x+k mid X&gt;k)=P(X=x)$ . - 성공 확률 p인 베르누이 시행을 현재 k번 시도 했다 . - 하지만 아직 까지 성공하지 못했다 . - 내가 여태까지 k번 실패했으니까 성공확률이 올라갈까?? &gt; 답은 No . - 내가 이제껏 시도한 횟수와 관계없이 성공할 확률은 p로 동일하다 . - 쉽게 말하자면 내가 순백의 주문서10%를 바르고 있는 중이다 . - 여태까지 50장을 발랐는데도 성공하지 못했다 . - 하지만 확률은 그대로 10%이고 기댓값도 10번으로 동일하다 . - 즉, 처음에 순백의 주문서를 성공시키기 위한 기대되는 시도 횟수는 10번이다 . - 50번을 실패했지만 여전히 순백의 주문서를 성공시키기 위한 기대되는 시도 횟수는 10번이다...... . &#44592;&#54616; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) = (1-p)^{x-1}p, ; x = 1, 2, 3, dots$ . - 성공 확률이 $p$일 때 $x-1$번 째 시도까지는 모두 실패하고 $x$번 째 시도에 성공할 확률 질량 함수 . &#44592;&#54616; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{1}{p}$ . - $Var(X) = cfrac{1-p}{p^2}$ . &#44592;&#54616; &#48516;&#54252; plot . import numpy np.random.geometric(p, size) . - $p$는 베르누이 시행에서 성공 확률, size는 표본의 수 . np.random.geometric(p = 0.1, size = 1000) . - 성공 확률이 p = 0.1인 베르누이 시행을 성공할 때까지 시도하는 것을 size = 1000번 반복한다 . - 순백의 주문서($p=0.1$)를 성공할 때까지 시도하여 순백의 주문서가 적용될 때까지 걸린 시도 횟수($X=1,2, dots$)를 $size = 1000$번 기록한다 . - np.random.geometric(p = 0.1, size = 1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.geometric(p = 0.1, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.geometric(p = 0.1, size = 1000)&#39;) plt.show() . &#51020;&#51060;&#54637; &#48516;&#54252; . - 확률변수 $X$를 성공 확률이 $p$인 베르누이 시행을 반복하여 $k$번째 성공이 나올 때 까지 시행횟수라 하면 확률변수 $X$는 음이항 분포를 따름 . - 기하분포는 $k=1$인 음이항 분포 . &#51020;&#51060;&#54637; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) ,= , _{x-1} rm C_{k-1} ,p^{k} ,(1-p)^{x-k} ,= , binom{x-1}{k-1} ,p^{k} ,(1-p)^{x-k}$ . - $x-1$번째 시도까지 성공횟수 $k-1$번였다가 $x$번째 시도에서 성공하여 성공횟수는 $k$가 되었음 . &#51020;&#51060;&#54637; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X) = cfrac{k}{p}$ . - $Var(X) = cfrac{k(1-p)}{p^2}$ . &#51020;&#51060;&#54637; &#48516;&#54252; plot . import numpy np.random.negative_binomial(n, p, size) . - $n$은 성공횟수, $p$는 베르누이 시행에서 성공 확률, size는 표본의 수 . np.random.negative_binomial(n = 5, p = 0.1, size = 1000) . - 성공 확률이 p = 0.1인 베르누이 시행을 5번 성공할 때까지 시도하는 것을 size = 1000번 반복한다 . - 순백의 주문서($p=0.1$)를 5번 성공할 때까지 시도하여 순백의 주문서가 5번 적용될 때까지 걸린 시도 횟수($X=5,6, dots$)를 $size = 1000$번 기록한다 . - np.random.negative_binomial(n = 5, p = 0.1, size = 1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.negative_binomial(n = 5, p = 0.1, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.negative_binomial(n = 5, p = 0.1, size = 1000)&#39;) plt.show() . - 위에서 기하 분포는 음이항 분포에서 $k = 1$인 특수한 경우라고 했음 . - 진짜로 동일한지 $p = 0.4$인 기하 분포와 $p = 0.4, k = 1$인 음이항 분포를 히스토그램을 그려 비교하자 . np.random.seed(1) sample1 = np.random.geometric(p = 0.4, size = 1000) sample2 = np.random.negative_binomial(n = 1, p = 0.4, size = 1000) fig, ax = plt.subplots(1, 2, figsize = (14, 4)) ax[0].hist(sample1, bins = 12) ax[1].hist(sample2, bins = 12) ax[0].set_title(&#39;np.random.geomaric(p = 0.3, size = 1000)&#39;) ax[1].set_title(&#39;np.random.negative_binomial(n = 1, p = 0.3, size = 1000)&#39;) plt.show() . - 히스토그램을 통해 비교하니 $k= 1$인 음이항 분포는 기하 분포와 동일함을 알 수 있다 . &#52488;&#44592;&#54616; &#48516;&#54252; . - $k$개의 성공과 $N-k$개의 실패로 이루어진 크기가 $N$인 유한모집단에서 크기가 $n$인 표본을 뽑고 이 중 성공의 개수를 $X$라 할 때 확률변수$X$는 초기하 분포를 따름 . - $N, k to infty$이고 $ cfrac{k}{N} to p$이면 초기하 분포를 이항 분포로 근사 가능 . - 비복원추출을 하기에 각각의 시행이 서로 영향을 미치므로 독립적 시행이 아님 &gt; 베르누이 시행과의 차이점 . - 샘플링 검사 시에 복원추출을 하지 않고 비복원 추출을 하기 때문에 초기하 분포를 주로 사용함 . &#52488;&#44592;&#54616; &#48516;&#54252;&#51032; &#54869;&#47456; &#51656;&#47049; &#54632;&#49688; . $f(x) = cfrac{_{k} , rm C ,_{x} ; times ; _{N-k} ; rm C ,_{n-x}}{_{N} , rm C ,_{n}} $ . - $N$개 중 $n$개를 뽑는 방법 중에서 성공 $k$개에서 $x$개의 성공을 뽑고 실패 $N-k$개에서 $n-x$개의 실패를 뽑을 확률 . &#52488;&#44592;&#54616; &#48516;&#54252;&#51032; &#44592;&#45843;&#44050;&#44284; &#48516;&#49328; . - $E(X)=n cdot cfrac{k}{N}$ . - $Var(X)= n cdot cfrac{k}{N} cdot cfrac{N-k}{N} cdot cfrac{N-n}{N-1}$ . - 이항분포의 기댓값과 분산과 유사함 . - n은 표본크기, $ cfrac{k}{N}$은 성공확률, $ cfrac{N-k}{N}$은 실패확률 . - $ cfrac{N-n}{N-1}$은 유한모집단수정항으로 $n$는 대체로 1보다 크므로 유한모집단수정항도 1보다 작음 &gt; 이항분포보다 분산이 더 작음 . &#52488;&#44592;&#54616; &#48516;&#54252; plot . import numpy np.random.hypergeometric(ngood, nbad, nsample, size) . - $ngood(=k)$은 유한모집단중 성공횟수, $nbad(=N-k)$는 유한모집단중 실패횟수, $nsample(=n)$은 표본크기, size는 표본의 수 . np.random.hypergeometric(ngood = 700, nbad = 300, nsample = 100, size = 1000) . - 성공횟수 ngood = 700개와 실패횟수 nbad = 300개로 구성된 크기가 1000인 유한모집단($N$)에서 샘플 nsample = 100개를 비복원추출하여 나온 성공횟수 $x$를 size = 1000번 반복한다 . - 당첨용지 700개($ngood = 700$)와 꽝용지 300개($nbad = 300$)로 구성된 로또용지 1000개(유한모집단의 크기$N$)중에서 100개($nsample = 100$)를 비복원추출하여 나온 성공횟수를 $size = 1000$번 기록한다 . - np.random.hypergeometric(ngood = 700, nbad = 300, nsample = 100, size = 1000)을 히스토그램으로 나타내면? . import numpy as np import matplotlib.pyplot as plt np.random.seed(1) sample = np.random.hypergeometric(ngood = 700, nbad = 300, nsample = 100, size = 1000) plt.hist(sample, bins = 30) plt.title(&#39;np.random.hypergeometric(ngood = 700, nbad = 300, nsample = 100, size = 1000)&#39;) plt.show() . - 이항분포와 유사해 보임 .",
            "url": "https://jaesu26.github.io/green/statistics/2021/06/30/%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC.html",
            "relUrl": "/statistics/2021/06/30/%ED%99%95%EB%A5%A0%EB%B6%84%ED%8F%AC.html",
            "date": " • Jun 30, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "깃허브 데스크탑",
            "content": "&#44611;&#54728;&#48652; &#45936;&#49828;&#53356;&#53457; &#51060;&#50857;&#54644;&#49436; &#52964;&#48139;&#54616;&#44592; . 처음에 레포지토리 선택할 때 정보를 저장할 폴더 경로를 선택한다 . | 나의 경우에는 &quot;C:/Users/한재수/github_desktop/green&quot; 이다 . | green폴더에 가보면 notebooks폴더가 있는데 거기서 작업한 주피터 노트북 파일은 깃허브 데스크탑 changes에 표시된다 . | 커밋할 파일 하나를 클릭하고 하단에 메시지를 같이 남긴다 . | 변동 내역 메시지를 작성하고 커밋을 했으면 마지막으로 푸쉬를 한다 . | 깃허브에 변동 내역이 저장된다 . | - 아무 것도 변경하지 않고 save만 해도 깃허브 데스크탑 changes에서 감지된다 . - 아무 것도 변경하지 않았는데 커밋이 된다는 의미... --&gt; 아무짝에도 쓸모 없다. --&gt; 이런 경우에는 커밋을 하지 말고 냅두자 . - 파일이 제대로 푸쉬가 안됐다면? --&gt; 깃허브 _notebook 파일에 있는 history를 보자 . - 만약 빨간색으로 $ times$표시가 되어있다면 클릭 --&gt; error메시지를 볼 수 있음 --&gt; 이를 보고 오류 수정 하면 됨 . &#51089;&#50629; &#44277;&#44036; . - 이제부터 작업은 나의 깃허브 레포지토리(green) 저장 폴더인 green에 있는 notebooks에서 해야 한다 . - 만약 &quot;C:/Users/한재수/github_desktop/green/notebooks&quot; 에서 작업하지 않으면 깃허브 데스크탑 changes에 기록되지 않는다 --&gt; 망함 . Liquid Exception: Liquid syntax error &#54644;&#44208; . - Jekyll에서 사용되는 liquid는 {{ 와 }}를 escape 문자로 사용 &gt; 마크다운에 {{ 과 }}이 있으면 커밋이 error가 나고 {{ 과 }} 사이에 있는 내용은 무시됨 . - 해결 방법 &gt; 여는 중괄호 앞에 {% raw %}를 닫는 중괄호 뒤에 {% endraw %}를 추가함 . - 참고: Liquid syntax error 해결 . - 참고: How to escape liquid template tags . Latex math alignment not working . - Liquid syntax error를 예상하고 {% raw %}와 {% endraw %}를 사용했는데 오류가 발생했음 . - Liquid Exception: Liquid syntax error (line 732): Unknown tag &#39;endraw&#39; . - 뭐가 문제인지 삽질하다가 {% raw %}와 {% endraw %}를 모두 없앴는데 오류가 해결됨 . - 교훈 : 미리 사용하지 말고 오류가 발생하면 사용하자 . - 그런데 또 다른 문제가 생겼다 &gt; 블로그에 수식이 랜더링되지 않음 . - 수식을 등호를 기준으로 정렬하려고 begin{align} ~ end{align} 을 사용했는데 이게 문제를 일으킴 . - 찾아보니 align 대신 aligned를 사용하면 된다고 한다 . - ref : https://github.com/fastai/fastpages/issues/439 . &#44611;&#54728;&#48652; &#49436;&#48260; &#50724;&#47448; &#54869;&#51064; . - 깃허브 데스크탑으로 커밋을 하려는데 오류가 발생했음 . - 왜 그런가 찾아보니 내 문제가 아니라 서버 문제였다 . - 갑자기 오류가 생겼는데 내 문제가 아닌 것 같으면 서버 상태를 확인해보자 . - site: 깃허브 서버 오류 확인 .",
            "url": "https://jaesu26.github.io/green/python/github/2021/06/26/%EA%B9%83%ED%97%88%EB%B8%8C-%EB%8D%B0%EC%8A%A4%ED%81%AC%ED%83%91.html",
            "relUrl": "/python/github/2021/06/26/%EA%B9%83%ED%97%88%EB%B8%8C-%EB%8D%B0%EC%8A%A4%ED%81%AC%ED%83%91.html",
            "date": " • Jun 26, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "리스트 처리",
            "content": "&#47532;&#49828;&#53944; &#51221;&#47148; . sort &#54632;&#49688;&#50752; sorted&#54632;&#49688; . - ?.sort 함수는 list타입인 ? 의 요소를 오름차순으로 정렬한다 . - ?.sort(reverse = True)함수는 내림차순으로 정렬한다 . - sort함수와 sorted함수는 거의 같다 . - ?.sort() 함수는 ?의 속성을 바꾸지만 sorted() 함수는 ?의 속성을 바꾸지 않는다 (a.append()와 + 연산의 차이) . a = [1, 5, 2, 3, 7, 4] print(a) . [1, 5, 2, 3, 7, 4] . a.sort() print(a) . [1, 2, 3, 4, 5, 7] . a.sort(reverse = True) print(a) . [7, 5, 4, 3, 2, 1] . - sort, sorted의 key 옵션에 지정된 함수의 결과에따라 정렬한다 . - lambda함수(익명 함수) 사용 --&gt; lambda 매개변수: 결과 . b = [(1, 2), (0, 2), (1, 3), (1, 5), (0, 1), (2, 8)] c = sorted(b, key = lambda x: (x[0], -x[1])) ## x[1]앞에 있는 &#39;-&#39;기호는 현재정렬순서와 반대로이다 print(c) ##첫 번째 원소는 오름차순, 두 번째 원소는 내림차순으로 정렬 . [(0, 2), (0, 1), (1, 5), (1, 3), (1, 2), (2, 8)] . reverse &#54632;&#49688; . - ?.reverse 함수는 list형태인 ? 의 요소를 역순으로 정렬한다 . d = [1, 5, 2, 3, 7, 4] d.reverse() print(d) . [4, 7, 3, 2, 5, 1] . reversed &#54632;&#49688; . - reversed 함수는 요소를 역순으로 정렬해 반환한다 . - 반환값을 그대로 사용하지 않고 list()나 tuple()함수를 통해 사용한다 . d = [1, 5, 2, 3, 7, 4] reversed(d) . &lt;list_reverseiterator at 0x179d8c11f10&gt; . d = [1, 5, 2, 3, 7, 4] print(tuple(reversed(d))) . (4, 7, 3, 2, 5, 1) . &#47532;&#49828;&#53944; &#52488;&#44592;&#54868; . 1&#52264;&#50896; &#47532;&#49828;&#53944; . a = [] ## 빈 리스트로 초기화 print(a) . [] . A = [x] * n . - $A = [x, x, x, cdots, x, x] longrightarrow$ $x$가 $n$개인 $1$차원 리스트 . a = [0]*10 ## 0리스트로 초기화 print(a) . [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] . 2&#52264;&#50896; &#47532;&#49828;&#53944; . n = 5 list_ = [[0] * n for _ in range(n)] ## 0으로 채원진 2차원 리스트 . list_ . [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]] . list_[0][0] = 123 . list_ . [[123, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]] . List = [[0] * 5 for _ in range(5) . - 그런데 _ 는 뭐지? . - 사실 _ 자리에 다른 것이 들어가도 된다 이를 테면 i . x = [0*i for i in range(5)] print(x) . [0, 0, 0, 0, 0] . - 위에 List에서 _ 대신에 i를 넣는다고 생각하자 . List = [[0] * 5 for i in range(5) . - 위에 리스트인 x 에서는 i가 리스트 안에 0을 몇 개 생성할 지 정하는 변수였다 . - 위에 리스트인 List 에서는 i가 무슨 역할을 하지?? . - 아무역할도 하지 않는다 . - 0을 5개 생성하고 이를 5번 반복한다 . - List를 정의할 때 부터 정해졌다 . - i는 그저 for문을 쓰기 위해 필요함 &gt; range(5)의 값을 받아낼 변수가 필요하다 . - 그래서 i 자리에 오는 변수는 아무짝에도 쓸모가 없다 . - 아무 의미가 없어서 그냥 아무 의미 없어보이는 기호인 _를 쓴다(내 생각) . &#47532;&#49828;&#53944; &#52628;&#44032; . ?.append() . - ? &gt; 리스트 . - 마지막(?[-1]) 위치에 하나의 원소 추가 . a = [] a.append(1) print(a) . [1] . ?.insert(i, v) . - i 위치에 v 원소 추가 . b = [1, 2, 3, 5, 6, 7] b.insert(3,4) print(b) . [1, 2, 3, 4, 5, 6, 7] . ?.extend() . - 마지막(?[-1]) 위치에 리스트 추가 . c = [1, 2, 3, 4, 5] c.extend([6, 7, 8]) print(c) . [1, 2, 3, 4, 5, 6, 7, 8] . ?.pop() . - pop(i)는 리스트의 i번째 요소를 돌려주고 그 요소는 삭제, pop() = pop(-1) . d = [1, 2, 3, 4 ,5] x = d.pop() print(x) print(d) . 5 [1, 2, 3, 4] . arr[::] &#50857;&#48277; . - 슬라이싱 방법임 . - arr[A:B:C] &gt; index A부터 index B(포함X)까지 C간격으로 arr 생성 . - A가 none이면 처음부터 B가 none이면 끝까지 C가 none이면 1만큼 . - 참고: https://docs.python.org/release/2.3.5/whatsnew/section-slices.html . arr = list(range(10)) print(arr) . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . arr[1:9:2] . [1, 3, 5, 7] . arr[:10:3] . [0, 3, 6, 9] . arr[1::2] ## arr[1:2]와 결과가 동일함 . [1, 3, 5, 7, 9] . arr[1:5:] . [1, 2, 3, 4] . arr[5::] ## arr[5:]과 결과가 동일함 . [5, 6, 7, 8, 9] . arr[5:] . [5, 6, 7, 8, 9] . arr[:3:] . [0, 1, 2] . arr[::4] ## arr[:4]와 결과가 동일함 . [0, 4, 8] . arr[:4] . [0, 1, 2, 3] . arr[::] ## arr[:]과 결과가 동일함 . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . arr[:] . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] . &#45796;&#52264;&#50896;&#50640;&#49436;&#51032; &#49324;&#50857; . - 다차원 matrix에서의 사용도 동일함 . - 리스트에서 [ ]를 영역마다 사용하여 슬라이싱 &gt; ex) list[0:2][0:2][0:2] . - 참고: https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html . arr1 = [[1, 2, 3], [2, 3, 4], [3, 4, 5]] ## arr1은 (3, 3)차원 ## arr1(a, b) &gt; a는 1차원 b는 2차원 &gt;a는 x축 b는 y축이라 생각해도 됨 arr1[0:2][0:2] ## x축에서 0~1까지, y축에서 0~1까지 리스트를 슬라이싱함 . [[1, 2, 3], [2, 3, 4]] . arr2 = [[[1, 2, 3], [2, 3, 4]], [[3, 4, 5], [4, 5, 6]], [[5, 6, 7], [6, 7, 8]]] arr2[0:2][0:2][0:2] ## x축에서 0~1까지, y축에서 0~1까지, z축에서 0~1까지 리스트를 슬라이싱함 . [[[1, 2, 3], [2, 3, 4]], [[3, 4, 5], [4, 5, 6]]] . arr2[:][1][0:2] ## x축에서 처음부터 끝까지, y축에서 1, z축에서 0~1까지 리스트를 슬라이싱함 . [[3, 4, 5], [4, 5, 6]] . numpy&#50640;&#49436;&#51032; &#49324;&#50857; . import numpy as np arr3 = np.array(arr2) print(arr3) . [[[1 2 3] [2 3 4]] [[3 4 5] [4 5 6]] [[5 6 7] [6 7 8]]] . arr3.shape ## arr3는 (3, 2, 3)차원의 matrix임 . (3, 2, 3) . - list에서는 [ ]를 영역마다 사용했지만 numpy array에서는 하나의 [ ] 안에서 표현 가능 . - numpy array에서는 콤마(,)로 영역을 구분하고 :를 통해 슬라이싱을 함 &gt; ex) numpy_array[0:2, 0:2, 0:2] . - list[0:2][0:2][0:2] &gt; 리스트에서 슬라이싱 . - arr[0:2, 0:2, 0:2] &gt; numpy array에서 슬라이싱 . - 둘다 의미는 x축에서 0~1까지, y축에서 0~1까지, z축에서 0~1까지 array를 슬라이싱하라는 뜻 . arr3[1, 1 ,1] ## 기본적인 인덱싱 방법 . 5 . arr3[0:2, 0:2, 0:2] ## x축에서 0~1까지, y축에서 0~1까지, z축에서 0~1까지 array를 슬라이싱함 . array([[[1, 2], [2, 3]], [[3, 4], [4, 5]]]) . arr3[:2, :1, :] ## x축에서 처음부터 1까지 y축에서 처음부터 0까지, z축에서 처음부터 끝까지 array를 슬라이싱함 . array([[[1, 2, 3]], [[3, 4, 5]]]) . - 어떤 array가 있는데 마지막 차원에서 인덱스가 마지막 번호인 array만 슬라이싱하고 싶다고 하자 . - 아래와 같이 해도 됨 . arr3[:, :, -1] ## 1차원의 모든 원소, 2차원의 모든 원소, 3차원은 마지막 원소만 가지는 array를 슬라이싱함 . array([[3, 4], [5, 6], [7, 8]]) . - numpy array에서는 ,를 통해 차원의 구분을 하고 :를 통해 슬라이싱을 함 . - 근데 차원이 매우 크다면? . - 예컨데 차원이 100차원이라면 일일이 :와 ,를 입력할 것인가? &gt; 궁금한건 마지막 차원에 대한 조건임, 더 작은 차원은 무관심 . - 어떻게 함?? &gt; ...(ellipsis)를 사용 . - ...은 우리가 일일이 입력해야할 앞의 차원에서의 :와 ,을 의미함 + ...을 뒤에 입력하면 뒤의 차원을 커버함 &gt; 하나의 [ ]안에서 한 개만 사용 가능 . arr3[..., -1] ## ...은 앞의 차원들의 원소를 모두 포함한다는 의미 . array([[3, 4], [5, 6], [7, 8]]) . arr3[..., 0:2] . array([[[1, 2], [2, 3]], [[3, 4], [4, 5]], [[5, 6], [6, 7]]]) . arr3[1, ...] ## 1차원에서 인덱스가 1인 array를 추출, 뒤에 차원들의 원소는 ...을 사용하여 모두 포함했음 . array([[3, 4, 5], [4, 5, 6]]) . &#49836;&#46972;&#51060;&#49905;&#51012; &#49324;&#50857;&#54644; &#51060;&#48120;&#51648;&#51032; RGB&#44050; &#44144;&#44984;&#47196;&#54616;&#44592; . - 이 문제 때문에 ellipsis에 대해 알아봄 . - OpenCV를 통해 이미지를 불러온다고 해보자 . - OpenCV에서는 컬러 이미지를 BGR 순서로 저장함 . - plt.imshow()로 이미지를 확인할 것임 . - 그런데 matplotlib에서는 RGB 순서로 저장함 &gt; RGB순서가 바뀜(흑백 사진은 괜찮음) . - 즉 OpenCV로 읽어온 이미지를 RGB순서로 바꿔야 함 . import matplotlib.pyplot as plt import cv2 as cv img = cv.imread(&#39;squirrel.jpg&#39;) plt.imshow(img) . &lt;matplotlib.image.AxesImage at 0x2737ecd7880&gt; . - cv.imread()를 통해 이미지를 읽어오는데 이 함수가 RGB순서가 아닌 BGR순서로 이미지를 읽어서 원본과 다르게 보이는 것임 . - 이미지도 숫자 matrix임 &gt; BGR순서만 RGB로 할 수 있을까? . - 만약 어떤 array가 있는데 나머지는 그대로 두고 마지막 차원의 원소의 순서만 반대로 하고 싶다면?? &gt; ...을 활용하자 . - img[..., ?]과 같이 하면 일단 마지막 차원의 원소를 제외하고 모두 그대로임 . - 이제 제어할 차원이 하나 남음 &gt; 벡터와 마찬가지 . - 1차원 array의 순서를 거꾸로 하려면??? &gt; array[ : : -1] &gt; 처음부터 끝까지 음의 방향으로 리스트 슬라이싱 . img2 = img[..., ::-1] plt.imshow(img2) ## 원본 이미지가 보임 . &lt;matplotlib.image.AxesImage at 0x2737ee0c340&gt; . - 원본 이미지가 제대로 보임 . - ref: https://stackoverflow.com/questions/50963283/python-opencv-imshow-doesnt-need-convert-from-bgr-to-rgb . - ref: https://ko.wikipedia.org/wiki/%EB%8B%A4%EB%9E%8C%EC%A5%90 . &#47532;&#49828;&#53944; &#49325;&#51228; . ?.remove(x) . - 리스트에서 x원소를 삭제 . - 삭제할 원소가 없을 시 error . a = [1, 2, 3, 4, 5, 6] a.remove(1) print(a) . [2, 3, 4, 5, 6] . a.remove(10) . ValueError Traceback (most recent call last) &lt;ipython-input-2-72b3315abecc&gt; in &lt;module&gt; -&gt; 1 a.remove(10) ValueError: list.remove(x): x not in list . &#47928;&#51088;&#50676; &#54252;&#54632;&#50668;&#48512; . ?.find(&#39;&#47928;&#51088;&#50676;&#39;) . - ?에 문자열이 존재하면 가장 앞에 원소의 시작 인덱스 값을 반환하며 존재하지 않으면 -1값을 반환 . day = &#39;2021-07-03&#39; . day.find(&#39;2021&#39;) . 0 . day.find(&#39;-&#39;) . 4 . day.find(&#39;2222&#39;) . -1 . &#39;&#47928;&#51088;&#50676;&#39; in ? , &#39;&#47928;&#51088;&#50676;&#39; not in ? . - ?에 문자열이 존재하면 True 반환, 존재하지 않으면 False 반환, not in에 경우는 반대로 . day = &#39;2021-07-03&#39; . &#39;2021&#39; in day . True . &#39;-&#39; not in day . False . &#39;2222&#39; in day . False . list = [&#39;1011&#39;, &#39;2022&#39;, &#39;day&#39;, &#39;model&#39;] . &#39;2022&#39; in list . True . &#39;day&#39; not in list . False . &#39;month&#39; in list . False . enumerate &#54632;&#49688; . - for문을 사용할 때 인덱스를 같이 출력할 수 있음 . - 참고: 파이썬 for문 . cards = [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;] for i in range(len(cards)): print(i, cards[i]) . 0 A 1 B 2 C . for value in enumerate(cards): print(value) . (0, &#39;A&#39;) (1, &#39;B&#39;) (2, &#39;C&#39;) . - enumerate 함수는 인덱스와 원소로 이루어진 tuple을 생성함 . - 만약 인덱스와 원소를 다른 변수로 만들고 싶다면 tuple unpacking을 사용하면 됨 . for idx, card in enumerate(cards): print(idx, card) . 0 A 1 B 2 C . zip &#54632;&#49688; . - zip 함수는 iterable한 객체들을 인자로 받아 각각의 원소를 tuple로 접근가능한 iterator를 만듦 . - 참고: python zip function . a = (&#39;John&#39;, &#39;Charles&#39;, &#39;Mike&#39;) b = (&#39;Jenny&#39;, &#39;Christy&#39;, &#39;Monica&#39;) zip(a, b) . &lt;zip at 0x179d8b6d100&gt; . list(zip(a, b)) . [(&#39;John&#39;, &#39;Jenny&#39;), (&#39;Charles&#39;, &#39;Christy&#39;), (&#39;Mike&#39;, &#39;Monica&#39;)] . tuple(zip(a, b)) . ((&#39;John&#39;, &#39;Jenny&#39;), (&#39;Charles&#39;, &#39;Christy&#39;), (&#39;Mike&#39;, &#39;Monica&#39;)) .",
            "url": "https://jaesu26.github.io/green/python/2021/06/24/%EB%A6%AC%EC%8A%A4%ED%8A%B8-%ED%95%A8%EC%88%98.html",
            "relUrl": "/python/2021/06/24/%EB%A6%AC%EC%8A%A4%ED%8A%B8-%ED%95%A8%EC%88%98.html",
            "date": " • Jun 24, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "마크다운 용법",
            "content": "fastpages &#52852;&#53580;&#44256;&#47532; . - _notebook 폴더안에 파일을 만드는데 아래와 같은 형식을 준수하자 . 제목 . &quot;부제목&quot; . -toc: true . -branch: master . -badges: true . -comments: true . -author: 한재수 . -categories: [python] . - 위에 내용을 아무곳에나 붙여 넣는다. 부제목은 (&gt;&quot;부제목&quot;), 제목은 (# 제목) . - categories에 해당하는 부분이 깃허브 홈페이지에서 tag에 보이는 부분이다. . - categories 에서 [ ] 안에 여러개를 추가 할 수 있다. ex) [python, R, CSS] . &#48660;&#47196;&#44536; &#44288;&#47532; . 1. 깃허브 가입하기 . 2. fastai/fastpages 사용 . 3. 깃허브 데스크탑 이용 . (1) 주피터노트북으로 공부한다 . (2) 깃허브와 연결된 어떤 폴더(드랍박스 안의 green)에 공부한 내용을 넣는다 . (3) 깃허브 데스크탑이라는 프로그램을 이용하여 local(내 윈도우 컴퓨터)에서 remote (github)로 변경사항을 반영한다 . (4) 2~3분 뒤에 블로그 홈페이지에 반영된다 . (5) 공부한 내용을 편집없이 주피터 노트북 파일을 올리기만 하면 블로그에 올라가서 편하다 필요에 따라 숨기기, 비밀 포스트도 만들 수 있다 . - 수식을 제대로 입력했는데 블로그에서는 raw 수식 내용이 그대로 보인다면 text{ ... }안에 내용이 수식과 일반 텍스트로 심하게 혼용이 되어 있는지 보자 . - 일반 텍스트는 text{ }안에 적고 수식은 밖에 적으면 해결됨 &gt; 삽질해서 확인함 . &#44611;, &#44611;&#54728;&#48652; . - 버전 관리 시스템 . - 서로 코드를 공유 . - 혼자 쓰면 개인 저장소.. . &#51452;&#54588;&#53552; &#45432;&#53944;&#48513; . &#50976;&#50857;&#54620; &#53412; . - 삭제한 셀 복원 &gt; Edit - Undo cell operation or Esc 후 z키 입력 . - 삭제한 코드 복원 &gt; Ctrl + z . - 주석처리 단축키 &gt; Ctrl + / (여러줄을 동시에 처리할려면 마우스로 스크롤하기) . &#51452;&#54588;&#53552; &#45432;&#53944;&#48513; &gt; remote &gt; page (&#50504; &#50732;&#46972;&#44040; &#49688; &#46020; &#51080;&#45796;) . - 깃허브 데스크탑 history에서 이제껏 했던 커밋을 볼 수 있다. 게다가 삭제된 파일을 복구할 수 도 있다. . - 화면 캡쳐 프로그램으로 캡쳐를 함 &gt; 마크다운에서 캡쳐한 이미지를 ctrl+v하면 캡쳐한 이미지가 삽입된다. . - 이미지 파일을 넣은 주피터 노트북 파일을 올리면 깃허브 notebook에는 올라가지만 블로그에는 올라가지 않는다. . &#47553;&#53356; &#49341;&#51077; . - 보통 링크 삽입은 [label](link)의 형식임 . - 그런데link에 )기호가 있으면 링크 연결에 문제가 있을 수 도 있음 . - [label][key] . - [key]: link . - 위와 같이 해도 링크 연결에 문제가 없고 위의 문제도 해결 가능함 . - 참고: 링크 연결 . &#49688;&#49885; &#44592;&#54840; &#54364;&#54788; . - 3.141592를 변수에 저장하고 싶음 . - pi = 3.141592 . - 그런데 pi 대신에 $ pi$를 사용하고 싶다면?? . - code셀에서 pi를 입력한 후 Tab을 누르면 됨 . pi = 3.141592 π = 3.141592 . pi . 3.141592 . π . 3.141592 . &#49472;&#51032; &#50577;&#45149;&#51004;&#47196; &#51060;&#46041; . - 키보드 위 키를 누르면 셀의 오른쪽 끝으로 이동함 . - 키보드 아래 키를 누르면 셀의 왼쪽 끝으로 이동함 . &#49688;&#49885;&#51012; &#47691;&#51080;&#44172; &#54364;&#54788;&#54616;&#44256; &#49910;&#45796;&#47732;?? . - $수식$ 꼴로 나타낸다. . - y = x^2 + 1 . - $y = x^2 +1$ . &#48145; &#52392;&#51088; &#54364;&#54788; . - $수식_밑첨자$ . - x_1 + x_2 = x_3 . - $x_1 + x_2 = x_3$ . $ sum$ &#54364;&#54788; . - limits 옵션을 통해 $ sum$의 시작과 끝의 위치를 $ sum$의 바로 위와 아래로 지정가능 . - $ sum_{n=1}^{ infty} frac{1}{n^2}$ . - $ sum limits_{n=1}^{ infty} frac{1}{n^2}$ . - mathop로 여러개의 sum을 { }로 감싸주면 글씨를 가운데에 표현 가능 . - $2 mathop{ sum sum} limits_{j&lt;k}Cov(X_j,X_k)$ &gt; mathop{ sum sum} limits_{j&lt;k} . &#48177;&#53552; &#54364;&#54788; . - 벡터 표현하기: 화살표, 볼드체 . - $X$는 변수 . - $ boldsymbol{X}, ; mathbf{X}, ; vec{~X~}$는 벡터 . &#50948;&#50500;&#47000;&#47196; &#51473;&#44292;&#54840; &#54364;&#54788; . - overbrace를 통해 위로 중괄호를 표현함 . - $x+x+x+ dots+x+x, ;x$를 $n$번 더함 . - underbrace를 통해 아래로 중괄호를 표현함 . - $x times x times x times dots times x times x, ;x$를 $n$번 곱함 . - $ overbrace{x + cdots + x}^{n rm times}$ . - $ underbrace{x times cdots times x}_{n rm times}$ . &#51216;&#52237;&#44592; . - s 제외하면 점 하나만 찍힘, s 포함하면 점 세개 찍힌다 . - dots &gt; $ dots$ . - cdots &gt; $ cdots$ . - ddots &gt; $ ddots$ . - vdots &gt; $ vdots$ . &#44292;&#54840; &#53356;&#44172; &#47564;&#46308;&#44592; . - big Big bigg Bigg 을 통해 괄호를 크게 만들 수 있음 . - $ big( Big( bigg( Bigg($ . - $ big[ Big[ bigg[ Bigg[$ . - $ big { Big { bigg { Bigg { $ . - 참고로 수식안에 들어가는 기호로서 중괄호 표현은 { 이다 . &#44544;&#50472; &#53356;&#44592; &#51312;&#51208; . - link : https://ko.overleaf.com/learn/latex/Font_sizes,_families,_and_styles . &#44060;&#54665; &#44036;&#44201; &#51312;&#51208; . - link : https://tex.stackexchange.com/questions/494582/spacing-of-newline-and . - 참고로 주피터노트북에서 보이는 간격이랑 블로그에서 보이는 간격이 다름 . &#49688;&#49885; &#49353;&#44628; &#48148;&#44984;&#44592; . - $x^2+1$ , $(x+1)^2$ . - ref : https://stackoverflow.com/questions/35465557/how-to-apply-color-in-markdown . &#47928;&#51088; &#50948;&#50640; &#47928;&#51088; &#54364;&#49884; . - ${H_0}^{ sim}$ &gt; {H_0}^{ sim} . - $ overset{ sim}{H_0}$ &gt; overset{ sim}{H_0} . - ref : https://tex.stackexchange.com/questions/43335/how-to-write-is-distributed-as-under-a-certain-hypothesis . &#49688;&#49885;&#51032; &#49884;&#51089; &#50948;&#52824;&#47484; &#46041;&#51068;&#54616;&#44172; &#54616;&#44256; &#49910;&#45796;&#47732;? . $$ frac{ partial boldsymbol L}{ partial beta_0} = - frac{1}{ sigma^2} sum limits^{n}_{i=1}(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} = frac{1}{ sigma^2} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} = - frac{n}{2 sigma^2}+ frac{1}{2 sigma^4} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0$$- begin{aligned} 와 end{aligned}를 사용하면 된다 . $$ begin{aligned} frac{ partial boldsymbol L}{ partial beta_0} &amp; = - frac{1}{ sigma^2} sum limits^{n}_{i=1}(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} &amp; = frac{1}{ sigma^2} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0 frac{ partial boldsymbol L}{ partial beta_1} &amp; = - frac{n}{2 sigma^2}+ frac{1}{2 sigma^4} sum limits^{n}_{i=1}x_i(y_i- beta_0- beta_1 x_i)=0 end{aligned}$$- ref: https://stackoverflow.com/questions/28353127/how-to-change-alignment-of-displayed-equations-in-ipython-notebook . &#50976;&#50857;&#54620; latex . boldsymbol . - applies to nearly all symbols, not just letters and numbers . - ex) $ boldsymbol{A} ,A$ . bf . - Used to turn on boldface; affects uppercase and lowercase letters, and digits . - ex) ${ bf 123} ,{123}$ . - ex) ${ bf A} ,{A}$ . therefore . - therefore를 통해 삼각형 모양 점3개를 만듦 . - $ therefore 1+1= text{힘든 삶}$ . bigcup . - 집합열을 포현할 때 합집합 기호의 밑과 위에 시작과 끝을 표시하고 싶다면 bigcup과 limits를 사용하자 . - $ cup_{i=1}^{ infty} A_i$ &gt; cup_{i=1}^{ infty} A_i . - $ bigcup_{i=1}^{ infty} A_i$ &gt; bigcup_{i=1}^{ infty} A_i . - $ bigcup limits_{i=1}^{ infty} A_i$ &gt; bigcup limits_{i=1}^{ infty} A_i . cfrac . - 일반적인 frac과의 차이점은 글씨의 크기임 . - $P(A|B) = frac{P(A cap B)}{P(B)}$ &gt; frac . - $P(A|B) = cfrac{P(A cap B)}{P(B)}$ &gt; cfrac . mid . - 수직선을 그려줌 &gt; 조건부 확률 표현할 때 사용 . - $P(A|B) = cfrac{P(A cap B)}{P(B)}$ &gt; | . - $P(A mid B) = cfrac{P(A cap B)}{P(B)}$ &gt; mid . xrightarrow . - 오른쪽방향의 화살표를 그려주는데 화살표위에 글씨를 적을 수 있다! . - 확률변수의 수렴을 표현할 때 사용할 수 있음 . - $X_n{ xrightarrow{p}} X$ &gt; X_n{ xrightarrow{p}} X : 확률수렴 . - 그런데 화살표길이가 더 길었으면 좋겠다 . - 그럴땐 ~ 기호를 이용하면 된다 . - $X_n{ xrightarrow{~~p~~}} X$ &gt; X_n{ xrightarrow{~~p~~}} X . - 아래처럼 할 수 도 있음 . - $X_n overset{p}{ longrightarrow}X$ &gt; X_n overset{p}{ longrightarrow}X . operatorname . - 이탤릭체인 글씨체를 변경 . - $ underset{x}{argmin}f(x)$ &gt; underset{x}{argmin}f(x) . - $ underset{x}{ operatorname{argmin}}f(x)$ &gt; underset{x}{ operatorname{argmin}}f(x) . &#47588;&#50864; &#50976;&#50857;&#54620; &#49324;&#51060;&#53944; . - &lt;Jupyter 노트북에서 Markdown 및 LaTeX을 작성하는 방법 알아보기 &gt; https://ichi.pro/ko/jupyter-noteubug-eseo-markdown-mich-latexleul-jagseonghaneun-bangbeob-al-abogi-18246612521469 . - latex command 총 정리 &gt; https://www.tutorialspoint.com/tex_commands/percentage.htm .",
            "url": "https://jaesu26.github.io/green/python/github/markdown/jupyter/latex/2021/06/24/markdown-in-latex.html",
            "relUrl": "/python/github/markdown/jupyter/latex/2021/06/24/markdown-in-latex.html",
            "date": " • Jun 24, 2021"
        }
        
    
  
    
        ,"post31": {
            "title": "map 함수",
            "content": "map &#54632;&#49688; &#53945;&#51669; . - 여러 개의 데이터를 한 번에 다른 형태로 변화하기 위해 사용한다. . - map 함수는 원본 리스트를 변경하지 않고 새 리스트를 생성한다. . - map 함수는 map 타입으로 결과를 리턴하기 때문에 리스트나 튜플 등으로 변환해야 한다. . - map 함수는 리스트의 요소를 지정된 함수로 처리한다. . x = list(range(5)) x . [0, 1, 2, 3, 4] . def two_times(x): return x * 2 . y = two_times(x) y . [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] . z = list(map(two_times, x)) z . [0, 2, 4, 6, 8] . map &#54632;&#49688; &#49324;&#50857;&#48277; . - map(함수, 반복가능한 객체) . x = [1.1, 2.1, 3.1, 4.1] y = map(int, x) print(y) . &lt;map object at 0x0000023B6D93D040&gt; . - map 함수는 map 타입으로 결과를 리턴하기 때문에 리스트나 튜플 등으로 변환한다. $ rightarrow [ star$] 변환하지 않으면 위와 같은 결과를 출력한다. [$ star$] . - print(y)하지 않고 그냥 y만 입력해도 된다. . x = [1.1, 2.1, 3.1, 4.1] y = list(map(int, x)) y . [1, 2, 3, 4] . def minus(a): return a - 0.1 . list(map(minus, x)) . [1.0, 2.0, 3.0, 3.9999999999999996] . - minus 함수는 map 함수를 위해 한 번 쓰고 버려질 운명이다. 만드는게 귀찮음... . map &#54632;&#49688;&#50640; &#46988;&#45796; &#49885; &#49324;&#50857; . x = [1.1, 2.1, 3.1, 4.1] list(map(lambda a: a - 0.1, x)) . [1.0, 2.0, 3.0, 3.9999999999999996] . input().split()&#44284; map . - input()함수는 c언어의 scanf()함수와 비슷하다. . z = input() . z . &#39;hello&#39; . - input()으로 입력받은 값은 문자열이다. . n = input() . type(n) . str . - input()함수에서 안내문구를 추가할 수 도 있다. . Q = input(&#39;숫자 하나를 입력하세요:&#39;) . Q . &#39;26&#39; . - input()함수의 출력값을 문자열이 아닌 다른 자료형으로 바꾸고 싶다면? . w = int(input(&#39;숫자 하나를 입력하세요:&#39;)) . type(w) . int . - input().split(&quot;기준문자열&quot;)을 사용하면 입력값을 변수 여러 개에 저장할 수 있다. . - split()에서 &quot;기준문자열&quot;이 없는 즉 default는 공백이다. . a, b = input().split() # 입력받은 값을 공백(스페이스, 탭, 엔터 등)을 기준으로 분리 . a, b . (&#39;10&#39;, &#39;20&#39;) . c = a, b type(c) . tuple . - a와b가 문자열이다. . - int형으로 바꾸고 싶다면? . a, b = int(input().split()) . TypeError Traceback (most recent call last) &lt;ipython-input-17-0de5d52cb787&gt; in &lt;module&gt; -&gt; 1 a, b = int(input().split()) TypeError: int() argument must be a string, a bytes-like object or a number, not &#39;list&#39; . - int()함수를 쓰면 될 것 같았는데 오류가 나온다 . - error메시지를 읽어보니 int()함수는 무조건 a string, a bytes-like object or a number 여야 한다.(not &#39;list&#39;) . - a, b는 tuple인 것 같다. . - 그러면 어떻게 하지? $ longrightarrow$ map()함수를 쓰면 된다. . a, b = map(int, input().split()) # 입력받은 값을 정수로 변환 . a, b . (10, 20) . type(a) . int . type(b) . int . - a, b = map(int, input().split())을 풀어서 쓰면 다음과 같은 코드이다. . x = input().split() # input().split()의 결과는 문자열 리스트 m = map(int, x) # 리스트의 요소를 int형으로 변환, 결과는 맵 객체 a, b = m # 맵 객체는 변수 여러 개에 저장 가능 . map()&#54632;&#49688; &#51060;&#50857;&#54644; &#54620; &#51460;&#50640; &#50668;&#47084; &#44050; &#51077;&#47141; &#48155;&#44592; . L = list(map(int, input().split())) L . [10, 8, 7, 1, 0, 3, 5, 2] . map()&#54632;&#49688; &#51060;&#50857;&#54644; &#50668;&#47084; &#51460;&#50640; &#50668;&#47084; &#44050; &#51077;&#47141; &#48155;&#44592; . data = [] N = int(input()) for i in range(N): data.append(list(map(int, input().split()))) . data . [[1, 4, 0, 2], [17, 8, 1, 0, 4, 6], [1, 0], [0, 4, 5], [0, 0, 10]] .",
            "url": "https://jaesu26.github.io/green/python/2021/06/21/map%ED%95%A8%EC%88%98.html",
            "relUrl": "/python/2021/06/21/map%ED%95%A8%EC%88%98.html",
            "date": " • Jun 21, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "파이썬 기말시험",
            "content": "- 문제 : 시험 문제 . import pandas as pd import numpy as np . 1&#48264; &#47928;&#51228; . class execution_sword(): def __init__(self): self.upgradestate = pd.DataFrame({&#39;day0&#39;:[0] * 100}) self.prob = 0.3 self.day = 0 def add_day(self): self.day = self.day + 1 ## 날짜를 하루 더한다 def attempt(self): self.attemptresult = np.random.binomial(n = 1, p = self.prob, size = 100) def update(self): self.upgradestate[&#39;day%s&#39; % self.day] = np.minimum(self.upgradestate[&#39;day%s&#39; % (self.day - 1)] + self.attemptresult, 5) ## +5이후로는 증가하지 않는다 self.ratio = sum(self.upgradestate.loc[:, &#39;day%s&#39; % self.day] == 5) / 100 def return_ratio(self): return self.ratio ## ratio(성공한 사람 수 / 전체 사람 수)를 리턴한다 . #1-(1) test1 = execution_sword() for test1.day in range(1, 63): test1.attempt() test1.update() 100 * test1.ratio ## 62일후 100명중 몇명이 +5강화 상태인가? ## 시뮬레이션 결과 100명이였다 . 100.0 . - 위에처럼 test.i를 함수 외부에서 조작하는 것은 좋지 않다 . - 마찬가지로 test1 클래스의 멤버변수(ratio)에 직접 접근하는 것도 좋지 않다 . - 이를 조작할 수 있는 함수를 새로 만들고 코드를 다시 구현하자 . test_1 = execution_sword() for k in range(1, 63): test_1.add_day() test_1.attempt() test_1.update() 100 * test_1.return_ratio() . 100.0 . 2&#48264; &#47928;&#51228; . class execution_sword2(execution_sword): def __init__(self): super().__init__() ## 함수 오버라이딩 self.prob = 0.7 self.failstate = pd.DataFrame({&#39;day0&#39;:[0] * 100}) def update(self): super().update() ## 함수 오버라이딩 self.failstate[&#39;day%s&#39; % self.day] = self.failstate[&#39;day%s&#39; % (self.day - 1)] + (self.attemptresult == 0) * 1 for j in range(100): if self.upgradestate.iloc[j, self.day] == 0: self.failstate.iloc[j, self.day] = self.failstate.iloc[j, self.day] - 1 ## i-1번째 + 강화시도(0 or 1) = i번째 ## i, i-1번째 강화상태가 0이라는 의미는 i-1째에 시도한 강화가 실패했다는 의미 ## upgradestate가 0이라는 의미는 실패했다는 것이므로 실패횟수가 하나 쌓인다 ## +0에서는 실패횟수가 쌓이지 않으므로 failstate값을 하나 뺀다 if (self.upgradestate.iloc[j, self.day] == 5) and (self.attemptresult[j] == 0): ## i-1번째 + 강화시도(0 or 1) = i번째 ## i번째가 +5강화이면서 i-1번째 시도한 강화가 실패라는 의미는 ## i-1번째가 +5강화였다는 의미이다. 그러므로 i번째 실패횟수가 +1 됐을것이다 ## +5강화에서는 강화를 도전하지 않을 것이다 ## 그러므로 i번째 실패횟수를 1을 감소시킨다 self.failstate.iloc[j, self.day] = self.failstate.iloc[j, self.day] - 1 ## +5에서는 강화를 시도하지 않을것이므로 ## 만약 실패했다면 failstate값을 하나 뺀다 def reset(self): for j in range(100): if (self.upgradestate.iloc[j, self.day] &gt; 0) and (self.upgradestate.iloc[j, self.day] &lt; 5): if self.failstate.iloc[j, self.day] == 2: self.failstate.iloc[j, self.day] = 0 self.upgradestate.iloc[j, self.day] = 0 ## 실패스택이 2라면 실패스택을 0으로 바꾸고 강화상태를 +0으로 바꾼다 def arrangeprobt(self): if self.ratio &gt;= 0.5: self.prob = 0.9 ## +5강 비율이 50%이상이라면 전체유저의 강화 성공확률을 90%로 바꾼다 @property def return_ratio(self): return self.ratio . - 위에서 멤버변수 ratio를 반환하는 return_ratio라는 함수를 만들었다 . - 그런데 전에는 인스턴스.ratio를 사용했는데 이제는 인스턴스.return_ratio()를 써야한다 . - 전에 사용하던 것처럼 값으로 쓰고싶다(괄호를 생략하여 메소드를 값처럼 사용하고 싶다) . - @property를 사용! . #2-(1) test2 = execution_sword2() for k in range(1, 63): test2.add_day() test2.attempt() test2.update() test2.reset() 100 * test2.return_ratio ## 괄호 생략 가능 ## 그런데 메소드 이름이 return_ratio라 괄호가 있는 것이 자연스러운 것 같음 ## 시뮬레이션 결과 100명이였다 . 100.0 . #2-(2) test3 = execution_sword2() for k in range(1, 32): test3.add_day() test3.attempt() test3.update() test3.reset() 100 * test3.return_ratio ## 31일후 100명중 몇명이 +5강화 상태인가? ## 시뮬레이션 결과 99명이였다 . 99.0 . #2-(3) test4 = execution_sword2() for k in range(1, 63): test4.add_day() test4.attempt() test4.update() test4.reset() test4.arrangeprobt() 100 * test4.return_ratio ## 과반수가 +5강화 일때 성공확률을 0.9로 바꾼다, 62일후 100명중 몇명이 +5강화 상태인가? ## 시뮬레이션 결과 100명이였다 . 100.0 . 3&#48264; &#47928;&#51228; . - 다음문장을 잘 읽고 참 거짓을 판단하여라 (10점) . 1. tuple은 원소의 값을 임의로 바꿀 수 있다 &gt; 거짓 . 2. class 에 정의된 함수(=메서드)는 self 만을 인자로 받을수 있다 &gt; 거짓 .",
            "url": "https://jaesu26.github.io/green/python/2021/06/18/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9E%85%EB%AC%B8-%EA%B8%B0%EB%A7%90%EC%8B%9C%ED%97%98.html",
            "relUrl": "/python/2021/06/18/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9E%85%EB%AC%B8-%EA%B8%B0%EB%A7%90%EC%8B%9C%ED%97%98.html",
            "date": " • Jun 18, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "학점 . - 1학년 1학기: 4.38 . - 1학년 2학기: 4.50 . - 2학년 1학기: 4.42 . - 2학년 2학기: 4.50 . 프로그래밍 언어 . - R . - 파이썬 . - 잘하고 싶다… . 자격증 . - 있을까? . 토익 . - 할거임 . 대외활동 . - 해야지 . 봉사활동 . - .. .",
          "url": "https://jaesu26.github.io/green/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jaesu26.github.io/green/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}